# Abstract Cyclic peptides, characterized by geometric con- straints absent in linear peptides, offer enhanced biochemical properties, presenting new oppor- tunities to address unmet medical needs. How- ever, designing target-specific cyclic peptides re- mains underexplored due to limited training data. To bridge the gap, we propose CP-Composer, a novel generative framework that enables zero-shot cyclic peptide generation via composable geo- metric constraints. Our approach decomposes complex cyclization patterns into unit constraints, which are incorporated into a diffusion model through geometric conditioning on nodes and edges. During training, the model learns from unit constraints and their random combinations in linear peptides, while at inference, novel con- straint combinations required for cyclization are imposed as input. Experiments show that our model, despite trained with linear peptides, is ca- pable of generating diverse target-binding cyclic peptides, reaching success rates from 38% to 84% on different cyclization strategies.

1.

# Introduction

Peptides occupy an intermediate position between small molecules and antibodies, offering unique advantages over conventional drug formats, such as higher specificity and enhanced cell permeability (Fosgerau & Hoffmann, 2015; Lee et al., 2019). Among them, cyclic peptides, which intro- duce geometric constraints into linear peptides, have earned

*Equal contribution 1Institute for AI Industry Research (AIR), Tsinghua 2Xingjian College, Tsinghua University 3Department of Computer Science and Technology, Tsinghua University 4Stanford University 5Gaoling School of Artificial Intelligence, Renmin University of China 6Beijing Key Laboratory of Research on Large Models and Intelligent Governance 7Department of Elec- tronic Engineering, Tsinghua University. Correspondence to: Yang Liu <liuyang2011@tsinghua.edu.cn >, Jianzhu Ma <ma- jianzhu@tsinghua.edu.cn>.

Proceedings of the 42 nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025 by the author(s).

1

Figure 1. Four common strategies to form cyclic peptides. (A) Stapled peptide where a lysine (K) at position i and an aspartic acid (D) at position i + 3 are connected via dehydration condensation on side chains. The aspartic acid can also be replaced with glutamic acid (E) at position i + 4. (B) Head-to-tail peptide where the first residue and the last residue form an amide bond for connection. (C) Disulfide peptide where two cysteines (C) non-adjacent in sequence are spatially connected through a disulfur bond. (D) Bicycle peptide which uses 1,3,5-trimethylbenezene to form a triangle between three cysteines (C) non-adjacent in sequence.

increasing attention (Zorzi et al., 2017). These constraints stabilize the peptide conformation, enhancing biochemical properties including binding affinity, in vivo stability, and oral bioavailability (Ji et al., 2024), which are essential for identifying desired drug candidates (Zhang & Chen, 2022).

Existing literature on target-specific peptide generation pri- marily focus on linear peptides, utilizing autoregressive models (Li et al., 2024a), multi-modal flow matching (Li et al., 2024b; Lin et al., 2024), and geometric latent dif- fusion (Kong et al., 2024). However, these methods are not directly applicable to cyclic peptide design due to the scarcity of available data (Rettie et al., 2024). Other ap- proaches either impose geometric constraints on linear pep- tides through post-filtering (Wang et al., 2024b), which typi- cally results in low acceptance rates, or rely on hard-coded model design (Rettie et al., 2024), which lacks general- izability across different cyclization patterns. In contrast, we hypothesize that the complex geometric constraints of cyclic peptides can be decomposed into fundamental unit constraints, resembling how complex mathematical formu- las are built from basic arithmetic operations. While existing datasets rarely contain peptides that satisfy intricate cyclic

SSSCCCKDCSSCABCD











Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

constraints, they typically include abundant instances of sin- gle unit constraints and their random combinations, which serve as the building blocks for more complicated designs. Therefore, we reason that a framework could potentially be developed to learn these unit constraints from available linear peptide data, circumventing data limitations and en- abling generalization to the diverse combined constraints required for cyclic peptide design.

In this paper, we present CP-Composer, a framework for zero-shot cyclic peptide generation, relying solely on avail- able data for linear peptides. Our work is equipped with the following contributions. 1) Decomposing cyclization strategies into fundamental geometric constraints. We identify four common chemical cyclization strategies (Fig- ure 1) and formalize cyclic peptide design as a geometrically constrained generation problem. By analyzing cyclization patterns, we derive two fundamental unit constraints, type constraints and distance constraints, allowing description of diverse cyclization strategies to be specific combinations of these units. 2) Encoding constraints with geometric condi- tioning. We incorporate unit constraints into a the denoising network of a diffusion model (Kong et al., 2024) using ad- ditional vectorized embeddings of types and distances on geometric graphs, which enables flexible conditioning on compositions of constraints required for cyclic peptide gen- eration. 3) Enabling zero-shot cyclic peptide design. We jointly train conditional and unconditional models on unit constraints and their random combinations found in linear peptide data. At inference, novel constraint combinations corresponding to desired cyclization strategies, which are unseen during training, are imposed as input conditions. The model is guided by the difference in score estimates between conditional and unconditional models, enabling zero-shot generalization to cyclic peptides. 4) Assessing generated cyclic peptides on comprehensive metrics. Ex- periments demonstrate that our CP-Composer generates cyclic peptides with complex geometric constraints effec- tively, achieving high success rates from 38% to 84%, while maintaining realistic distributions on amino acid types and dihedral angles. Molecular dynamics further confirm that the generated cyclic peptides exhibit desired binding affinity while forming more stable binding conformation compared to the native linear peptide binders.

2024), there have been growing interests in scaling these models to systems of larger scales, such as antibody (Luo et al., 2022), peptide (Kong et al., 2024), and protein (Yim et al., 2023; Watson et al., 2023; Anand & Achim, 2022) in general, or to those with complex dynamics, such as molecu- lar dynamics simulation (Han et al., 2024b). Despite fruitful achievements, how to impose diverse geometric constraints stills remain under-explored for geometric diffusion models, which we aim to address in this work.

Diffusion guidance. Diffusion sampling can be flexibly controlled by progressively enforcing guidance through the reverse denoising process. Dhariwal & Nichol (2021) pro- poses classifier-guidance, which employs an additionally trained classifier to amplify the guidance signal. Classifier- free guidance (CFG) (Ho & Salimans, 2022) is a more widely adopted alternative that replaces the classifier with the difference of the conditional and unconditional score, which has been further generalized to the multi-constraint scenario by composing multiple scores in diffusion sam- pling (Liu et al., 2022; Huang et al., 2023). Diffusion guid- ance has also been explore for solving inverse problems on images (Song et al., 2024; Kawar et al., 2022; Song et al., 2021b), molecules (Bao et al., 2022), and PDEs (Jiang et al., 2024). Our approach instead extends CFG to compose geo- metric constraints with application to cyclic peptide design.

Peptide design. Target-specific peptide design initially re- lied on physical methods using statistical force fields and fragment libraries (Hosseinzadeh et al., 2021; Swanson et al., 2022). With the rise of equivariant neural networks (Sator- ras et al., 2021; Han et al., 2024a), geometric deep gen- erative models have emerged. PepFlow (Li et al., 2024b) and PPFlow (Lin et al., 2024) use multi-modal flow match- ing, while PepGLAD (Kong et al., 2024) applies geometric latent diffusion with a full-atom autoencoder. However, these methods struggle with cyclic peptide design due to limited data. Prior works introduce disulfide bonds via post-filtering (Wang et al., 2024b) or enforce head-to-tail cyclization through hard-codedo model design (Rettie et al., 2024). In contrast, our approach decomposes cyclization into fundamental unit constraints, enabling zero-shot cyclic peptide generation with broad flexibility across diverse pat- terns.

2. Related Work

3. Method

Geometric diffusion models. Besides their success on ap- plications like image (Rombach et al., 2021; Song et al., 2020; 2021a) and video (Ho et al., 2022) generation, diffu- sion models have become a preeminent tool in modeling the distribution of structured data in geometric domains. While early works have explored their applicability on tasks like molecule generation (Xu et al., 2022; 2023; Park & Shen,

In this section, we detail our method, CP-Composer. We first introduce basic concepts of peptide modeling and cyclic strategies in Sec. 3.1 and specify these strategies as con- straints in Sec. 3.2. We further present the guided generation framework and the encoding strategy for incorporating the constraints in Sec. 3.3 and Sec. 3.4, respectively. We finally describe the training and inference schemes in Sec. 3.5. The overal workflow is depicted in Fig. 2.

2

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Figure 2. Overall training and inference design of CP-Composer. We define two unit constraints, type constraint and distance constraint (§ 3.2), which are incorporated into the diffusion model via geometric conditioning (§ 3.4). During training, the model learns from single unit constraints and their combinations observed in linear peptides. At inference, novel combinations corresponding to specific cyclization strategies are imposed with guidance signal amplified by classifier-free guidance, enabling zero-shot cyclic peptide design (§ 3.5).

3.1. Preliminaries

Representing peptide as geometric graph. We represent the binding site and peptide as a fully-connected geometric graph G = (V, E) where V is the set of nodes and E is the set of edges. Each node is a residue, binded with node features (hi, ⃗Xi) with hi ∈ Rm being the one-hot encoding of the amino acid type and ⃗Xi ∈ Rki×3 being the coordinate of the ki atoms.

Geometric latent diffusion model for peptide design. Our model is built on PepGLAD (Kong et al., 2024), a latent geometric diffusion model, but is adaptable to other diffusion-based frameworks. It employs a variational au- toencoder to project peptide graphs G into residue-level latents Gz = {(zi, ⃗zi)}N i=1 with an encoder Eϕ, and a cor- responding decoder Dξ for the inverse, where zi ∈ R8 is the E(3)-invariant latent and ⃗zi ∈ R3 is the E(3)-equivariant counterpart. A diffusion model is learned in the compact latent space, with the denoiser ϵθ(G(t) z , t) parameterized by an equivariant GNN (Kong et al., 2023). The sampling pro- cess initiates with latents G(T ) i=1 drawn from the prior and gradually denoises it using DDPM (Ho et al., 2020) sampler for a total of T steps. The final latents G(0) are decoded back to the data space using decoder Dξ. z

z = {(z(T )

, ⃗z(T ) i

)}N

i

Cyclic peptide and cyclization strategies. Unlike common linear peptides, which are chain-like structures, a cyclic pep- tide is formed by animo acids connected in a ring structure. As shown in Fig. 1, we primarily focus on four types of cyclic peptides in this paper: stapled, head-to-tail, disulfide and bicycle peptides. Each strategy applies constraints on

3

specific amino acid types and/or their pairwise distances. Taking the disulfide peptide as an example (Fig. 1C), to link two cysteines at indices i, j with a disulfur bond of length dS, a disulfide peptide is constrained by1

CDisulfide,i,j = ({ arg max(hi) = arg max(hj) = kC}, {∥ ⃗Xi − ⃗Xj∥2 = dS}),

(1)

where kC represents the index of cysteine (C) in the one- hot embeddings. This constraint can be decomposed into two node-level constraints on the amino acid types and one edge-level constraint on the distance. We refer to these as unit geometric constraints with further details on these constraints provided in Sec. 3.2. We demonstrate that all four cyclic strategies can be expressed as combinations of these unit geometric constraints in Appendix B.

3.2. Decomposing Cyclization Strategies as Geometric

Constraints

In this work, we consider two types of unit geometric con- straints, namely type constraint and distance constraint. In particular, type constraint operates on node-level by enforc- ing the node to be of certain type, while distance constraint takes place on edge-level, specifying a pair of nodes to reside at a certain distance. Definition 3.1 (Type constraint). A type constraint is a set CT := {(i, li)}i∈VT where each entry (i, li) represents that node i should be of type li, while VT ⊆ V is the set of nodes to enforce the type constraint.

1For simplicity, we slightly abuse the notation ∥ ⃗Xi − ⃗Xj∥2, where the distance is measured using the nodes’ Cα coordinates.

Sampled ConstraintsKAType ConstraintsKSSSCCCTarget ConstraintsLinear PeptideDistance ConstraintsCyclic PeptideNode EncodingsEdge EncodingsComposed EncodingsComposed EncodingsTrainingZero-shot GenerationOne-hot EncodingsRBF Encodings(





)AK++(







)CX3+Classifier-Free GuidanceZero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Definition 3.2 (Distance constraint). A distance constraint is a set CD := {(i, j, dij)}(i,j)∈ED where each element (i, j, dij) represents that node i and j should be positioned at the distance of dij, while ED ⊆ E is the set of edges to enforce the distance constraint.

Notably, our taxonomy of geometric constraints is particu- larly interesting due to its completeness, in the sense that each of the cyclic strategies C described in Sec. 3.1 can be decomposed into combinations of type constraints CT and/or distance constraints CD. We defer the detailed expla- nations to Appendix B.

Problem definition. We formulate the task of cyclic peptide design as finding the candidate peptides G that satisfy con- straint C, where C is any one of the four cyclic constraints.

3.3. Inverse Design with Diffusion Guidance

To perform inverse design, a widely adopted approach is to progressively inject certain guidance term into diffusion sampling towards the design target (Bao et al., 2022; Song et al., 2023), which share similar spirit as classifier guid- ance (Dhariwal & Nichol, 2021). Specifically, at each sam- pling step t, the conditional score is derived by Bayes’ rule: z |C) = ∇G(t) + ∇G(t)

log pt(G(t) z ) log pt(C|G(t)

log pt(G(t)

∇G(t)

z ),

(2)

z

z

z

log pt(C|G(t)

where the last term ∇G(t) z ) takes the effect as guidance, which can typically be a hand-crafted energy func- tion (Kawar et al., 2022; Song et al., 2024) or a pretrained neural network (Dhariwal & Nichol, 2021; Bao et al., 2022).

z

However, empirically the approach is often demonstrated unfavorable since the guidance term in Eq. 2 is the gra- dient of neural network, which detriments sample quality due to adversarial effect (Ho & Salimans, 2022). Distinct from the approach above, we propose an alternative that, inspired by classifier-free guidance, guides the sampling by directly composing unconditional and conditional score without additional gradient terms. In detail, we have,

˜ϵθ(G(t)

z , C, t) = (w + 1)ϵθ(G(t)

z , C, t) − wϵθ(G(t)

z , t) (3)

where w is the guidance weight and the guided score ˜ϵθ will replace ϵθ for score computation. In particular, the rationale of Eq. 2 and Eq. 3 are linked by the following distribution

˜pt(G(t)

z |C) ∝ pt(G(t)

z )pt(C|G(t)

z )w,

(4)

with the corresponding conditional score

z

∇G(t) =∇G(t) ≈ϵθ(G(t)

z

log ˜pt(G(t) log pt(G(t)

z |C) z ) + w∇G(t)

z

z , t) + w∇G(t)

z

log pt(C|G(t)

z ),

log pt(C|G(t)

z ).

(5)

4

By further leveraging the relation ∇G(t) z |C)−∇G(t) ∇G(t) ϵθ(G(t)

log pt(G(t) z , t) into Eq. 5, we obtain the expression in Eq. 3.

z ) ≈ ϵθ(G(t)

z ) = z , C, t)−

log pt(G(t)

log pt(C|G(t)

z

z

z

Conceptually, Eq. 2 adopts energy-guidance that di- rectly models log pt(C|G(t) z ) by an externally trained en- ergy function. Eq. 3 instead follows the convention in classifier-free guidance by rewriting ∇G(t) z ) = z |C)−∇G(t) z , C, t)− ∇G(t) ϵθ(G(t)

log pt(G(t) z ) ≈ ϵθ(G(t) z , t), which gives Eq. 3 after simplification.

log pt(C|G(t)

log pt(G(t)

z

z

z

In recent studies, how to obtain the conditional score ϵθ(G(t) z , C, t) still remains unclear. Notably, C is a com- plicated geometric constraint, which is fundamentally dif- ferent from a class label (Ho & Salimans, 2022) or a target value (Bao et al., 2022), where an embedding (e.g., one- hot for class label) can be readily adopted as the control signal to feed into the denoiser. In the following section, we will introduce our approach to encode type and distance constraint.

3.4. Encoding Constraints via Geometric Conditioning

To encode the constraints as control signals, we propose geometric conditioning that embeds the type and distance constraints into the denoiser through vectorization. Conditioning type constraints. For type constraint CT = {(i, li)}i∈VT where li ∈ {0, 1, · · · , K − 1} is the desired node type for node i, we operate at node-level by augment- ing the E(3)-invariant node feature hi with an additional vector li ∈ RK which serves as the control signal. This cor- responds to the encoding function fT (CT ) = {(i, li)}i∈VT that lifts li to the embedding space where

li =

(cid:40)

One-hot(li) 0

i ∈ VT , i ∈ V\VT .

(6)

Such design of the control signal is simple yet effective, since different type constraints will induce different signal li, thus making the constraints distinguishable to the network. More importantly, for any type constraint, the conditional score ϵθ(G(t) z , C, t) obtained by this means still enjoys E(3)- equivariance, since li is E(3)-invariant.

Conditioning distance constraints. For distance constraint CD := {(i, j, dij)}(i,j)∈ED where dij specifies the distance between node i and j, we instead design the encoding func- tion as fD(CD) = {(i, j, dij)}(i,j)∈ED , where the control signal dij is defined at edge-level:

(cid:40)

dij =

RBF(dij) ϕ

(i, j) ∈ ED, (i, j) ∈ E\ED.

(7)

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Here RBF(·) is the radial basis kernel that lifts the distance from a scalar to a high-dimensional vector (Sch¨utt et al., 2018), and ϕ denotes that the edges not in the set ED will not be featurized. The control signal dij is then viewed as a special type of edge feature, which will be further pro- cessed by an additional dyMEAN layer (Kong et al., 2023), whose input will be the subgraph (V, ED) with edge features {dij}(i,j)∈ED . More details are deferred to Appendix C.2. Akin to the analysis for type constraints, our way of encod- ing distance constraints also preserve the E(3)-equivariance of the conditional score, with proof in Appendix A.2.

Moreover, the encoding is also injective, as formally stated in Theorem 3.3. Such property is crucial for effective guid- ance since different constraints will be projected as different control signals, always making them distinguishable to the score network.

Theorem 3.3 (Injective). Both fT and fD are injective. That is, f (C1) = f (C2) if and only if C1 = C2, where (f, C1, C2) can be (fT , C1 D). := Furthermore, (fT (CT ), fD(CD)) is also injective.

T , C2 T ) or (fD, C1 function ˜f (CT , CD)

their product

D, C2

Composing type and distance constraints. Our approach of encoding the type and distance constraints in node- and edge-level respectively also facilitates conveniently com- posing them together. In particular, we can easily devise ϵθ(G(t) z , CT , CD, t) by simultaneous feeding the type and distance control signals in Eq. 6 and 7 into the score network, which corresponds to enforcing a compositional constraint (CT , CD). This extension is critical since it enables us to enforce richer combinations of the constraints at inference time, even generalizing to those unseen during training. In this way, we are able to design cyclic peptides with training data that only consist of linear peptides due to the general- ization capability of our approach.

3.5. Training and Inference

With the geometric conditioning technique to derive the conditional score, we are now ready to introduce the training and inference framework.

Design space for constraints. For a linear peptide G sam- pled from training set with features {(hi, ⃗Xi)}N i=1, we con- sider the following design space for type constraint:

CT (G) = {CT |CT = {(i, arg max(hi)}i∈VT , |VT | ≤ 4}, (8)

which include all of the type constraints that control the type of the node to be the same as that of node i in G and the number of constraints to be fewer or equal to 4. For distance

5

Algorithm 1 Training Procedure of CP-Composer Input: Data distribution D, mask probabilities for type and distance constraints pT , pD, encoder Eϕ, score network ϵθ, diffusion scheduler Scheduler(·) 1: while not converged do 2:

{c.f. Eq. 8-9}

Sample G ∼ D, CT ∼ Unif(CT (G)), and CD ∼ Unif(CD(G)) CT ← ∅ with probability pT CD ← ∅ with probability pD (ϵ, G(t) Take gradient step on L(θ) = ∥ϵ − ϵθ(G(t)

z , t) ← Scheduler(Eϕ(G))

z , CT , CD, t)∥2 2

3: 4:

5: 6:

7: end while

constraint, we select the following design space:

CD(G) = {CD|CD = {(i, j, ∥ ⃗Xi − ⃗Xj∥2)}(i,j)∈ED ,

dG(i, j) ∈ {3, 4, 6}, |ED| ≤ 6},

(9)

which spans across all possible distance constraints that specify the distance between node i and j to be their Eu- clidean distance in G, while the shortest path distance be- tween i and j, i.e., dG(i, j), equals to 3, 4, or 6. We design CT (G) and CD(G) such that CT (G) × CD(G) covers the con- straint space of cyclic peptides, where × is the Cartesian product. This permits our approach to generalize to novel compositions within the space CT (G) × CD(G) at inference time without necessarily seeing such particular combination in training data, e.g., the four compositional constraints of cyclic peptides.

Training. We employ a single network ϵθ to jointly opti- mize the conditional and unconditional score during training, following the paradigm in Ho & Salimans (2022). At each training step, we first sample G from training data distri- bution D and derive the candidate constraints CT (G) and CD(G). We then sample a type constraint CT and a distance constraint CD uniformly from the candidates CT (G) and CD(G), respectively. To jointly optimize the conditional and unconditional score networks, we replace CT and CD by empty set ∅ with probability pT and pD respectively, where the empty set will enforce no meaningful type and/or dis- tance control signal which degenerates to the unconditional score. Finally, we encode G into latent space by Eϕ, sample the noise ϵ and diffusion step t, and compute the noised latent G(t) z . The noise prediction loss (Ho et al., 2020) is adopted to train the score network. We present the detailed training procedure in Alg. 1.

Inference. At inference time, we will select one of the four cyclic constraints at one time. Each constraint is represented T and C∗ by (C∗ D are the target type and distance constraint, respectively. We start from the initial latent G(T ) sampled from the prior and perform standard

D) where C∗

T , C∗

z

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Table 1. Success rates and KL divergence for generated samples from different cyclization strategies.

Stapled peptide

Head-to-tail peptide

Succ.

AA-KL

B-KL

S-KL

Succ.

AA-KL

B-KL

S-KL

PepGLAD (Kong et al., 2024) w/ EG (Bao et al., 2022)

22.80% 25.41%

0.1035 0.0744

CP-Composer w = 0.0 CP-Composer w = 1.0 CP-Composer w = 2.0 +CADS (Sadat et al., 2024) CP-Composer w = 5.0 CP-Composer w = 10.0

0.0932 25.71% 0.1017 30.00% 0.1067 21.42% 27.14% 0.0807 38.57% 0.1812 0.3532 32.86%

1.1401 1.1821

1.1179 1.1235 1.0996 1.0975 1.1515 1.1726

0.0126 0.0127

0.0126 0.0161 0.0147 0.0119 0.0180 0.0232

30.23% 61.63%

0.1052 0.0798

0.1021 37.21% 0.1008 55.81% 0.1055 65.11% 45.54% 0.0798 74.42% 0.1320 0.1784 68.60%

1.1347 1.0891

1.0787 1.0604 1.1005 1.0589 1.0523 1.0301

0.0125 0.0128

0.0118 0.0124 0.0126 0.0132 0.0122 0.0175

Disulfide peptide

Bicycle peptide

Succ.

AA-KL

B-KL

S-KL

Succ.

AA-KL

B-KL

S-KL

PepGLAD (Kong et al., 2024) w/ EG (Bao et al., 2022)

0 0

0.0808 0.0711

CP-Composer w = 0.0 CP-Composer w = 1.0 CP-Composer w = 2.0 +CADS (Sadat et al., 2024) CP-Composer w = 5.0 CP-Composer w = 10.0

0.1016 7.50% 0.1477 21.25% 0.2873 41.25% 0.0939 3.75% 82.50% 0.5139 1.6965 62.50%

1.1324 1.0891

1.1062 1.0939 1.0994 1.0788 1.0397 4.0312

0.0124 0.0103

0.0151 0.0151 0.0379 0.0162 0.1913 1.1046

0 0

0.0838 0.0729

0.1225 0 0.1638 11.53% 0.2147 30.76% 3.85% 0.0901 84.62% 0.3385 1.2677 38.46%

1.1823 1.0968

1.1980 1.1490 1.1195 1.0624 1.0759 8.1935

0.0238 0.0228

0.0252 0.0395 0.0735 0.0684 0.3351 0.3374

Algorithm 2 Inference Procedure of CP-Composer Input: Target type and distance constraint (C∗ T , C∗ D), dif- fusion sampler Sampler(·), guidance weight w, step T , score network ϵθ, decoder Dξ 1: Initialize latents G(T ) 2: for t = T, T − 1, · · · , 1 do 3:

from prior

z , C∗

z

D, t) −

T , C∗

Compute score ˜ϵ ← (w + 1)ϵθ(G(t) wϵθ(G(t) z , ∅, ∅, t) {Eq. 10} z ← Sampler(G(t) G(t−1) 4: 5: end for Return: Dξ(G(0) z )

z , ˜ϵ, t)

{Denoising step}

diffusion sampling with the guided score:

˜ϵ(G(t)

z , C∗

T , C∗

D, t) =(w + 1)ϵθ(G(t)

T , C∗

z , C∗ z , ∅, ∅, t),

D, t)

(10)

− wϵθ(G(t)

where a modified classifier-free guidance is employed to further amplify the guidance signal. The sample is acquired by decoding G(0) z back to the data space using the decoder Dξ. The inference procedure is depicted in Alg. 2.

4. Experiments

Task. We evaluate CP-Composer on target-specific cyclic peptide design, aiming to co-design the sequence and the binding structure of cyclic peptides given the binding site on the target protein.

Dataset. We utilize PepBench and ProtFrag datasets (Kong et al., 2024) for training and validation, with the LNR

6

dataset (Kong et al., 2024; Tsaban et al., 2022) for test- ing. PepBench contains 4,157 protein-peptide complexes for training and 114 complexes for validation, with a target protein longer than 30 residues and a peptide binder between 4 to 25 residues. ProtFrag encompasses 70,498 synthetic samples resembling protein-peptide complexes, which are extracted from local contexts in protein monomers. LNR consists of 93 protein-peptide complexes curated by domain experts, with peptide lengths ranging from 4 to 25 residues.

We evaluate zero-shot cyclic peptide generation in Sec. 4.1, demonstrate the flexibility of composable geometric con- straints with high-order multi-cycle constraints in Sec. 4.2, and assess the stability and binding affinity of the generated cyclic peptides through molecular dynamics in Sec. 4.3.

4.1. Zero-Shot Cyclic Peptide Generation

Metrics. We evaluate the generated peptides based on two key aspects: cyclic constraint satisfaction and generation quality. For each target protein in the test set, we generate five candidate peptides and compute the following metrics. Success Rate (Succ.) measures the proportion of target proteins for which at least one of the five generated peptides satisfies the geometric constraints of the specified cycliza- tion strategy. Amino Acid Divergence (AA-KL) calculates the Kullback–Leibler (KL) divergence between the amino acid composition of reference peptides and all of the gen- erated samples. For cyclization patterns that impose amino acid constraints at specific positions, we exclude these con- strained amino acid types when computing the distributions, as successful designs inherently deviate from the reference distribution on these amino acid types. Backbone Dihe-

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

able geometric constraints. In Table 3, we further compare CP-Composer with DiffPepBuilder (Wang et al., 2024a). Although DiffPepbuilder is a method specifically designed for disulfide peptide generation, CP-Composer shows a bet- ter success rates than DiffPepbuilder. These results show the effectiveness of CP-Composer. We visualize examples of generated peptides for each cyclization strategy in Fig. 3, with more cases in Appendix E. Furthermore, the weight parameter w effectively balances success rates and gen- eration quality, with increasing control strength yielding higher constraint satisfaction yet slightly higher KL diver- gence, indicating a trade-off between constraint satisfaction and distributional fidelity. This flexibility allows users to customize the method based on specific application needs, prioritizing either higher success rates or closer resemblance to natural peptide distributions.

4.2. Flexibility in High-Order Combinations

Figure 4. Generated peptides conforming to high-order combina- tions of cyclizations, with the red boxes highlighting the positions for cyclization.

Setup. To demonstrate the flexibility of our framework in handling composable geometric constraints, we investigate more complex and customized scenarios that involve mul- tiple cyclizations within a single peptide. Specifically, we explore the following high-order combinations: 2*Stapled has two stapled pairs in one peptide. -S-S- + H-T includes one disulfide bond and one head-to-tail in one peptide; 2*- S-S- contains two disulfide bonds in one peptide; 3*-S-S- involves three disulfide bonds in one peptide; The flexibility of CP-Composer enables seamless implementation of these complex constraints: simply combining the individual unit constraints for each cyclization strategy allows the model to accommodate them simultaneously.

Results. As shown in Table 2, despite the increasing com- plexity of the constraints, CP-Composer achieves reasonable

7

Figure 3. Four types of generated cyclic peptides, with the red boxes highlighting the position for cyclization.

dral Angle Divergence (B-KL) and Side-Chain Dihedral Angle Divergence (S-KL) indicate the KL divergence be- tween the distribution of the dihedral angles in reference peptides and the generated samples, assessing rationality in the generated backbone and side chains, respectively.

Baselines. First, we compare our CP-Composer with the backbone model PepGLAD (Kong et al., 2024) without ad- ditional guidance to validate the effectiveness of our frame- work with composable geometric constraints. We further im- plement a baseline with the prevailing Energy-based Guid- ance (EG) (Dhariwal & Nichol, 2021; Bao et al., 2022) applied to node embeddings and pairwise distances to as- sess the advantages of our approach, with implementation details in Appendix C. To compare CP-Composer with other cyclic peptide generation method, we implement DiffPep- Builder (Wang et al., 2024a), a model specifically designed for disulfide peptides. Furthermore, we also incorperate our method with a advanced sampler Condition Annealed Dif- fusion Sampler(CADS) (Sadat et al., 2024) to analysis the performance of our method combining with other sampler.

Results. As shown in Table 1, CP-Composer significantly improves constraint satisfaction rates across all cyclization strategies compared to unguided baselines, while maintain- ing fidelity to reference distributions in amino acid com- position and structural dihedral angles. The energy-guided baseline proves effective in simple cases requiring control over a single pairwise distance (i.e., head-to-tail cycliza- tion), but struggles with more complex scenarios involving combinations of distance constraints and type constraints. This limitation is evident from its lower success rates on stapled peptides and complete failure in handling more in- tricate cyclization patterns including disulfide and bicycle peptides. In contrast, CP-Composer consistently achieves high success rates across these challenging cases, demon- strating the strength of our framework design with compos-

Stapled PeptideHead-To-Tail PeptideDisulfide PeptideBicycle Peptide-S-S-+ Head-to-Tail-S-S-+ -S-S--S-S-+ -S-S-+ -S-S-Stapled + StapledZero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Figure 5. RMSD trajectories from 100 ns molecular dynamics simulations for two target proteins, each bound to either a native linear peptide binder or a cyclic peptide generated by our model. The target proteins and their corresponding linear peptide binders are derived from PDB 3RC4 (top) and PDB 4J86 (bottom), respectively.

success rates across all high-order cyclization scenarios. The control strength parameter w remains effective, with higher values leading to enhanced success rates. The only excep- tion is 2*Stapled, likely due to the inherent difficulty of the Staple strategy, which already exhibits the lowest success rate in Table 1. This indicates that our framework effectively learns to generate peptides that conform to the joint distribu- tion of multiple constraints. Fig. 4 visualizes peptides with these high-order cyclization patterns, highlighting the flex- ibility of CP-Composer in designing structurally feasible peptides tailored for customized requirements.

Table 2. Success rates for high-order combinations of multiple cyclizations within the same peptide.

2*Stapled

-S-S-+H-T

2*-S-S-

3*-S-S-

w = 1.0 w = 2.0 w = 2.5 w = 3.0

2.5% 7.5% 7.5% 7.5%

0 10.0% 20.0% 26.0%

0 0 26.0% 17.2% 34.5% 34.0% 62.0% 65.5%

Table 3. Success rates comparison between DiffPepBuilder and our method Succ.

Disulfide Peptide

2*-S-S-

CP-Composer DiffPepBuilder (Wang et al., 2024a)

41.25% 23.07%

62.00% 32.78%

In Table 3, we compare CP-Composer with DiffPepBuilder. The results show that our method outperform the cycplic peptide generation model under high-order cyclization sce- nario: two disulfide bonds in one peptide. This indicates the flexibility of our framework.

8

4.3. Evaluations by Molecular Dynamics

Setup. We perform molecular dynamics (MD) simulations using the Amber22 package (Salomon-Ferrer et al., 2013) to compare the stability and binding affinity of linear pep- tides from the test set with cyclic peptides generated by our model. We use the ff14SB force field for proteins and pep- tides (Maier et al., 2015) with all systems solvated in water, and 150 nM Na+/Cl− counterions are added to neutralize charges and simulate the normal saline environment (Jor- gensen et al., 1983; Li et al., 2024c). The SHAKE algorithm is applied to constrain covalent bonds involving hydrogen atoms (Ryckaert et al., 1977), while non-bonded interac- tions are truncated at 10.0 ˚A, with long-range electrostatics treated using the PME method. To estimate peptide binding energies, we further employ MM/PBSA calculations (Gen- heden & Ryde, 2015). Notably, while MD simulations provide high accuracy in evaluating conformational stability and binding affinity, they are very computationally expen- sive. Therefore, we randomly select two target proteins from the test set and generate one cyclic peptide using head-to- tail and disulfide bond cyclization strategies for evaluation. More details on the setup of MD are in Appendix C.3.

Results. As shown in Fig. 5, the root mean square deviation (RMSD) trajectories of the two linear peptides from the test set exhibit significant fluctuations, indicating vibrate binding conformations. In contrast, the RMSD trajectories of the cyclic peptides generated by our model are quite flat, producing consistently lower RMSD compared to the linear peptides, suggesting that the introduced geometric constraints effectively enhance conformational stability. Ta- ble 4 presents the average RMSD values with standard devi- ations, along with the binding affinity (∆G) estimated via

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Table 4. RMSD trajectories from molecular dynamics after 50 ns (average values and standard deviations), along with binding affini- ties (∆G) estimated by running simulations with MM/PBSA.

Peptide

RMSD ( ˚A) ∆G-MM/PBSA (kcal/mol)

PDB: 3RC4

Linear (test set) Cyclic (ours)

2.57±0.51 1.44±0.23

PDB: 4J86

Linear (test set) Cyclic (ours)

3.37±0.73 1.56±0.40

-9.73 -10.66

-15.17 -20.41

MM/PBSA simulations. The results indicate that cyclic pep- tides achieve significantly stronger binding affinities than their linear counterparts, thanks to their enhanced stability in the binding conformations.

4.4. Generalization beyond Available Data

In Fig. 6, we visualize the structural embeddings of peptides generated under different cyclization strategies, along with linear peptides from the test set, using ESM2-650M(Lin et al., 2023) and T-SNE (Van der Maaten & Hinton, 2008). The results reveal distinct clusters corresponding to different cyclization strategies, all of which are clearly separated from the linear peptides. This indicates that CP-Composer gener- alizes well beyond the available data, effectively exploring unseen regions of cyclic peptides.

Figure 6. T-SNE visualization of ESM embeddings for peptides in the test set and those generated with different cyclization strategies.

5. Conclusion

able strategies. Our framework offers a principled approach to cyclic peptide design, with potential extensions to broader biomolecular applications involving geometric constraints.

Acknowledgements

This work is jointly supported by the National Key R&D Program of China (No.2022ZD0160502), the National Natural Science Foundation of China (No. 61925601, No. 62376276, No. 62276152), Beijing Nova Program (20230484278), China’s Village Science and Technology City Key Technology funding, Beijing Natural Science Foundation (No. QY24249) and Wuxi Research Institute of Applied Technologies.

Impact Statement

This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

References

Anand, N. and Achim, T. Protein structure and sequence generation with equivariant denoising diffusion proba- bilistic models. arXiv preprint arXiv:2205.15019, 2022. 2

Bao, F., Zhao, M., Hao, Z., Li, P., Li, C., and Zhu, J. Equiv- ariant energy-guided sde for inverse molecular design. arXiv preprint arXiv:2209.15408, 2022. 2, 4, 6, 7

Bertsekas, D. P. Constrained optimization and Lagrange

multiplier methods. Academic press, 2014. 14

Dhariwal, P. and Nichol, A. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34:8780–8794, 2021. 2, 4, 7

Fosgerau, K. and Hoffmann, T. Peptide therapeutics: current status and future directions. Drug discovery today, 20(1): 122–128, 2015. 1

Genheden, S. and Ryde, U. The mm/pbsa and mm/gbsa methods to estimate ligand-binding affinities. Expert opinion on drug discovery, 10(5):449–461, 2015. 8, 15

We introduce CP-Composer, a generative framework that enables zero-shot cyclic peptide design via composable ge- ometric constraints. By decomposing complex cyclization patterns into unit constraints, it circumvents the limitation of data, achieves high success rates while preserving fidelity to natural distributions of type and structural statistics, and allows for high-order combinations of cyclization patterns, enabling the design of multi-cycle peptides with customiz-

Goldenthal, R., Harmon, D., Fattal, R., Bercovier, M., and Grinspun, E. Efficient simulation of inextensible cloth. In ACM SIGGRAPH 2007 papers, pp. 49–es. 2007. 14

Han, J., Cen, J., Wu, L., Li, Z., Kong, X., Jiao, R., Yu, Z., Xu, T., Wu, F., Wang, Z., et al. A survey of geomet- ric graph neural networks: Data structures, models and applications. arXiv preprint arXiv:2403.00485, 2024a. 2

9

Stapled peptideHead-to-tail peptideDisulfide peptideBicycle peptideLinear peptide (test set)Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Han, J., Xu, M., Lou, A., Ye, H., and Ermon, S. Geometric trajectory diffusion models. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024b. URL https://openreview.net/forum? id=OYmms5Mv9H. 2

Ho, J. and Salimans, T. Classifier-free diffusion guidance.

arXiv preprint arXiv:2207.12598, 2022. 2, 4, 5

Ho, J., Jain, A., and Abbeel, P. Denoising diffusion proba- bilistic models. Advances in neural information process- ing systems, 33:6840–6851, 2020. 3, 5

Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D. J. Video diffusion models. Advances in Neural Information Processing Systems, 35:8633–8646, 2022. 2

Hosseinzadeh, P., Watson, P. R., Craven, T. W., Li, X., Ret- tie, S., Pardo-Avila, F., Bera, A. K., Mulligan, V. K., Lu, P., Ford, A. S., et al. Anchor extension: a structure-guided approach to design cyclic peptides targeting enzyme ac- tive sites. Nature Communications, 12(1):3384, 2021. 2

Huang, L., Chen, D., Liu, Y., Shen, Y., Zhao, D., and Zhou, J. Composer: Creative and controllable image synthesis with composable conditions. arXiv preprint arXiv:2302.09778, 2023. 2

Ji, X., Nielsen, A. L., and Heinis, C. Cyclic peptides for drug development. Angewandte Chemie International Edition, 63(3):e202308251, 2024. 1

Jiang, E., Peng, J., Ma, Z., and Yan, X.-B. Ode-dps: Ode-based diffusion posterior sampling for inverse prob- arXiv preprint lems in partial differential equation. arXiv:2404.13496, 2024. 2

Jorgensen, W. L., Chandrasekhar, J., Madura, J. D., Impey, R. W., and Klein, M. L. Comparison of simple potential functions for simulating liquid water. The Journal of chemical physics, 79(2):926–935, 1983. 8, 15

Kawar, B., Elad, M., Ermon, S., and Song, J. Denoising diffusion restoration models. Advances in Neural Infor- mation Processing Systems, 35:23593–23606, 2022. 2, 4

Kong, X., Huang, W., and Liu, Y. End-to-end full-atom antibody design. arXiv preprint arXiv:2302.00203, 2023. 3, 5, 13, 15

Kong, X., Jia, Y., Huang, W., and Liu, Y. Full-atom pep- tide design with geometric latent diffusion, 2024. URL https://arxiv.org/abs/2402.13555. 1, 2, 3, 6, 7, 14, 15

Lee, A. C.-L., Harris, J. L., Khanna, K. K., and Hong, J.-H. A comprehensive review on current advances in peptide drug development and design. International journal of molecular sciences, 20(10):2383, 2019. 1

Li, J., Chen, T., Luo, S., Cheng, C., Guan, J., Guo, R., Wang, S., Liu, G., Peng, J., and Ma, J. Hotspot-driven peptide design via multi-fragment autoregressive extension. arXiv preprint arXiv:2411.18463, 2024a. 1

Li, J., Cheng, C., Wu, Z., Guo, R., Luo, S., Ren, Z., Peng, J., and Ma, J. Full-atom peptide design based on multi- modal flow matching. In Forty-first International Confer- ence on Machine Learning, 2024b. 1, 2

Li, M., Lan, X., Shi, X., Zhu, C., Lu, X., Pu, J., Lu, S., and Zhang, J. Delineating the stepwise millisecond allosteric activation mechanism of the class c gpcr dimer mglu5. Nature Communications, 15(1):7519, 2024c. 8, 15

Lin, H., Zhang, O., Zhao, H., Jiang, D., Wu, L., Liu, Z., Huang, Y., and Li, S. Z. Ppflow: Target-aware peptide design with torsional flow matching. In Forty-first In- ternational Conference on Machine Learning, 2024. 1, 2

Lin, Z., Akin, H., Rao, R., Hie, B., Zhu, Z., Lu, W., Smetanin, N., Verkuil, R., Kabeli, O., Shmueli, Y., et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science, 379(6637): 1123–1130, 2023. 9

Liu, N., Li, S., Du, Y., Torralba, A., and Tenenbaum, J. B. Compositional visual generation with composable dif- fusion models. In European Conference on Computer Vision, pp. 423–439. Springer, 2022. 2

Luo, S., Su, Y., Peng, X., Wang, S., Peng, J., and Ma, J. Antigen-specific antibody design and optimization with diffusion-based generative models for protein struc- tures. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/ forum?id=jSorGn2Tjg. 2

Maier, J. A., Martinez, C., Kasavajhala, K., Wickstrom, L., Hauser, K. E., and Simmerling, C. ff14sb: improving the accuracy of protein side chain and backbone parameters from ff99sb. Journal of chemical theory and computation, 11(8):3696–3713, 2015. 8, 15

Park, J. and Shen, Y. Equivariant blurring diffusion for hier- archical molecular conformer generation. arXiv preprint arXiv:2410.20255, 2024. 2

Rettie, S., Juergens, D., Adebomi, V., Bueso, Y. F., Zhao, Q., Leveille, A., Liu, A., Bera, A., Wilms, J., ¨Uffing, A., et al. Accurate de novo design of high-affinity protein

10

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

binding macrocycles using deep learning. bioRxiv, pp. 2024–11, 2024. 1, 2

Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. High-resolution image synthesis with latent diffusion models. 2022 ieee. In CVF Conference on Com- puter Vision and Pattern Recognition (CVPR), volume 1, 2021. 2

Ryckaert, J.-P., Ciccotti, G., and Berendsen, H. J. Numerical integration of the cartesian equations of motion of a sys- tem with constraints: molecular dynamics of n-alkanes. Journal of computational physics, 23(3):327–341, 1977. 8, 15

Sadat, S., Buhmann, J., Bradley, D., Hilliges, O., and We- ber, R. M. Cads: Unleashing the diversity of diffusion models through condition-annealed sampling, 2024. URL https://arxiv.org/abs/2310.17347. 6, 7

Salomon-Ferrer, R., Gotz, A. W., Poole, D., Le Grand, S., and Walker, R. C. Routine microsecond molecular dynam- ics simulations with amber on gpus. 2. explicit solvent particle mesh ewald. Journal of chemical theory and computation, 9(9):3878–3888, 2013. 8, 15

Satorras, V. G., Hoogeboom, E., and Welling, M. E (n) equivariant graph neural networks. In International con- ference on machine learning, pp. 9323–9332. PMLR, 2021. 2

Sch¨utt, K. T., Sauceda, H. E., Kindermans, P.-J., Tkatchenko, A., and M¨uller, K.-R. Schnet–a deep learn- ing architecture for molecules and materials. The Journal of Chemical Physics, 148(24), 2018. 5, 13

Song, B., Kwon, S. M., Zhang, Z., Hu, X., Qu, Q., and Shen, L. Solving inverse problems with latent diffu- sion models via hard data consistency. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum? id=j8hdRqOUhN. 2, 4

Song, J., Meng, C., and Ermon, S. Denoising diffu- In International Conference on sion implicit models. Learning Representations, 2021a. URL https:// openreview.net/forum?id=St1giarCHLP. 2

Song, J., Zhang, Q., Yin, H., Mardani, M., Liu, M.-Y., Kautz, J., Chen, Y., and Vahdat, A. Loss-guided diffu- sion models for plug-and-play controllable generation. In International Conference on Machine Learning, pp. 32483–32498. PMLR, 2023. 4

Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Er- mon, S., and Poole, B. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020. 2

Song, Y., Shen, L., Xing, L., and Ermon, S. Solving inverse problems in medical imaging with score-based generative models. arXiv preprint arXiv:2111.08005, 2021b. 2

Swanson, S., Sivaraman, V., Grigoryan, G., and Keating, A. E. Tertiary motifs as building blocks for the design of protein-binding peptides. Protein Science, 31(6):e4322, 2022. 2

Tsaban, T., Varga, J. K., Avraham, O., Ben-Aharon, Z., Khramushin, A., and Schueler-Furman, O. Harnessing protein folding neural networks for peptide–protein dock- ing. Nature communications, 13(1):176, 2022. 6

Van der Maaten, L. and Hinton, G. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008. 9

Wang, F., Wang, Y., Feng, L., Zhang, C., and Lai, L. Target- specific de novo peptide binder design with diffpep- builder, 2024a. URL https://arxiv.org/abs/ 2405.00128. 7, 8

Wang, F., Wang, Y., Feng, L., Zhang, C., and Lai, L. Target- specific de novo peptide binder design with diffpepbuilder. Journal of Chemical Information and Modeling, 2024b. 1, 2

Watson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., Ahern, W., Borst, A. J., Ragotte, R. J., Milles, L. F., et al. De novo design of protein struc- ture and function with rfdiffusion. Nature, 620(7976): 1089–1100, 2023. 2

Xu, M., Yu, L., Song, Y., Shi, C., Ermon, S., and Tang, J. Geodiff: A geometric diffusion model for molecular conformation generation. In International Conference on Learning Representations, 2022. URL https:// openreview.net/forum?id=PzcvxEMzvQC. 2

Xu, M., Powers, A., Dror, R., Ermon, S., and Leskovec, J. Geometric latent diffusion models for 3d molecule gener- ation. In International Conference on Machine Learning. PMLR, 2023. 2

Yang, S., He, X., and Zhu, B. Learning physical constraints with neural projections. Advances in Neural Information Processing Systems, 33:5178–5189, 2020. 14

Ye, H., Lin, H., Han, J., Xu, M., Liu, S., Liang, Y., Ma, J., Zou, J., and Ermon, S. TFG: Unified training-free guid- ance for diffusion models. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. URL https://openreview.net/forum? id=N8YbGX98vc. 14

Yim, J., Trippe, B. L., De Bortoli, V., Mathieu, E., Doucet, A., Barzilay, R., and Jaakkola, T. Se (3) diffusion model

11

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

with application to protein backbone generation. arXiv preprint arXiv:2302.02277, 2023. 2

Zhang, H. and Chen, S. Cyclic peptide drugs approved in the last two decades (2001–2021). RSC Chemical Biology, 3 (1):18–31, 2022. 1

Zorzi, A., Deyle, K., and Heinis, C. Cyclic peptide ther- apeutics: past, present and future. Current opinion in chemical biology, 38:24–29, 2017. 1

12

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

A. Proofs

A.1. Proof of Theorem 3.3

For clarity, we restate Theorem 3.3 below. Proposition 3.3 (Injective). Both fT and fD are injective. That is, f (C1) = f (C2) if and only if C1 = C2, where D). Furthermore, their product function ˜f (CT , CD) := (fT (CT ), fD(CD)) (f, C1, C2) can be (fT , C1 is also injective.

T ) or (fD, C1

D, C2

T , C2

To prove Theorem 3.3, we first prove the following lemma. Lemma A.2. If g : RJ (cid:55)→ RK is injective, then f (X) = {(i, g(ki))}i∈VX is also injective, where X = {(i, ki)}i∈VX .

Proof. f (X1) = f (X2) ⇐⇒ {(i, g(k1 VX ⇐⇒ VX1 = VX2 := VX, k1 deduction step leverages the injectivity of function g.

i ))}i∈VX1 = {(i, g(k2 i , ∀i ∈ VX ⇐⇒ {(i, k1

i = k2

i ))}i∈VX2 ⇐⇒ VX1 = VX2 := VX, g(k1 i )}i∈VX1 = {(i, k2

i ), ∀i ∈ i )}i∈VX2 ⇐⇒ X1 = X2, where the third

i ) = g(k2

Now we are ready to prove Theorem 3.3.

Proof. We first prove the injectivity of fT . We choose g to be the one-hot encoding function One-hot(·) : R (cid:55)→ RK. It is straightforward that this function is injective. By leveraging Lemma A.2, the proof is completed. For the injectivity of fD, similarly we instantiate g as the RBF feature map ϕ(·) : R (cid:55)→ R∞. Such map is injective, since ∥ϕ(d1) − ϕ(d2)∥2 =< d1, d1 > + < d2, d2 > −2 < d1, d2 >= 1 + 1 − 2 exp(−γ∥d1 − d2∥2), which implies ϕ(d1) = ϕ(d2) ⇐⇒ d1 = d2, hence injectivity. By leveraging Lemma A.2, the proof is completed.2 T ), fD(C1 Since both fT and fD are injective, (fT (C1 T = C2 fD(C2 (fT (CT ), fD(CD)) is also injective, which concludes the proof.

D) = D). Therefore the product function ˜f (CT , CD) :=

D)) = (fT (C2 D) = (C2

D)) ⇐⇒ fT (C1

D) ⇐⇒ C1

D ⇐⇒ (C1

T ) = fT (C2

T ), fD(C1

T ), fD(C2

D = C2

T , C1

T , C1

T , C2

A.2. Equivariance

Proposition A.3 (Equivariance). The conditional score ϵθ(G(t)

z , C, t) is E(3)-equivariant, where C is CT or CD.

The proof is straightforward since our encodings of CT and CD are both E(3)-invariant, therefore the E(3)-equivariance of the score is preserved, following the proof in Kong et al. (2023).

B. Decompositions of Cyclic Strategies

As illustrated in Fig. 1, cyclic peptides are looped by four strategies, each of which can be decomposed into unit geometric constraints defined in Sec. 3.2 as follows. Specifically, the pair (i, li) indicates a type constraint that node i is required to be type li, and the triplet (i, j, dij) means a distance constraint that the pairwise distance between node i, j should be dij.

Stapled peptide. Given a lysine (K) located at index i, a stapled peptide can be formed via a covalent linkage between the lysine and either an aspartic acid (D) at i + 3, with constraints as

CStapled-D,i = ({(i, K), (i + 3, D)}, {(i, i + 3, dKD)}),

or a glutamic acid (E) at i + 4, with constraints as

CStapled-E,i = ({(i, K), (i + 4, E)}, {(i, i + 4, dKE)}),

(11)

(12)

where dKD, dKE are the lengths of covalent linkages between the K-D and K-E pairs, respectively.

2In practice we truncate the infinite-dimensional feature space by setting a limit on the number of bases, similar to Sch¨utt et al. (2018).

13

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Head-to-tail peptide. Given a peptide composed of N amino acids indexed by 0, 1, · · · , N − 1, an additional amide bond is linked between the head and tail amino acid as

CHead-to-tail = ({}, {(0, N − 1, dP )}),

(13)

where dP is the length of the amide bond.

Disulfide peptide. Connecting two non-adjacent cysteines (C) at i, j with a disulfur bond, a disulfide peptide is constrained by

where dS is the length of the disulfur bond.

CDisulfide,i,j = ({(i, C), (j, C)}, {(i, j, dS)}),

Bicycle peptide To link the three cysteines (C) at i, j, k, a bicycle peptide is constrained by

CBicycle,i,j,k = ({(i, C), (j, C), (k, C)}, {(i, j, dT ), (i, k, dT ), (j, k, dT )}),

where dT is the side length of the equilateral triangle formed by the centered 1,3,5-trimethylbenezene.

(14)

(15)

C. Implementation Details

C.1. Energy-based classifier guidance

With the definition of the geometric constraints, we now introduce their corresponding energy function, a scalar function that evaluates the satisfaction of the constraint given the input geometric graph. Definition C.1 (Energy function of a constraint). An energy function of constraint C is a differentiable function gC(·) : X (cid:55)→ R≥0, such that gC(G) = 0 if G ∈ X satisfies the constraint C and gC(G) ̸= 0 otherwise.

Intuitively, the energy function serves as an indicator of constraint satisfaction, following the conventional way of handling equality constraints (Bertsekas, 2014).

One naive way to tackle inverse problem is to directly optimize the energy function (Yang et al., 2020; Goldenthal et al., 2007) of the constraint with respect to the initial latents G(T ) z , since its minima correspond to the data points G that satisfy the constraint. However, the large number of sampling steps T required by diffusion models makes the optimization computationally prohibitive, as the gradient needs to be backpropagated through the denoiser T times. Moreover, the energy function is not guaranteed to be convex, which further troubles the optimization.

Energy-based classifier guidance has been introduced to inject constraint as guidance of diffusion sampling in a soft and iterative manner. In our setting, we can pair up pt(C|Gz) and the energy function through Boltzmann distribution, i.e., pt(C|Gz) = exp(−gC(Dξ(Gz))/Z, where Z is the normalizing constant. In this way, we have,

∇Gz log pt(Gz|C) = ∇Gz log pt(Gz) − w∇Gz gC(Dξ(Gz)),

(16)

where w ∈ R is added to control the guidance strength. Performing such sampling procedure is equivalent to sampling from the posterior (Ye et al., 2024):

p(Gz|C) := p(Gz) exp(−wgC(Dξ(Gz)))/Z,

(17)

which concentrates the density more on the regions with lower energy function value, biasing the sampling towards data points better satisfying the constraint C = (CT , CD).

In our implementation, we adopt the guidance function in Kong et al. (2024) as the energy function gC. In particular, the choice of w significantly influences the generation quality. A larger w typically enhances control strength but degrades generation quality when becoming excessively large. To strike a balance between controllability and quality, we conduct a sweep across various w values and ultimately employ w ∈ {10, 30, 50} for energy-based classifier guidance. The best performance across different w values is reported for all conditions.

14

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

C.2. Distance Constraints as Edge-Level Control

To inject the edge-level control into the model, we apply the adapter mechanism by adding an additional dyMEAN block (Kong et al., 2023) to each layer, and changing the message passing process into

{(h(l+0.5) i {(h(l+1) i

, ⃗X (l+0.5) i , ⃗X (l+1) i

)}i∈V = AME({(h(l) i )}i∈V = AME({(h(l+0.5)

, ⃗X (l)

i

i )}i∈V , {dij}(i,j)∈ED , ED), , ⃗X (l+0.5) i

)}i∈V , ∅, E),

(18)

(19)

where ED ⊆ E is the set of constrained edges, and AME is the Adaptive Multi-Channel Equivariant layer proposed in Kong et al. (2023). Readers are referred to the original paper for further details.

C.3. Molecular Dynamics

We perform molecular dynamics (MD) simulations to assess the stability and binding affinity of linear peptides from the test set and cyclic peptides generated by our model. Simulations are conducted using the Amber22 package with the CUDA implementation of particle-mesh Ewald (PME) MD and executed on GeForce RTX 4090 GPUs (Salomon-Ferrer et al., 2013). For system preparation, the ff14SB force field is applied to proteins and peptides (Maier et al., 2015). All systems are solvated to a 10 ˚A truncated octahedron transferable intermolecular potential three-point (TIP3P) water box and 150 nM Na+/Cl− counterions are added to neutralize charges and simulate the normal saline environment (Jorgensen et al., 1983; Li et al., 2024c). Prior to equilibration, two rounds of energy minimization are performed: the first relaxes solvent molecules and Na+/Cl− counterions while keeping all other atoms fixed, and the second relaxes all atoms without constraints. The systems are then gradually heated from 0 K to 310 K over 500 ps under harmonic restraints of 10 kcal · mol−1 · ˚A on proteins and peptides. Subsequently, equilibration is carried out at 300 K and 1 bar under NPT conditions, with harmonic −2 restraints on protein and ligand atoms progressively reduced from 5.0 to 3.0, 1.0, 0.5, and finally 0.1 kcal · mol−1 · ˚A spanning a total of 2.5 ns. Production simulations are performed with temperature (300 K) and pressure (1 bar) using the Langevin thermostat and Berendsen barostat, respectively. The SHAKE algorithm is applied to constrain covalent bonds involving hydrogen atoms (Ryckaert et al., 1977), while non-bonded interactions are truncated at 10.0 ˚A, with long-range electrostatics treated using the PME method. To estimate peptide binding energies, we further employ MM/PBSA calculations (Genheden & Ryde, 2015). While MD simulations provide high accuracy in evaluating conformational stability and binding affinity, they are computationally expensive. Therefore, we randomly select two target proteins from the test set and generate one cyclic peptide using head-to-tail and disulfide bond cyclization strategies for evaluation.

−2

C.4. Hyperparamter details

We train CP-Composer on a 24G memory RTX 3090 GPU with AdamW optimizer. For the autoencoder, we train for up to 100 epochs and save the top 10 models based on validation performance. We ensure that the total number of edges (scaling with the square of the number of nodes) does not exceed 60,000. The initial learning rate is set to 10−4 and is reduced by a factor of 0.8 if the validation loss does not improve for 5 consecutive epochs. Regarding the diffusion model, we train for no more than 1000 epochs. The learning rate is 10−4 and decay by 0.6 and early stop the training process if the validation loss does not decrease for 10 epochs. During the training process, we set the guidance strength as 1 for sampling at the validation stage. The structure details of the autoencoder and the diffusion model are the same as Kong et al. (2024). For the RBF kernel, we use 32 feature channels.

D. Further Analysis

D.1. Necessity of RBFs

We evaluate the influence of the RBFs to the quality of the generation of peptide under most difficult setting: Bicycle peptide (26 samples in test set). In Table 5, Based on the validation and parameter sensitivity study, we can conclude the necessity of RBF design to support the distance control. Further, an saturation beyond 16 channels is observed, indicating that finite RBFs is enough for empirical performance.

D.2. Generation efficiency

In Table 6, we show the runtime comparison between our method and the DiffPepBuilder when they both use a 24GB RTX3090 GPU.

15

Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints

Table 5. Success rates among different number of RBFs

Succ.(w=2) Bicycle peptide

RBFs=0 RBFs=16 RBFs=32

26.92% 30.76% 30.76%

Table 6. Runtime of our method and DiffPepBuilder

CP-Composer DiffPepBuilder

second per peptide

1.42s

29.94s

Figure 7. Four types of generated cyclic peptides, with the red boxes highlighting the position for cyclization.

E. Additional Visualizations

In Fig. 7, we show more cases of the stapled, Head-to-tail, disulfur and bicycle peptide.

F. Code Availability

The codes for our CP-Composer is provided at the link https://github.com/jdp22/CP-Composer_final.

16

Head-to-TailpeptideDisulfidepeptideStapledpeptideKDCSSCBicyclepeptideSSSCCC