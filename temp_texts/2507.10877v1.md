# Abstract

 Structural assessment of biomolecular complexes is essential for translating molecular modeling into functional

 insights in life science, impacting our understanding of biological mechanisms and informing drug discovery. How-

ever, existing structure-based scoring functions are typically system-specific, lacking generalizability across the

 diverse chemical and structural landscape of biomolecular complexes. We introduce BioScore, a foundational scor-

ing function for assessing biomolecular structures and interactions. BioScore addresses three critical challenges—

data sparsity, cross-system representation, and task compatibility—through a unified dual-scale geometric graph

 representation learning with specifically designed structure assessment and affinity prediction modules. This frame-

work enables BioScore to support a wide array of tasks, including affinity prediction, conformation ranking, and

 structure-based virtual screening. Across 16 benchmark tasks spanning proteins, nucleic acids, small molecules,

 and carbohydrates etc, BioScore consistently outperforms or matches 70 traditional tools and deep learning methods.

 This rigorous benchmarking procedure also features our newly proposed PPI Benchmark—a comprehensive bench-

mark system for protein–protein complex scoring. BioScore’s near universal applicability is demonstrated in three

 aspects: (1) pre-training on mixed-structure data yields up to 40% improvement in protein–protein affinity predic-

tion and over 90% increase in Pearson correlation for antigen–antibody binding; (2) cross-system generalizability

 enables zero- and few-shot prediction for nucleic acid interacting with molecule and protein with improvements of

 15%

and

71%

in

Pearson

correlation,

respectively;

and

(3)

its

unified

representation

successfully

characterizes

 chemically challenging systems such as cyclic peptides, achieving over 60% Pearson gain in affinity prediction.

 BioScore thus establishes a scalable, robust, and generalizable framework for structural assessment tasks across a

 broad spectrum of biomolecular systems.



 2

# Introduction

 In recent years, artificial intelligence (AI) has achieved transformative progress across a range of domains, from

 natural language processing and image recognition to biomedical research. AI models have evolved from special-

ized, task-specific tools into general-purpose systems with cross-domain capabilities1–4. Within the growing move-

ment of “AI for Science,” AI has been increasingly deployed to tackle grand scientific challenges, particularly in

 the life sciences and drug discovery5,6. Central to this effort is the pursuit of models with robust generalizability

 and strong zero-shot or few-shot learning capabilities across a wide spectrum of downstream tasks7–9. In the study

 of biomolecular complexes, this has catalyzed the development of large-scale foundation models aimed at bridging

 diverse molecular classes, with the goal of developing a universal representation and interpretation across complex

 biological systems10,11.

 Several

landmark

studies

have

laid

the

groundwork

for

distinct

foundational

frameworks

for

biomolecular

 modeling. The Evo model series12,13 applies language modeling techniques to genomic sequences, effectively cap-

turing diverse modalities—DNA, RNA, and proteins—through a unified lens. In structural modeling, AlphaFold314

 and ESMFold15 are excellent examples of how to build

universal structure predictors extending across increasingly

 diverse biomolecular systems and bridge the modality gap between structure and sequence, respectively. Kong et

 al. introduced an equivariant Transformer architecture capable of modeling the hierarchical organization and phys-

ical interactions among molecular entities14. More recently, Fang et al. presented ATOMICA, a generalist model for

 characterizing interaction interfaces spanning small molecules, metal ions, amino acids, and nucleic acids16. To-

gether, these efforts outline a grand scheme to unify structure and semantics that can universally characterize a

 variety of biomolecules and their interactions.

 For structural assessment tasks in life science, the AlphaFold series stands as a milestone achievement14. Yet

 despite their remarkable capabilities in structure prediction, recent studies reveal a key limitation: AlphaFold3 ex-

hibits poor performance in ranking binding affinities, making it inadequate for distinguishing active from inactive

 compounds17. This shortcoming underscores a broader challenge in the field18–21: while biomolecular structure pre-

diction

has

made

tremendous

progress14,22–24,

the

systematic

evaluation

of

inter-molecular

interactions

currently

 lacks a transformative solution of comparable impact. As most essential biological processes critically depend on

 the strength of biomolecular interactions, assessing binding affinity and the stability of binding conformations is a

 critical step in elucidating the mechanisms of life and advancing drug design25. However, experimentally resolving

 the 3D structures of biomolecular complexes is often costly and time-consuming26, it has not been easy to directly

 obtain the primary binding mode along with binding affinity of biomolecular complexes at large scale.



	To address this gap, scientists leveraged molecular docking techqniue as early as the 1990s27, aiming to com-

putationally model complex structures with a score function in drug design. With technological advancements, the

 role of scoring functions has expanded beyond simply evaluating docking poses. Ideally, a scoring function should

 naturally provide affinity prediction and screening functionalities, enabling not only the assessment of inter-molec-

ular binding strengths but also supporting tasks such as virtual screening and lead compound optimization. In the

 3





 fields of life sciences and drug design, scoring functions are becoming a vital bridge between structure prediction

 and functional interpretation28.

 Historically, scoring functions fall into two broad categories: physics-based or empirical models that approx-

imate binding affinities via pre-defined energy terms, and statistical models that extract potential functions from

 known structures29,30. Both approaches rely on pre-defined functional forms and assume simple relationships be-

tween input features and binding affinity, limiting their flexibility and generalizability. Deep learning offers a pow-

erful alternative31. By learning complex, nonlinear mappings from structural data to affinities, AI-based scoring

 functions have shown promise32. However, most current models are narrowly trained on protein–small molecule

 datasets and exhibit limited transferability to systems involving more complex molecular scaffolds—macrocycles

 and

natural

products—as

well

as

biomolecules

such

as

nucleic

acids,

peptides,

and

antibodies

etc. This

narrow

 scope

constrains

their

applicability

across

the

full

landscape

of

therapeutic

targets,

which

increasingly

includes

 protein–protein and protein–nucleic acid interactions—key players in immune signaling, transcriptional regulation,

 and disease pathogenesis25,33,34.

 This gap raises an important question: in the era of foundation models, can we develop a universal scoring

 function for biomolecular complexes? Several key challenges must be addressed. First, data sparsity: outside of

 protein–small molecule systems, there is a dearth of labeled structural data with experimentally measured affini-

ties35–37. Second, representational complexity: distinct biomolecular systems exhibit diverse interaction modes and

 physicochemical

properties,

complicating

the

design

of

generalizable

feature

representations.

Third,

functional

 tradeoffs: while an ideal scoring function should support scoring, ranking, docking, and screening, current models

 are often optimized for a single task at the expense of others—a problem that becomes more acute when extending

 to diverse biomolecular systems.

 Despite these challenges, a universal scoring function remains both physically plausible and practically valu-

able. Fundamentally, biomolecules—whether proteins, nucleic acids, or small molecules—share a common chem-

ical basis, being composed of atoms from a limited set of elements. This opens the door to atom-level representa-

tions that transcend molecular species. Moreover, the physical forces that govern molecular interactions—electro-

statics, van der Waals forces, hydrogen bonding etc—are universal. These shared principles support the theoretical

 foundation for a generalizable evaluation framework.

 Importantly, a foundational scoring function would fill a critical gap in the modeling pipeline. While much

 attention has focused on the unified molecular encoders, scoring functions represent the final, decision-making step

 in structure-based tasks such as virtual screening and affinity optimization. For instance, cyclic peptides—an emerg-

ing class of therapeutics with unique macrocyclic features—are gaining traction in drug development. Yet current

 scoring functions, predominantly tailored for protein–small molecule systems, are ill-equipped to handle the mod-

eling

of

highly

flexible

macrocycles

and

related

structures. A

universal

scoring

function

could

bridge

this

gap,

 enabling broader and more accurate structural assessments across diverse biological systems.



Here, we present BioScore—the first foundational scoring function designed to assess binding phenomanon

 across a broad range of biomolecular complexes (Fig. 1a). BioScore’s technical highlights can be summarized as

 4





 follows. (1) Representation: It departs from traditional atom/block discretizations by introducing interface-masking

 encodings and distance-aware edge construction, capturing dual-scale atomic and block-level features. This ap-

proach enables coarse-grained yet expressive representations applicable across molecular classes of various struc-

tural complexity. (2) Scoring Methodology: BioScore proposes a new structural assement score that incorporates a

 learned statistical potential (via a mixture of density network, MDN) and a newly defined interaction-edge-aware

 score. (3) Training strategy: A pretraining–fine-tuning workflow prioritizing large-scale structural learning at the

 pretraining stage balances performance across heterogeneous tasks, enabling plug-and-play adaptation to specific

 molecular systems.

During the development of BioScore, we recognized a lack of suitable benchmarks to evaluate

 scoring functions for protein–protein interactions (PPIs). To this end, we constructed a newly proposed PPI Bench-

mark, the first comprehensive dataset for evaluating the full-spectrum capabilities of scoring functions in protein–

protein complexes. BioScore is evaluated across 16 tasks—including classical systems (protein–small molecule,

 protein–protein, protein–nucleic acid, nucleic acid–small molecule) and specialized systems (e.g., cyclic peptides,

 macrocycles, carbohydrates, antibody–antigen, and peptide–MHC complexes). Against 70 traditional and domain-

specific deep learning baselines (Table S1), BioScore consistently achieves state-of-the-art (SOTA) or near SOTA

 performance across domains (Table S2).

 In this study, three key findings demonstrate the generalizability of BioScore. (1) Cross-domain pretraining sig-

nificantly improves the overall performance, including 40% gains in protein–protein affinity prediction and over

 90%

relative

improvement

in

Pearson

correlation

for

antibody–antigen

binding.

(2)

Structural

transfer

learning

 enables accurate zero-shot prediction on nucleic acid–small molecule systems and boosts few-shot performance on

 protein–nucleic acid complexes by 15% and 71% (Pearson correlation) over prior SOTA, respectively. (3) Universal

 representation learning enhances performance on challenging molecular classes that lie at the blurring boundary of

 the traditional notion of small molecules, such as macrocycles and some carbohydrates. For example, BioScore

 delivers over 60% relative gain in correlation for protein–cyclic peptide interactions compared to baseline methods.

 As the first universal scoring function tailored for diverse biomolecular complexes, BioScore offers a unified, ex-

tensible framework for cross-system evaluation, providing a robust foundation for mechanistic analysis and drug

 discovery across complex biological systems. As the landscape of potential therapeutic targets and drug modalities

 expands beyond traditional proteins and Rule-of-Five small molecules, BioScore fills a critical gap by enabling

 rigorous evaluation of prospective drug candidates.

 Results

 Design Principles of BioScore

 Most existing deep learning–based scoring functions rely on domain-specific encoding strategies and task-special-

ized designs, limiting their ability to generalize across different types of biomolecular complexes38,39. In contrast,

 BioScore integrates the principles of statistical potentials with a unified geometric representation framework, aim-

ing to strike a balance between generality and effectiveness.

 5







 First, to enhance the cross-system consistency of complex representations, BioScore integrates dual-scale in-

formation from both atoms and building blocks such as residues and nucleobases (Figure 1b). It constructs an all-

atom geometric graph at the atomic level while incorporating domain-specific block-level information. This unified

 geometric

graph

structure

allows

the

model

to

accommodate

various

biomolecular

systems,

including

proteins,

 nucleic acids, and molecules of varying degrees of structural complexity. Additionally, a feature extraction module

 based on a general equivariant Transformer (Figure 1f) is employed to capture both intra-domain and cross-domain

 information across different biomolecular complexes.		

While explicitly adding inter-molecular interaction edges within complexes is a common practice in represen-

tation

learning—especially

emphasized

in

prior

work

on

general

biomolecular

representation16,40,41—it

induces

 overfitting when applied in scoring functions based on statistical potentials (Figure S1), ultimately compromising

 the modeling of distance distributions. To address this challenge, we propose a interface-masking encoding strategy

 that deliberately masks inter-molecular edges and retains only intra-molecular edges, thereby enhancing the model’s

 capacity to perceive and learn true spatial distances. This design is crucial for constructing a foundational scoring

 function applicable to general biomolecular complexes. Ablation experiments demonstrate that the introduction of

 the interface-masking strategy significantly improves docking and screening performance across various structural

 complexity and chemical diversity, including protein–ligand (small molecule), protein–protein complexes (Tables

 S3–S4).

 In complex system modeling, BioScore further introduces a distance-threshold-based edge construction strat-

egy. This approach builds intra-molecular and inter-molecular edges by applying tailored distance cutoffs for dif-

ferent biomolecules and edge types: 10 Å for proteins/nucleic acids38, 2 Å for small molecules42, and 8 Å for com-

plex interaction edges. These thresholds are determined by empirical experiences as well as extensive testing. We

 settle for this rule-based method for now, instead of a dynamical, self-adapted threshold setting to streamline the

 numerical processing. Compared to the common K-nearest neighbor (KNN) methods or enumeration strategies,

 this

distance-cutoff

strategy

better

characterizes

the

critical

edge

count—which

is

essential

for

the

downstream

 dual-tower output module—while significantly improving computational efficiency. Specifically, compared to our

 previous model RTMScore38 developed for protein-ligand (PLI) systems, BioScore achieves a 15-fold improvement

 in computational speed, as shown in Table S5 (We have also included statistics for several important scoring func-

tions used in our study, which will be discussed in detail in later sections).

 Finally, BioScore employs a dual-tower scoring architecture designed to address two task categories: dock-

ing/screening and scoring/ranking (Figure 1e). In the docking and screening pathway, the model constructs statis-

tical-potential-based scoring terms based on the principles of inverse Boltzmann distribution, and introduces an

 interaction-edge-count-based confidence term as an auxiliary signal to enhance the model’s ability to distinguish

 true binding conformations. This strategy significantly improves docking and screening performance across multi-

ple complex systems (Tables S3–S4). In the scoring and ranking pathway, the model fits nonlinear relationships

 between

interacting

atom

pairs

and

binding

free

energies

using

neural

networks,

outputs

the

mean

score

as

the

 6





 primary prediction, and incorporates an edge-count-aware confidence term to improve the characterization of bind-

ing affinity strength. Together with our pretraining–fine-tuning strategy (Figures 1d and 1e), BioScore is capable

 of learning structural features from diverse biomolecular systems collected from multiple datasets (Table S6) and

 adapting to task objectives across different molecular species. During pretraining, BioScore specifically trains the

 MDN module by leveraging pairwise distance distributions derived from experimental complex configurations.

 This enables BioScore to capture general structural features by minimizing the negative log-likelihood of the dis-

tance distributions. In the subsequent fine-tuning phase, the model undergoes task-specific fine-tuning on each type

 of

complex,

such

as

protein–protein

interactions,

molecular

binding

affinity,

or

other

relevant

supervised

tasks,

 while

combining

multiple

loss

components

to

adapt

its

learned

representations

to

specific

downstream

objec-

tives.For a detailed description of BioScore, please refer to the Methods section.

 A New Comprehensive Benchmark for Protein–Protein Interactions

 One of the key challenges in developing a universal scoring function is to establish systematic evaluation across

 different molecular systems. At present, only the protein–small molecule system has some widely accepted scoring

 benchmarks—such as CASF-201643—while other biomolecular systems, particularly protein–protein complexes,

 lack

a

standardized

benchmark

dataset. This

gap

leads

to

significant

inconsistencies

in

evaluation

criteria,

data

 sources, and capability coverage across different methods, hindering fair and consistent comparisons.

 To address the aforementioned challenges, we constructed a benchmark dataset for structural assements of

 protein–protein complexes (PPI Benchmark) based on the PDBbind v2020 database44, covering three core tasks:

 scoring, docking, and screening. The benchmark design is inspired by CASF-2016, while ensuring data quality and

 source consistency.

 We first selected 177 representative protein–protein complexes, then further filtered 79 complexes considering

 the diversity of chain lengths to construct the foundational dataset (Figures 2a, 2b). Based on this, we further three

 task-specific subsets: (1) Scoring benchmark: comprising the 79 native complexes with experimental binding af-

finity annotations, used to evaluate binding affinity prediction performance (Figure 2b); (2) Docking benchmark:

 for each complex, decoy conformations were generated using ZDOCK45, and 7,979 conformations were selected

 based on DockQ scores to ensure balanced quality distributions, used to assess the model’s ability to distinguish

 native-like from non-native conformations (Figure 2c); (3) Screening benchmark: for each of the 79 receptor–ligand

 pairs, cross-docking was performed, and 613,900 conformations were obtained through K-means clustering and

 sampling, used to evaluate the model’s ability to discriminate active from inactive ligands (Figure 2d).

 Compared to existing benchmarks, our newly proposed PPI Benchmark represents the first multidimensional

 evaluation framework for protein–protein complexes built from a unified data source, providing an objective and

 reproducible foundation for comprehensive scoring function evaluation. Detailed construction procedures and eval-

uation metrics are described in the Supplementary Information.

 Comprehensive Evaluation on Protein–Protein Interactions

 7









 We first systematically evaluated the three core capabilities of BioScore on the custom-built PPI Benchmark and

 compared its performance against various deep learning models (GNN-DOVE46, DProQA47, GET41, MINT48) and

 classical methods (ZRANK249, VoroMQA50) (Table 1). BioScore ranks first in 9 out of 13 metrics, highlighting its

 superior overall performance. Detailed descriptions of the baseline models are provided in the Supplementary In-

formation.

 In the scoring task, BioScore ranked second only to MINT, a model recently developed by Ullanat et al., which

 was pretrained on 96 million sequence pairs from STRING-DB51, whereas our model was trained on only ~1,700

 structural data points (a detailed description of the training and testing data across all evaluation tasks is provided

 in the Methods section). In the docking task, BioScore significantly outperformed other methods in terms of the

 success rate for identifying native and high-quality conformations (Table 1, Figures 3a and 3b) and demonstrated

 strong robustness under diverse decoy distributions. In the screening task, BioScore was the only method that ex-

hibited effective discrimination capability on our constructed screening benchmark (Figure 3c), further validating

 the

advantages

of

statistical-potential-based

scoring

approaches

and

their

applicability

to

protein–protein

com-

plexes when appropriately adapted. Moreover, while existing models tend to excel in specific functionalities, they

 often

lack

generality.

For

instance,

although

GET

and

MINT

perform

well

in

scoring

tasks,

they

are

limited

in

 docking and screening tasks, while VoroMQA shows docking capabilities but lacks affinity predictive power. Bi-

oScore is the only model that simultaneously integrates all three functionalities among tested methods on the newly

 proposed PPI benchmark.

 To further evaluate BioScore’s generalizability, we applied it to two more challenging tasks: antigen–antibody

 affinity prediction and peptide–MHC-I screening. Antibodies recognize antigens through their complementarity-

determining regions (CDRs) in the variable domains, which are highly variable in both structure and sequence and

 exhibit low evolutionary conservation, making binding affinity prediction particularly difficult52. We collected 272

 complex structures with affinity labels from the SAbDab database53 and divided them into training, validation, and

 test sets (in a 3:1:6 ratio) while controlling for data leakage. The results show that BioScore significantly outper-

forms GET and MINT in this task (Figure 3d, Table S7).

 In the peptide–MHC-I task, we previously constructed a screening benchmark comprising 11 alleles based

 onthe pipeline proposed by ITN54. Under the zero-shot condition—without fine-tuning on any task-specific data—

BioScore outperformed all baseline models in both AUROC and AUPR metrics (Figure 3e), demonstrating strong

 cross-domain generalization capabilities.

 Strong Generalization and Robustness in Protein–Ligand Scoring Tasks

 Prediction of protein–small molecule interactions (PLI) is of great importance in the early stages of drug discovery,

 serving as a key component in molecular docking and virtual screening workflows32. Given the relative abundance

 of high-quality data in this domain (for example, nearly 20,000 PLI entries are available in PDBbind v202044), PLI

 prediction has become a major focus for both traditional scoring function development and deep learning model

 research, leading to the establishment of widely used benchmark datasets such as CASF-201643.

 8







 Our previously developed model, RTMScore38, demonstrated strong performance in PLI tasks but still faced

 three major limitations: (1) it required enumerating all possible interaction edges between proteins and small mol-

ecules, leading to low computational efficiency; (2) it adopted separate encoding strategies for proteins (receptor)

 and small molecules (ligand), preventing effective information exchange across the two encoders and resulintg in

 limited generalizability; and (3) it primarily supported docking and screening tasks, lacking in scoring and ranking

 capabilities. To address these challenges, we subsequently introduced GenScore55, which incorporated a correlation

 loss based on binding affinity into the loss function, thereby improving ranking capabilities. However, GenScore

 still could not reliably predict absolute binding affinity values. These limitations have been systematically addressed

 in BioScore.

 On the CASF-2016 benchmark, we constructed the training data exclusively from PDBbind, without intro-

ducing any additional data augmentation. The results demonstrate that BioScore outperforms multiple mainstream

 methods—including many first-tier, SOTA methods such as RTMScore and GenScore—across the scoring, ranking,

 and screening tasks (Figure 4, Table S8). In the docking task, BioScore ranks third, achieving comparable perfor-

mance to GenScore and RTMScore, indicating that it maintains strong structural discrimination capabilities while

 preserving its modeling generality.

 To further validate its generalization performance, we evaluated BioScore on two external screening bench-

marks, DUD-E56 and DEKOIS2.057, and compared its performance with EquiScore58, a SOTA screening model.

 The results indicate that on DUD-E, BioScore ranks first across all three enrichment factor metrics (EF1%, EF5%,

 EF10%), and second in the BEDROC metric, slightly behind RTMScore (Figure S2). On DEKOIS2.0, while Bi-

oScore trails behind EquiScore and RTMScore, it consistently ranks within the top three across most metrics (Figure

 S3), demonstrating robust screening capability and generalization across datasets.

 Finally, we selected one protein–small molecule complex from our benchmark set, 3KR8, which corresponds

 to the catalytic domain of human tankyrase 2. Tankyrases are involved in fundamental cellular processes such as

 telomere homeostasis and Wnt signaling59. Figure 4e–f presents the residue–atom distance map and the correspond-

ing energy contribution map calculated by BioScore for the 3KR8 complex, clearly demonstrating a strong corre-

lation between spatial proximity and binding energy contribution. Furthermore, based on previous structural and

 biochemical studies of this complex60, we highlighted several key amino acid residues that are known to drive the

 interaction

with

the

ligand

(Figure

4g). These

residues

show

excellent

agreement

with

those

identified

as

high

 contributors in the BioScore-derived energy map, indicating that BioScore effectively captures biophysically mean-

ingful interaction patterns relevant for inhibitor binding.

 Cross-Domain Pre-training Enhances BioScore's Perfermence

 In the aforementioned PLI and PPI benchmark evaluations, BioScore outperformed domain-specific methods de-

spite not relying on any task-specific data augmentation strategies. Unlike previous approaches that improve per-

formance through manually constructed positive/negative samples or by training model with an increased task-

9







 specific data volumes, BioScore’s enhancement stems from its universal biomolecular complex modeling capabil-

ity—achieved

through

cross-domain

mixed

training

on

heterogeneous

complex

systems.

This

type

of

training

 mechanism is only feasible within a model architecture that supports unified representation scheme and task adap-

tation capability.

 As previously discussed, deep learning–based scoring functions commonly face the challenge of data sparsity.

 We posit that an ideal foundational scoring function should possess the ability to extract shared structural infor-

mation across diverse biomolecular complexes, thereby improving performance on any individual system. Follow-

ing this principle, BioScore is first pretrained on a combined dataset of PLI and PPI structural data, and then fine-

tuned

on

labeled

data

for

each

specific

system. To

systematically

validate

the

effectiveness

of

this

strategy,

we

 designed

control

experiments

comparing

performance

under

two

conditions:

pretraining

on

single-domain

data

 versus pretraining on cross-domain PLI and PPI mixed data, and evaluated their impact on both PPI and PLI tasks

 (Tables S9–S12).

 In the PPI task (Table S9), cross-domain training led to substantial improvements: across the three affinity

 prediction metrics, the average performance increase was 43.05%, with the Pearson correlation coefficient improv-

ing by as much as 109.09%. For the four screening capability metrics, the average improvement reached 42.17%,

 and the Top-1% success rate increased by 71.47%. These results indicate that despite differences in molecular types

 and binding modes between PLI and PPI systems, the physical and geometric patterns embedded in their 3D struc-

tures exhibit strong transferability when formulated in an appropriate framework. The inclusion of PLI data effec-

tively compensates for the limited data availability in PPI systems and other cases (to be elucidated in subsequent

 sections). A similar trend was observed in the more challenging task of antigen–antibody binding affinity prediction.

 The incorporation of PLI pretraining data led to an average improvement of 37.27% across three key affinity pre-

diction metrics, with the Pearson correlation showing a substantial gain of 91.67% (Table S10).

 In the PLI task (Table S11), incorporating PPI data also had a positive impact on ranking capabilities, with an

 average improvement of 16.91%. Performance on scoring, docking and screening metrics remained stable, indicat-

ing that BioScore is robust in learning from heterogeneous structural information, particularly in data-rich scenarios.

 Notably, this cross-domain training strategy also proves effective for systems in specialized chemical spaces

 (Table

S12),

such

as

protein–cyclic

peptide

complexes,

demonstrating

broad

transfer

potential. We

will

present

 further investigations on these specific cases below.

 We also explored the combination of PLI and PPI data during the fine-tuning stage. However, the results (Table

 S13) indicate that while this approach still outperforms single-domain fine-tuning, it is slightly less effective than

 our current strategy—performing cross-domain mixing during pretraining and using only target-domain data during

 fine-tuning. We

hypothesize

that

this

is

because

structural

modeling

exhibits

stronger

generality,

whereas

label

 fitting is more sensitive to data distribution. Based on this strategy, BioScore maintains its generalization capability

 while

also

offering

“plug-and-play”

flexibility

and

efficiency

for

specific

task

scenarios,

aligning

with

the

dual

 demands for resource efficiency (e.g. training data volume) and accuracy in practical applications.

 10







 Scoring Nucleic Acids: From Protein–Nucleic Acid to Nucleic Acid–Ligand

 In the previous section, we clearly demonstrated the benefits of cross-domain training for PPI and PLI tasks. A

 follow-up

question

naturally

arises:

can

BioScore

maintain

its

competitive

performance

for

other

biomolecular



systems? Biomolecular complexes (relevant for life science and drug discovery) usually come from the four major

 categories: protein–ligand interactions (PLI), protein–protein interactions (PPI), protein–nucleic acid interactions

 (PNI), and nucleic acid-ligand interactions (NLI). Among them, protein–nucleic acid interactions (PNI) play a fun-

damental role in essential biological processes such as gene expression regulation, cellular function maintenance,

 and pathogen immunity, making them a critical focus in the drug target research34. However, compared to other

 biomolecular complex systems, affinity prediction for PNI poses greater challenges, primarily due to the high struc-

tural diversity and high structural flexibility inherent to nucleic acid molecules61.

 To systematically evaluate BioScore’s scoring capability for PNI, we exclusively used 1,052 valid PNI entries

 from PDBbind. To simulate the data scarcity commonly encountered in the real-world PNI scenarios, we strictly

 limited the training data volume, using only 276 samples (split 3:1:6 for training, validation, and testing, as shown

 in Figures 5a and 5b). During pretraining, PLI and PPI structural data were combined with PNI data for joint train-

ing, followed by fine-tuning on PNI label data. The results (Figure 5c, Table S14) demonstrate that BioScore out-

performs multiple representative graph-based baseline methods across all scoring metrics. Specifically, compared

 to the best-performing baseline, BioScore improves the Pearson correlation by 70.88%. Notably, in RMSE and

 MAE, BioScore achieves highly accurate predictions of binding affinity (Figure 5f), showcasing its strong capacity

 for affinity prediction even under extremely low-resource learning conditions.

 We further extended our evaluation to the more challenging scenario of nucleic acid–ligand complexes. Among

 all biomolecular complex systems, data for NLI are the scarcest41, with only 134 valid entries in PDBbind—less

 than 1% of the PLI dataset. Here, we treated these 134 NLI samples as a zero-shot test set and directly evaluated

 binding affinity prediction using the model fine-tuned solely on PNI data. Remarkably, without having seen any

 NLI

data,

BioScore

achieved

excellent

zero-shot

transfer

performance,

significantly

outperforming

all

baseline

 models (Figures 5d and 5h, Table S15). These results demonstrate that BioScore effectively captures shared struc-

tural and interaction patterns across systems and successfully generalizes to new scenarios with greater structural

 differences and extreme data scarcity.

 It is worth noting that RNA–ligand interactions play essential roles in biological processes such as gene regu-

lation

and

protein

synthesis,

serving

as

a

key

mechanistic

basis

for

emerging

research

areas

like

antiviral

drug

 development and non-coding RNA targeting62. To further validate the adaptability of BioScore, we selected this

 subtype as a representative case and conducted a detailed analysis of its affinity predictive power. We compared

 BioScore with traditional docking tools such as rDock, and also included MM/GBSA — a higher-accuracy molec-

ular mechanics–based affinity estimation methods63. The experimental results (Figures 5e and 5h) demonstrate that

 even without explicit training on any NLI data, BioScore achieves prediction accuracy second only to the physics-

grounded and computationally intensive MM/GBSA method and significantly outperforms all other methods, in-

cluding rDock, which is specifically designed for RNA–ligand interactions.

 11





 Generalization Over Challenging Regions in Chemical Space

 The results from the preceding evaluations demonstrate the ability of a universal foundational scoring function to

 leverage

information

from

different

domains

for

performance

enhancement

in

a

specific

domain,

as

well

as

its

 capacity for cross-domain generalization to complex, low-data, or even zero-shot scenarios. We further sought to

 investigate whether BioScore could be applied to certain molecular classes that have been challenging for prior

 methods for various technical reasons.

Among these, cyclic peptides stand out as one of the most representative

 cases. Since the discovery of insulin in 192064, cyclic peptide drugs have demonstrated unique value across fields

 such as oncology, metabolic disorders, and infectious diseases, owing to their combination of small-molecule-like

 membrane permeability and antibody-level target selectivity65. Their molecular weights typically range from 500

 to 5,000 Da, filling the gap between small molecules (<500 Da) and biologic drugs (>5,000 Da). From a chemical

 space perspective, we posit that cyclic peptides occupy an interesting region at the blurring boundary between small

 molecules and proteins (Figures 6a and 6b), implying that neither a purely small-molecule nor a purely protein-

centric perspective is sufficient to fully characterize cyclic peptides with most existing data-driven methods. Bi-

oScore, as a scoring function for general biomolecular complexes, offers a unique opportunity to bridge small-

molecule and protein perspectives for the study of cyclic peptides.

 We previously constructed a protein–cyclic peptide benchmark dataset, CPSet, and evaluated the binding af-

finity prediction performance of various docking tools for protein–cyclic peptide complexes66. It is important to

 note that in both the current and previous evaluations, we excluded all samples containing macrocyclic structures

 (including cyclic peptides) from the PLI dataset, making this task a true zero-shot test. The results demonstrate that

 BioScore significantly outperforms all traditional scoring methods in terms of Pearson correlation coefficient (Fig-

ure 6c). Control experiments (Table S12) further show that BioScore only achieves its current optimal performance

 under the PLI and PPI mixed pretraining setup, highlighting its unique capacity to break through the limitations of

 single-domain perspectives and generalize to the specialized protein–cyclic peptide complex system.

 Beyond cyclic peptides, non-peptidic macrocyclic drugs have also garnered increasing attention in recent years

 for

drug

design67,68.

These

molecules

often

exhibit

natural

product-like

structures,

typically

do

not

conform

to

 Lipinski’s Rule of Five, yet hold unique potential for expanding chemical space in drug discovery (Figure 6d). We

 extracted non-peptidic macrocyclic data from PDBbind as a zero-shot test set to evaluate BioScore’s scoring capa-

bility for protein–non-peptidic macrocycle complexes. Here, we again compared BioScore with baseline models

 such as GET, EGNN, and the traditional docking method AutoDock Vina. Without any additional fine-tuning, Bi-

oScore demonstrated performance far exceeding that of all baseline methods (Figures 6e and 6f, Table S16).

 We further evaluated the applicability of BioScore to protein–carbohydrate systems. Such interactions play

 critical roles in fundamental biological processes, including cell recognition, signal transduction, and immune reg-

ulation69. However, their binding sites exhibit high structural diversity70, making prediction much more challenging

 than in typical protein–small molecule systems (Figure 6g). Existing scoring functions for protein–carbohydrate

 interactions include CSM-carbohydrate71, PCAPRED72, and CSM-lig73. Notably, Nguyen et al., in the development

 12







 of CSM-carbohydrate, manually curated a dataset of 370 protein–carbohydrate complexes with both structural and

 label information from resources such as ProCarbDB74, ProCaff75, and PCAPRED72, and tested their model on an

 independent benchmark set of 43 protein–carbohydrate complexes. For a fair comparison, we fine-tuned BioScore

 exclusively

on

the

same

370

labeled

samples

provided

by

CSM-carbohydrate,

without

using

PLI

labels

from

 PDBbind to avoid potential data leakage issues. We then evaluated BioScore’s performance on the same independ-

ent test set, and the results (Figure 6h, Table S17) demonstrate that BioScore, trained on the same label data, out-

performs all existing methods and achieves SOTA performance.

 In

summary,

BioScore

demonstrates

excellent

performance

across

specialized

complex

systems,

including

 cyclic

peptides,

non-peptidic

macrocycles,

and

protein–carbohydrate

interactions.

These

results

highlight

Bi-

oScore’s capacity for structural transferability and task adaptability after overcoming the limitations of single-do-

main perspectives, underscoring its broad practical potential as a foundational scoring function.

 Discussion

 In this study, we present BioScore—the first foundational scoring function specifically designed for structure-based

 assements of general biomolecular complexes. Unlike previous scoring methods developed for specific systems

 such as protein–ligand or protein–protein interactions, BioScore is applicable to a wide range of biomolecular com-

plexes, offering broad compatibility for diverse structural inputs. While prior work on general molecular represen-

tation learning has enabled cross-system encoding, it has primarily focused on affinity scoring tasks, lacking struc-

tural evaluation capabilities such as docking and screening. BioScore represents a true technological advancements

 in this regard: by integrating interface-masking encoding, a distance-threshold-based edge construction strategy,

 and a dual-tower scoring design inspired by the physics-grounded method termed inverse Boltzmann distribution,

 it is the first model to unify scoring, ranking, docking, and screening functionalities within a single framework for

 general biomolecular complexes, addressing the longstanding challenge of balancing generality, task comprehen-

siveness and computational efficiency.



Across multiple regions of chemical space—including protein–protein and protein–ligand interactions—Bi-

oScore demonstrates leading performance on various standard evaluation metrics. Along the way, we also propose

 a new PPI benchmark suite that should facilitate future efforts in further developing scoring functions. Based on

 the comprehensive testing and analysis, BioScore exhibits exceptional generalization capability in challenging tasks

 under extreme data scarcity or zero-shot scenarios. For challenging cases such as antigen–antibody, peptide–MHC

 and nucleic acid–ligand complexes, BioScore outperforms many existing methods in either virtual screening or

 binding affinity prediction. This is made possible by BioScore’s cross-domain knowledge transfer, enabled by its

 mixed-domain pretraining strategy. Furthermore, BioScore shows high adaptability across challenging molecular

 classes, such as cyclic peptide, non-peptidic macrocycle, and carbohydrate, filling a critical gap left by traditional

 models in handling fuzzy boundaries in chemical space.

 Nevertheless,

BioScore

has

room

for

improvement.

Currently,

the

model

does

not

fully

leverage

the

vast

 amount of biomolecular complex data that contain only sequence and affinity labels, which are far more abundant

 13







 than data with both structural information and labels. Future work could explore integrating multimodal techniques

 to embed sequence semantics into the structural modeling framework, thereby enhancing model performance in

 scenarios lacking structural data. Additionally, BioScore’s performance in PLI screening tasks can definitely be

 improved, highlighting the need for more targeted data augmentation strategies to improve model discriminability

 and robustness. From an algorithmic perspective, traditional physics-based modeling methods that explicitly intro-

duce functional form to model binding free energy remain valuable, and incorporating such physical priors into the

 current framework could further improve the interpretability and accuracy of the scoring function. Despite these

 exciting developments one can pursue in the near future, the current version of BioScore already offer strong per-

formance

and

can

be

readily

deployed

in

the

real-world

research

and

drug

discovery

projects.

Furthermore,

by

 integrating (and even fine tuning) BioScore with structure prediction and related binder design methods, such as

 AlphaFold3 and BindCraft etc, we see an exicting venue where structure prediction, assements and design all done

 in a self-consistent loop to greatly improve the task of binder designs.



Method

 Preparation of the Training Dataset

 BioScore adopts a pretraining–fine-tuning training strategy. The raw structural data and experimental binding af-

finity annotations of various biomolecular complexes used during training were primarily sourced from the widely

 adopted PDBbind database44 (version 2020), a standard resource in the development of scoring functions. The data

 were preprocessed according to the following steps:

 (1) Filtering

 a. Given the significant differences in interaction patterns between covalently bounded protein-molecule complexes

 and general non-covalent systems, we preemptively removed all covalent complexes from the PLI dataset to prevent

 mixed inputs from interfering with model learning. The specific procedure was as follows: We first integrated three

 publicly

available

protein–covalent

ligand

structure

databases—CovPDB76,

CovBinderInPDB77,

and

Covalen-

tInDB 2.078—using the combination of the protein’s UniProt ID and the normalized SMILES string of the small

 molecule (considering stereoisomers) as unique identifiers for each protein–covalent small molecule complex pair.

 For identical entries, only the first occurrence was retained, resulting in a total of 4,768 unique complex structures.

 Based on this, we applied the same “UniProt ID – normalized SMILES” matching criterion to identify and remove

 covalent complexes from the PDBbind (version 2020) PLI dataset, ultimately retaining 18,608 non-covalent PLI

 complexes for the subsequent construction of the training dataset.

 b. Furthermore, considering the imbalance in structural and affinity annotation data distributions across different

 biomolecular complex systems, we established distinct filtering criteria tailored to the objectives of the two training

 stages to maximize the utilization of available data. For the pretraining stage, as no labels are required, we priori-

tized data diversity while applying only minimal structural constraints. Complexes were retained if they met the

 14







 following conditions: (1) clear specification of interacting components; (2) absence of rare elements or non-canon-

ical amino acids in the structure; and (3) a minimum of one heavy atom per component. For the fine-tuning stage,

 stricter criteria were applied based on conformation quality and affinity labels to ensure effective training: (1) struc-

tures must be determined by non-NMR methods with a resolution better than 2.5 Å; and (2) complexes must have

 explicit affinity annotations of type “Kd,” “Ki,” or “IC50,” reported in units of “M” or convertible to “M.” For PPIs,

 PNIs, and NLIs in PDBbind (with NLIs appearing only in test sets), given the small difference in retained data

 between the two filtering strategies, we uniformly adopted the stricter criteria for data quality considerations.

 (2) Interaction Region Extraction

 To ensure computational efficiency, we extracted interaction regions from the filtered data to replace full complex

 structures as model inputs. Based on differences in interaction patterns across biomolecular complex systems, we

 adopted system-specific extraction strategies. For PLIs, the ligand was retained in its entirety, while the receptor

 region was extracted using ProDy 2.4.1 by identifying all residues within 10 Å of the ligand structure. For PPIs,

 PNIs, and NLIs (the latter appearing only in test sets), both receptor and ligand regions were defined by distance

 thresholds, retaining only residues or atoms from both components that lie within 6 Å of each other.

 (3) Deduplication

 To prevent data leakage and ensure fair evaluation of model performance, all training data were deduplicated against

 benchmark test sets (CASF-2016, PPI Benchmark) by removing complexes with identical PDB IDs from the train-

ing and validation sets. Specifically,

as

recent

studies

(notably

by

Joseph

Szymborski

et

al.79) have highlighted

 sequence similarity as an additional source of data leakage in PPI prediction tasks, we applied an additional se-

quence similarity–based deduplication step for all PPIs. Using the benchmark test sets as the query set and the

 pretraining/fine-tuning

datasets

as

the

reference

set,

we

conducted

sequence

similarity

searches

via

MMseqs2

 15.6f452. Each complex’s sequence was defined by concatenating the receptor and ligand chain sequences, with a

 sequence coverage threshold of 0.3. Based on the search results, we removed all reference set complexes with a

 minimum

sequence

similarity

≥30%

to

any

benchmark

test

complex. This

stringent

deduplication

ensured

the

 reliability of evaluation results. Furthermore, considering that the generality evaluation also involves specialized

 applications such as protein–cyclic peptide and protein–macrocycle systems, for all PLIs, in addition to PDB ID–

based

deduplication

against

CASF-2016,

we

also

removed

any

complexes

where

the

ligand

was

a

macrocyclic

 molecule (identified by SMILES, defined as containing at least one ring with ≥12 atoms).

 (4) Dataset Splitting

 Data that could not be effectively processed in the aforementioned steps were discarded. The retained data were

 randomly split into training and validation sets based on specific ratios. For PDBbind, following our previous work,

 we fixed the validation set size at 1,500 samples for PLIs. For PNIs, we reserved sufficient data for testing, adopting

 a 3:1:6 split for training, validation, and test sets. For all other cases without special instructions, a 9:1 split between

 training and validation sets was applied. Specifically, to address the impact of sequence similarity on PPI prediction

 tasks, PPIs were first clustered using MMseqs2 15.6f452 before random splitting. Two complexes were grouped

 15





 into the same cluster if their sequence similarity exceeded 30% (with a sequence coverage threshold of 0.3). Clus-

ters were then used as the splitting unit: 10% of the clusters were randomly selected as the validation set, and the

 remaining clusters formed the training set. All datasets used in the pretraining and fine-tuning stages are listed in

 Table S6.

 Model Performance Evaluation Description

 To comprehensively evaluate the model’s capabilities across different biomolecular complexes, we collected and

 constructed a series of test sets for extensive performance evaluation of BioScore.

 (1) PPI Benchmark

 Details of the PPI Benchmark construction are provided in the Supplementary Information due to space limitations.



(2) PLI Evaluation – Benchmark Dataset

 CASF-2016 is a classic benchmark for protein–ligand interaction (PLI) scoring functions, constructed based on

 PDBbind PL. The core set comprises 285 active PLI complexes spanning 57 targets and is designed to evaluate

 four fundamental capabilities of models: scoring, ranking, docking, and screening.

 (3) PLI Evaluation – External Test Sets

 We adopted the widely used virtual screening benchmark datasets DEKOIS 2.057 and DUD-E56 as external test sets

 for evaluating the screening capabilities of PLI models. DEKOIS 2.0 covers 81 different targets, with each target

 including 40 active ligands and 1,200 decoys. DUD-E includes 22,886 active ligands spanning 102 targets, with 50

 decoys provided for each active ligand. For model evaluation, we generated at least 10 docking conformations per

 complex using Glide SP. All docking conformation data were sourced from our previous work (GenScore55).

 (4) PPI Evaluation – Benchmark Dataset

 Using the PPI Benchmark we constructed based on PDBbind PP as the benchmark, the core set comprises 79 active

 PPI complexes across different targets. This dataset is designed to evaluate model capabilities in scoring, docking,

 and screening. The specific construction process is described in detail above.

 (5) PPI Evaluation – External Test Sets

 We used an antigen–antibody test set constructed from the SAbDab database53 as an external benchmark for PPI

 scoring evaluation. Complexes were filtered based on the following criteria: antigen type must be peptide/protein;

 antibody chains (heavy, light) and antigen chains must be clearly annotated; and binding affinity scores must be

 explicitly available. A total of 272 unique antigen–antibody interaction pairs were collected. We adopted a few-shot

 evaluation protocol: a small portion of the data was used for model fine-tuning, while the remaining data were

 reserved for evaluation. Specifically, the antigen–antibody complexes were clustered using MMseqs2 15.6f452,

 with a sequence similarity threshold of 80% (sequence coverage ≥0.3). Clusters were used as the splitting unit and

 randomly divided into training/validation/test sets at a 3:1:6 ratio, resulting in 112/10/150 samples for training,

 validation, and testing, respectively. Additionally, we used the peptide–MHC virtual screening benchmark from our

 previous work (ITN54) as an external test set for PPI screening evaluation. This benchmark contains 42,459 unique

 complexes

across

11

HLA

class

I

targets,

labeled

for

binary

classification,

with

an

overall

positive-to-negative

 16







 sample ratio of approximately 1:3. Considering that all peptide ligands in this dataset are nonapeptides (relatively

 small in molecular weight), we applied the same preprocessing pipeline as used for PLIs to enhance model repre-

sentation accuracy.

 (6) PNI Evaluation

 The test set for evaluating PNI scoring capability under the few-shot scenario was constructed by randomly splitting

 the preprocessed PDBbind PNI data as described above.

 (7) NLI Evaluation

 The dataset for evaluating NLI scoring capability under the zero-shot scenario was derived from the preprocessed

 PDBbind NL data and further refined by identifying the RNA–ligand interaction subset, as defined in our previous

 work.

 (8) Protein–Cyclic Peptide Test Set

 Constructed based on the protein–cyclic peptide benchmark dataset CPSet proposed in our previous work66, retain-

ing only those complexes with explicit binding affinity annotations.

 (9) Protein–Non-Peptidic Macrocycle Test Set

 Constructed from PDBbind PLI by filtering complexes whose ligands are macrocyclic molecules (defined as con-

taining at least one ring with ≥12 atoms, based on SMILES) and have explicit binding affinity annotations. All

 cyclic peptide ligands were manually excluded through curation.

 (10) Protein–Carbohydrate Test Set

 Constructed by using the protein–carbohydrate dataset curated by Nguyen et al. as the training set71, with 43 entries

 from PCAPRED serving as an independent test set72.

 All test sets underwent the same filtering and interaction region extraction procedures as described for the pretrain-

ing and fine-tuning datasets. Complexes that could not be effectively processed were discarded. Detailed infor-

mation on each test set is provided in Table S2. We used the model weights pretrained on PDBbind PLI+PPI data

 as the foundation for testing under various scenarios. For all docking and screening evaluations, no additional fine-

tuning was performed; the pretrained weights were directly applied. For all scoring and ranking evaluations, task-

specific fine-tuning was conducted using the corresponding datasets: protein–small molecule scoring/ranking, pro-

tein–cyclic peptide and protein-non-peptidic macrocycle evaluations were fine-tuned on PDBbind PLI; protein–

protein scoring evaluations were fine-tuned on PDBbind PPI; and antigen–antibody and protein–carbohydrate eval-

uations were fine-tuned on their respective pre-split datasets. Notably, for nucleic acid–related tasks such as PNI

 and NLI, we included a small portion of PDBbind PNI data in the pretraining stage and subsequently fine-tuned on

 PDBbind PNI. This strategy ensured that the model could learn interaction patterns relevant to nucleic acid com-

plexes during training.

 BioScore: a theoretical introduction

 17









 Many deep learning–based scoring functions utilize custom-designed descriptors to capture key ligand–target in-

teractions, which are then input into prediction algorithms. However, such approaches may essentially overfit the

 mapping between input data and labels without achieving true generalization and typically lack docking and screen-

ing capabilities. In contrast, integrating AI techniques into traditional scoring paradigms—such as force field–based

 or statistical potential–based methods—aligns more closely with intuitive modeling principles. Unlike force field–

based methods, which decompose binding free energy into multiple energy terms, statistical potential–based scoring

functions calculate binding free energy by summing the statistical potentials of molecular pairs within the complex.

The earliest statistical potential approaches derived pairwise distance probability distributions by analyzing

 large datasets of protein–small molecule complex structures, identifying the frequency at which specific (key) atom

 pairs—each atom coming from the protein or the small molecule—appear at particular distances25,29. The underly-

ing rationale is that if a specific atom pair is observed at a particular distance significantly more frequently in the

 experimentally curated complex structures than expected by random chance, this pair is likely to form a favorable

 interaction. In other words, the occurrence frequency of specific atom pair distances is assumed to correlate posi-

tively with their contribution to the binding phenomenon. This intuition can be further formalized mathematically.

 For continuous systems, the Boltzmann distribution can be expressed as:

 𝑝(𝑥) =

!"($) &’

𝑒

𝑍

(1)

 Here,x represents the state of the biomolecular complex, such as the atomic coordinates, that can be used to describe

 the energy of the system as 𝜖(𝑥). When the partition function 𝑍 is explicitly specified, p(x) is a probability density

 function, satisfying:

 (

+ 𝑝(𝑥)𝑑𝑥 = 1 !(

(2)

 From the Boltzmann distribution above, one can then define the potential of mean force (PMF), such as 𝜀)*+(𝑦) ,

 where 𝑦 is a subset of degrees of freedom of interest—eg. Pairwise distance between atom pairs in our context—

that can be extracted from the full molecular configuraton 𝑥. The PMF is related to the probability density via:

 𝜀)*+(𝑦) = −𝐾𝑇𝑙𝑜𝑔 + 𝑝(𝑥)𝛿(𝑚(𝑥) − 𝑦)𝑑𝑥 + 𝐶

(3)

 Where 𝐾 is the Boltzmann constant, 𝑇 is the temperature,

𝑚(𝑥) = 𝑦 being a function to extract the subset of de-

grees of freedom of interest, and 𝐶 is a normalization constant. This formulation establishes a direct relationship

 between distance distributions and PMF or interaction energy (loosely speaking). In practice, we do not rigorously

 calculate PMF by rigorously performing the integration in Eq. (3) in the context of building a statistical potential.

 Rather, we simply try to use the limited set of available structural data to invert the Boltzmann distribution and

 derive

a

PMF-like

free

energy

contribution.

If

we

can

accurately

determine

or

fit

the

distance

distributions

for

 different atom pairs, we can compute their corresponding statistical potential.



Deep learning techniques are particularly well-suited for modeling such distance distributions. By leveraging

 mixture density network, it is possible to fit distance distributions as a weighted sum of Gaussian components,

 providing a more flexible and accurate representation. This insight has led to the development of methods such as

18





 DeepDock80, RTMScore38, and GenScore55. While these earlier works were primarily limited to protein–small mol-

ecule

systems

due

to

data

availability

constraints,

our

study

demonstrates

that

this

inverse

Boltzmann–inspired

 approach can also be extended to protein–protein, protein–nucleic acid, and other biomolecular complexes, high-

lighting its broad generalizability and value.

 For deep learning–based scoring functions, how to effectively represent atom pair features is a critical chal-

lenge. Previous studies have shown that through careful feature selection, it is possible to achieve effective scoring

 of protein–small molecule complexes at a non-all-atom, fine-grained level. However, to generalize such approaches

 to arbitrary biomolecular complexes, using domain-specific encoding strategies for different biomolecules lacks

 generalizability.

 To address this problem, there are two feasible approaches. The first is to represent all biomolecular compo-

nents

uniformly

at

the

atomic

level.

Since

atoms

are

the

fundamental

building

blocks

of

all

biomolecules,

this

 approach is intuitive. However, atomic-level encoding also has significant limitations: biomolecules differ greatly

 in their molecular forms, and "block"-level units—such as amino acids in proteins or nucleotides in nucleic acids—

encode much richer, domain-specific information than atoms alone. This is why biomolecular language models

 such as ESM81 and DNABERT82 adopt block-level units as their fundamental sequence representations; their suc-

cess highlights the importance of such heuristics in molecular representation learning.

 The second approach is to exclusively encode molecules at the block level, for instance, representing proteins

 only

at

the

residue

level.

This

strategy

can

work

well

within

specific

biomolecular

systems.

For

example,

 RTMScore38

employs

amino

acids

as

the

basic

encoding

unit

for

proteins

to

reduce

computational

complexity.

 However, the high specificity of block-level representations limits the transferability of information across different

 domains.

 Our goal is to develop a foundational scoring function that not only supports arbitrary biomolecular inputs but

 also enables cross-system data complementarity—an essential requirement to address the practical challenge of

 limited data availability beyond protein–small molecule systems.

 In summary, while encoding strategies based solely on atoms or blocks are feasible, they are not optimal for

 building a general-purpose scoring function. To overcome these limitations, we propose a cross-domain molecular

 representation that integrates dual-scale atomic and block-level information. Specifically, we decompose any mo-

lecular entity into block units: for small molecules, blocks correspond to atoms; for proteins, blocks correspond to

 amino acid residues; and for nucleic acids, blocks correspond to nucleobases. The entire molecular complex is then

 represented as a unified graph 𝒢 = (𝒱, ℰ), where the node set 𝒱 = ?@𝐻,, 𝑋-CCC⃗EF1 ≤ 𝑖 ≤ 𝐵J corresponds to the block

 units. Each node contains a feature matrix and a coordinate matrix. For a block consisting of 𝑛, atoms, the feature

matrix 𝐻, ∈ ℝ.!×0" represents the feature vectors of the atoms, and the coordinate matrix 𝑋, ∈ ℝ.!×1 encodes the

corresponding 3D atomic coordinates. The feature vector for each atom is constructed by combining three learnable

 embeddings: the atomic type, the block type it belongs to, and the relative position of the atom within the block.

 Formally, we define:

 𝑑(𝑖, 𝑗) = 𝑚𝑖𝑛 OP𝑋⃗,[𝑝] − 𝑋⃗2[𝑞]P 3

T	1 ≤ 𝑝 ≤ 𝑛,, 1 ≤ 𝑞 ≤ 𝑛2V

(4)

 19





 It is important to emphasize that the key difference between our approach and previous general-purpose bio-

molecular complex representation learning methods lies in our introduction of a interface-masking encoding strat-

egy.

Specifically,

we

represent

the

entire

complex

as

a

single

graph

but

construct

edges

only

within

individual

 molecular

entities,

deliberately

excluding

inter-molecular

edges.

Prior

works

on

general

biomolecular

complex

 representation learning were primarily designed to better represent different biomolecular systems and interaction

 interfaces, without a specific focus on the unique requirements of scoring function design for complexes.

 As previously discussed, in the design of statistical potential–based scoring functions, appropriate representa-

tion learning should aim to facilitate the neural network—specifically, the mixture density network—in learning a

 reasonable mapping between atom pair representations and the probability density distributions of their distances.

 Our study reveals that in such statistical potential–based frameworks, explicitly exposing the inter-molecular edge

 information during atom pair representation learning leads to inferior mapping results.

 This contrasts with the conventional wisdom in prior general biomolecular complex representation studies,

 which consistently emphasize the importance of inter-molecular edge information for representing biomolecular

 interactions. While this design choice may seem intuitive (as interaction edges appear essential for encoding bio-

molecular interfaces), our investigation demonstrates that for statistical potential–based scoring, incorporating in-

teraction edge information actually bears a detrimental effect.

 Further analysis shows that within the statistical potential modeling framework, inter-molecular edges, though

 commonly used in representation learning to strengthen the modeling of atom pair relationships, introduce signifi-

cant modeling biases. These explicit interaction priors cause the model to receive strong, structure-specific signals

 about the native conformation at the input stage, leading to overly concentrated predictions around the true distances

 in the training samples. This results in a loss of smoothness and generalization in the learned distance distributions,

 effectively causing a structural overfitting. We support this analysis with evidence from the validation loss curves

 (Figure S1). Moreover, representing the entire complex as a single graph—rather than adopting a dual-branch ar-

chitecture where each molecular entity is modeled independently—offers a key advantage: it provides a unified

 representation format for different types of complexes. Without this design, each biomolecular system would re-

quire a dedicated encoder, undermining the model’s generality and limiting its capacity to integrate information

 across domains.

 In addition to the interface-masking strategy, another noteworthy technical detail of our approach is the design

 of a distance-threshold-based edge construction strategy for both intra- and inter-molecular edges. Traditional edge

 construction strategies generally fall into two categories. The first is the exhaustive enumeration approach, where

 all pairwise distances between atoms in interacting biomolecules are precomputed. This method was employed in

 our previous works, RTMScore38,55 and GenScore. However, this approach suffers from low computational effi-

ciency, particularly when extending beyond protein–small molecule complexes (which typically feature binding

 interfaces with median sizes of 300–1500 Å²) to larger biomolecular systems16, such as protein–protein complexes,

 where the median interface size ranges from 2000 to 4000 Å². The second common strategy is the k-nearest neigh-

bors approach, where a fixed number of intra- and inter-molecular edges are assigned to each atom. While more

 20





 efficient, this method discards valuable information inherent in the number of edges itself. For example, in classical

 statistical potential–based methods, the total binding free energy is computed by summing the contributions from

 key atom pairs, implicitly capturing the principle that a larger number of critical interaction edges tends to correlate

 with stronger binding affinity.

 To preserve this information and enable the incorporation of interaction edge count–aware confidence scores,

 we predefined distance thresholds for edge construction: for inter-molecular edges, a uniform threshold of 8 Å was

 applied across all biomolecular complex systems, such that only atom pairs within 8 Å (from different molecular

 entities) are connected by inter-molecular edges. For intra-molecular edges, we applied system-specific thresholds:

 2 Å for small molecules and 10 Å for proteins and nucleic acids. Compared to the KNN approach, our distance-

threshold strategy preserves meaningful variations in edge counts. Compared to the exhaustive enumeration ap-

proach, it significantly improves computational efficiency while maintaining the critical interaction patterns re-

quired for accurate scoring.

 To enable a unified representation of such complex systems, we adopted GET (Geometric Equivariant Trans-

former) as the encoder, following the design introduced by Kong et al.41 This framework effectively captures both

 domain-specific hierarchical structures and general cross-domain physical interaction properties. GET is composed

 of

equivariant

dual-level

attention

modules,

feedforward

modules,

and

layer

normalization

modules,

with

each

 component being E(3)-equivariant. In each layer of GET, the equivariant dual-level attention module first jointly

 models block-level and atom-level interactions. The equivariant feedforward module then updates atomic features

 within each block by incorporating geometric information from the block as a whole. Finally, the equivariant layer

 normalization module ensures invariance of the model under molecular rotations and translations. Specifically, in

 the equivariant dual-level attention module, for two blocks 𝑖 and 𝑗 composed of 𝑛, and 𝑛2 atoms, respectively, the

 atom-level cross-attention between blocks 𝑖 and 𝑗 is computed as:

 𝑅,2[𝑝, 𝑞] = 𝑀𝐿𝑃4 \𝑄,[𝑝], 𝐾2[𝑞], 𝑅𝐵𝐹@𝐷,2[𝑝, 𝑞], 𝑒,2E‘

𝛼,2 = 𝑆𝑜𝑓𝑡𝑚𝑎𝑥@𝑅,2𝑊4E

(5)

 (6)

 Here, 𝑅,2[𝑝, 𝑞] represents the interaction information matrix between each pair of atoms from blocks 𝑖 and 𝑗. 𝑀𝐿𝑃4

 is used to compress the input features into interaction information vectors. 𝑄,[𝑝] denotes the query feature of atom

 𝑝 in block 𝑖, 𝐾2[𝑞] denotes the key feature of atom 𝑞 in block 𝑗, 𝐷,2[𝑝, 𝑞] is the Euclidean distance between atoms

 𝑝 and 𝑞, and 𝑒,2 represents the distance feature between blocks 𝑖 and 𝑗. The pairwise atomic distances are embed-

ded using radial basis functions (RBF). A learnable linear projection weight 𝑊4 ∈ ℝ0#×5 is applied to map 𝑅,2 ∈ ℝ.!×.$×0# into scalar values. These scalar values are then passed through a softmax function to obtain the atom- level cross-attention 𝛼,2 ∈ ℝ.!×.$ between blocks 𝑖 and 𝑗. The block-level cross-attention between blocks 𝑖 and 𝑗

 is computed by aggregating the atom-level attention values as follows:

 𝑟,2 =

1 𝑛,𝑛2

.$

.! j j 𝑅,2[𝑝, 𝑞] )75

675

(7)

 21





 The subsequent step updates the hidden states and coordinates of each atom within a block,

 𝛽,2 =

𝑒𝑥𝑝@𝑟,2𝑊8E

∑

9∈𝒩(,)

𝑒𝑥 𝑝(𝑟,9𝑊8)

𝐻,

<[𝑝] = 𝐻,[𝑝] + j 𝛽,2𝑀𝐿𝑃=@𝑚,2,)E 2?𝒩(,)

<[𝑝] = 𝑋⃗,[𝑝] + j 𝛽,2@𝑀𝐿𝑃@@𝑚,2,)E ∙ 𝑚CC⃗,2,)E 𝑋⃗ ,

2?𝒩(,)

(8)

 (9)

 (10)

 Taking block 𝑖 as an example, the hidden state of each atom 𝑝 is updated by computing a weighted sum of the

 original feature 𝐻,[𝑝] and the aggregated information 𝑚,2,) from its neighboring blocks 𝑗

where the weights for

 different neighboring blocks are determined by the block-level attention coefficient 𝛽,2. For coordinate updates, the

 direction shift vector 𝑚CC⃗,2,)

is scaled by an element-wise product with the scalar coefficient 𝑀𝐿𝑃@@𝑚,2,)E, and the

 resulting vectors are aggregated across neighboring blocks using the same block-level attention weights 𝛽,2. In the

 subsequent equivariant feedforward network module, the hidden states and coordinates of each atom within a block

 are further updated, enabling each atom to learn the geometric information of its corresponding block,

 ℎ< = ℎ + 𝑀𝐿𝑃A@ℎ, ℎB, 𝑅𝐵𝐹(‖(𝑥⃗ − 𝑥BCCC⃗)‖3)E

𝑥⃗< = 𝑥⃗ + (𝑥⃗ − 𝑥BCCC⃗)𝑀𝐿𝑃$@ℎ, ℎB, 𝑅𝐵𝐹(‖(𝑥⃗ − 𝑥BCCC⃗)‖3)E

(11)

 (12)

 Here, ℎB and 𝑥BCCC⃗ denote the hidden state and coordinates of the centroid of the block to which the atom belongs. To

 ensure E(3)-equivariance, we apply equivariant layer normalization to the atomic coordinates. Specifically, we first

 extract the centroid of the entire graph, 𝔼u𝑋⃗v, where 𝑋⃗ represents the coordinates of all atoms across all blocks in

 the graph. We then apply layer normalization to both the hidden states and the coordinates as follows:

 ℎ< =

ℎ − 𝔼[ℎ]

w𝑉𝑎𝑟[ℎ]

∙ 𝛾 + 𝛽

𝑋⃗ − 𝔼u𝑋⃗v

𝑋⃗ < =

∙ 𝜎 + 𝔼u𝑋⃗v

z𝑉𝑎𝑟 {𝑋⃗ − 𝔼u𝑋⃗v|

(13)

 (14)

where 𝛾, 𝛽, 𝜎 are

learnable

parameters,

and 𝑉𝑎𝑟[∙] denotes

the

variance

computed

relative

to

the

centroid. This

 process ensures that, after subtracting the centroids of all atoms, the coordinates are normalized and scaled accord-

ing to a standard Gaussian distribution.

 Based on the above framework, we can effectively use a mixture density network to model the mapping be-

tween block pair representations and their corresponding distance probability density distributions. Specifically, we

 first concatenate the features of block pairs within the complex (denoted as receptor and ligand to represent the two

 molecular entities in the complex):

 BC*)DE$ = 𝐶𝑜𝑛𝑐𝑎𝑡\ℎ, ℎ,,2

D,FG.0, ℎ2

HEB)ICH‘

The concatenated block pair feature is then transformed via an Multilayer Perceptron (MLP):

 BC*)DE$ = 𝑀𝐿𝑃\ℎ,,2 𝐼,,2

BC*)DE$‘

(15)

 (16)

 22







 The parameters of the Gaussian components in the mixture density network—namely the means	𝜇, standard devi-

ations 𝜎, and mixture coefficients 𝛼—are obtained via three simple linear layers applied to 𝐼,,2

BC*)DE$:

 𝜇,,2 = 𝐸𝐿𝑈\𝑊J𝐼,,2

BC*)DE$ + 𝑏J‘ + 1.0

𝜎,,2 = 𝐸𝐿𝑈\𝑊K𝐼,,2

BC*)DE$ + 𝑏K‘ + 1.1

𝛼,,2 = 𝑆𝑜𝑓𝑡𝑚𝑎𝑥\𝑊L𝐼,,2

BC*)DE$ + 𝑏L‘

(17)

 (18)

 (19)

 where 𝑊J, 𝑊K, 𝑊L, 𝑏J, 𝑏K, 𝑏L are learnable parameters of the respective linear layers. The probability density dis-

tribution of the distance for a single block pair can then be expressed as:

 5M

𝑃\𝑑,,2

BC*)DE$T𝐼,,2

BC*)DE$‘ = j 𝛼,,2,.𝒩\𝑑,,2

BC*)DE$T𝜇,,2,., 𝜎,,2,.‘

(20)

 As previously shown in Equation (3), based on the inverse Boltzmann relationship between probability density and

 energy, the calculation of statistical-potential-approximated binding free energy in prior studies typically follows

 .75

the formula:

 0!$	O	BPIC++	

∆𝐺 = −𝐾𝑇 j 𝑙𝑛 \𝑃@𝑑,2F𝐼,2E‘

,2

(21)

 where the cutoff indicates that only block pairs within a predefined distance threshold contribute to the final binding

 free energy calculation. However, based on the fundamental equation for binding free energy, we know that:

 ∆𝐺 = 𝐺QCP.0 − 𝐺P.QCP.0 = 𝐸QCP.0

,.IEH + 𝐸QCP.0

,.IHG − 𝐸P.QCP.0

,.IHG

(22)

 Traditional

statistical-potential–based

scoring

functions

essentially

compute

only

the

interaction

term

under

the

 bound state:

 &’()*+,	O	BPIC++	 0!,$

,.IEH = −𝐾𝑇

𝐸QCP.0

j ,,2

𝑙𝑛 (cid:135)𝑃\𝑑,,2

BC*)DE$T𝐼,,2

BC*)DE$‘(cid:136)

(23)

 In other words, they estimate the relative binding free energy by ignoring the contribution arising from the confor-

mational rearrangements of individual molecules upon complex formation. To approximate the absolute binding

 free energy, these methods assume no significant energetic differences due to conformational changes in the un- ,.IHG − 𝐸P.QCP.0 pose a dual-tower scoring module that separately handles docking/screening and scoring/ranking tasks. First, we

 bound state, i.e. many methods simply ignore 𝐸QCP.0



in Eq. (22). To address this limitation, we pro-

,.IHG

retain the core principle of the traditional statistical potential approach as summarized above. However, we explic-

itly treat the computed energy as a relative binding free energy rather than an absolute one. At the same time, we

 recognize an inherent drawback of the traditional statistical potential methods: they compute the total binding en-

ergy by summing the log-transformed probability densities of key atom pairs (i.e., those within a predefined dis-

tance cutoff). This design can inadvertently assign artificially high scores to implausible complex conformations,

 where each individual edge may have a low score, but the accumulation of many unreasonable edges leads to an

 23





 overall unreasonably high score. To mitigate this issue, we simply weight the summation by the number of contri-

butions. This change prevents the model from overestimating the contributions of unfavorable conformations due

 to sheer amount of atom pairs. Meanwhile, we preserve a key advantage of the summation formulation—namely,

 the implicit positive correlation between the number of effective interaction edges and binding affinity. To capture

 this, we introduce an interaction edge count–aware confidence score as an additional scoring term. Specifically:

 𝑈B)D$	 =

1

𝑛

&’()*+,OBPIC++

,,2|0!,$

&’()*+,

0!,$

	O	BPIC++	

j ,2

𝑙 𝑛 (cid:135)𝑃\𝑑,,2

BC*)DE$T𝐼,,2

BC*)DE$‘(cid:136)

𝑆𝑐𝑜𝑟𝑒 = −𝑈B)D$ + 𝑙𝑜𝑔 (cid:135)𝑛

&’()*+,OBPIC++(cid:136)

,,2|0!,$

(24)

 (25)

 We demonstrate that the modified output formulation significantly improves docking and screening capabili-

ties in both PPI and PLI tasks, exhibiting strong generalizability across different biomolecular complex systems.

 We designate this output score as the first output mode of the scoring function, specifically tailored for docking and

 screening workflows across arbitrary biomolecular complexes. This score provides the capability to (1) distinguish

 native-like

from

non-native

binding

conformations

(docking)

and

(2)

differentiate

active

from

inactive

ligands

 (screening) across various biomolecular systems. Furthermore, we extend the block pair representations learned by

 the model to define a second output mode for the scoring function. Here, an MLP is used to learn the mapping

 between block pair representations and binding free energy values. The final output score is computed as the mean

 of

these

pairwise

contributions,

while

the

interaction

edge

count–aware

confidence

score

is

incorporated

as

an

 auxiliary output term. This second output mode is used for scoring and ranking workflows across arbitrary bio-

molecular complexes:

 𝑈B)D$ = 	

1

𝑛

&’()*+,SBPIC++

,,2|0!,$

&’()*+,

0!,$

S	BPIC++	

j ,,2

𝑀𝐿𝑃\𝐼,,2

BC*)DE$‘

𝑆𝑐𝑜𝑟𝑒 = −𝑈B)D$ + 𝛼T ∗ 𝑙𝑜𝑔 (cid:135)𝑛

&’()*+,OBPIC++(cid:136)

,,2|0!,$

(26)

 (27)

 where 𝛼T are learnable parameters.

 To achieve a balance among the four capabilities of scoring, ranking, docking, and screening, we propose a

 pretraining–fine-tuning strategy. In the pretraining stage, we utilize only the structural data from various biomolec-

ular complexes to train the mixture density network module. By minimizing the negative log-likelihood loss to

 maximize the probability density values of block pair distances, the model learns generalizable structural features

 that enable docking and screening capabilities. The loss function for this stage is defined as:

 ℒUHEIHG,. = ℒVWX =

1

𝑛

&’()*+,SBPIC++

,,2|0!,$

&’()*+,

0!,$

S	BPIC++	

j ,,2

−𝑙𝑛𝑃\𝑑,,2

BC*)DE$T𝐼,,2

BC*)DE$‘

(28)

 24





 In the subsequent fine-tuning stage, labeled data from different biomolecular complexes (i.e., complexes with

 both structural and binding affinity annotations) are used for task-specific fine-tuning within each biomolecular

 system. The loss function for this stage is defined as:

 ℒY,.EIP.E = 𝑎 × ℒVZ[ + 𝑏 × ℒ\CHHEDGI,C. + 𝑐 × ℒVWX

(29)

 where 𝑎, 𝑏, 𝑐 are empirically defined hyperparameters, with default values set to 0.5, 5, and 1, respectively. During

 pretraining, the distance threshold is set to 7 Å, whereas in the fine-tuning stage and the dual-tower scoring outputs,

 it is set to 5 Å. Experiments were conducted on NVIDIA L20 GPUs (48 GB VRAM). The model is trained using

 the Adam optimizer. The hyperparameter settings for both the pretraining and fine-tuning stages are summarized

 in Table S18.

 Acknowledgement

 CYH acknowledges support from National Ke Research and Development Program of China (2024FA1306400) and Natural

Science Foundation of China (22373085).

 25











 References

 1. Fei, N. et al. Towards artificial general intelligence via a multimodal foundation model. Nat. Commun. 13, 3094

 (2022).

 2. Topol, E. J. Learning the language of life with AI. Science 387, eadv4414 (2025).

 3. Mitchell, M. Debates on the nature of artificial general intelligence. Science 383, eado7069 (2024).

 4. Hafner, D., Pasukonis, J., Ba, J. & Lillicrap, T. Mastering diverse control tasks through world models. Nature

 640, 647–653 (2025).

 5. Zhang, K. et al. Artificial intelligence in drug development. Nat. Med. 31, 45–59 (2025).

 6. Yuksekgonul, M. et al. Optimizing generative AI by backpropagating language model feedback. Nature 639,

 609–616 (2025).

 7. Moor, M. et al. Foundation models for generalist medical artificial intelligence. Nature 616, 259–265 (2023).

 8. Li, Q. et al. Progress and opportunities of foundation models in bioinformatics. Brief. Bioinform. 25, bbae548

 (2024).

 9. Guo, F. et al. Foundation models in bioinformatics. Natl. Sci. Rev. 12, nwaf028 (2025).

 10. Baek, M. Towards the prediction of general biomolecular interactions with AI. Nat. Methods 21, 1382–1383

 (2024).

 11. Kong, X. et al. UniMoMo: Unified Generative Modeling of 3D Molecules for De Novo Binder Design. Preprint

 at https://doi.org/10.48550/arXiv.2503.19300 (2025).

 12. Nguyen,

E.

et

al.

Sequence

modeling

and

design

from

molecular

to

genome

scale

with

Evo.

Science

386,

 eado9336 (2024).

 13. Brixi,

G.

et

al.

Genome

modeling

and

design

across

all

domains

of

life

with

Evo

2.

Preprint

at

 https://doi.org/10.1101/2025.02.18.638918 (2025).

 14. Abramson, J. et al. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature 630,

 493–500 (2024).

 15. Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science 379,

 1123–1130 (2023).

 16. Fang, A., Zhang, Z., Zhou, A. & Zitnik, M. ATOMICA: Learning Universal Representations of Intermolecular

 Interactions. Preprint at https://doi.org/10.1101/2025.04.02.646906 (2025).

 17. Zheng, H. et al. AlphaFold3 in Drug Discovery: A Comprehensive Assessment of Capabilities, Limitations, and

 Applications. Preprint at https://doi.org/10.1101/2025.04.07.647682 (2025).

 18. Senior, A. W. et al. Improved protein structure prediction using potentials from deep learning. Nature 577, 706–

710 (2020).

 19. Callaway, E. AlphaFold is running out of data — so drug firms are building their own version. Nature 640, 297–

298 (2025).

 20. Arnold, C. AlphaFold touted as next big thing for drug discovery — but is it? Nature 622, 15–17 (2023).

 26





 21. Siebenmorgen, T. et al. MISATO: machine learning dataset of protein–ligand complexes for structure-based

 drug discovery. Nat. Comput. Sci. 4, 367–378 (2024).

 22. Krishna, R. et al. Generalized biomolecular modeling and design with RoseTTAFold All-Atom. Science 384,

 eadl2528 (2024).

 23. Fang, X. et al. A method for multiple-sequence-alignment-free protein structure prediction using a protein lan-

guage model. Nat. Mach. Intell. 5, 1087–1096 (2023).

 24. Zhang, X. et al. Efficient and accurate large library ligand docking with KarmaDock. Nat. Comput. Sci. 3, 789–

804 (2023).

 25. Shirali, A. et al. A comprehensive survey of scoring functions for protein docking models. BMC Bioinformatics

 26, 25 (2025).

 26. Ain, Q. U., Aleksandrova, A., Roessler, F. D. & Ballester, P. J. Machine‐learning scoring functions to improve

 structure‐based binding affinity prediction and virtual screening. WIREs Comput. Mol. Sci. 5, 405–424 (2015).

 27. Gabel, J., Desaphy, J. & Rognan, D. Beware of Machine Learning-Based Scoring Functions—On the Danger

 of Developing Black Boxes. J. Chem. Inf. Model. 54, 2807–2815 (2014).

 28. Shen, C. et al. Beware of the generic machine learning-based scoring functions in structure-based virtual screen-

ing. Brief. Bioinform. 22, bbaa070 (2021).

 29. Li, J., Fu, A. & Zhang, L. An Overview of Scoring Functions Used for Protein–Ligand Interactions in Molecular

 Docking. Interdiscip. Sci. Comput. Life Sci. 11, 320–328 (2019).

 30. Vangone, A., Oliva, R., Cavallo, L. & Bonvin, A. M. J. J. Prediction of Biomolecular Complexes. in From

 Protein Structure to Function with Bioinformatics (ed. J. Rigden, D.) 265–292 (Springer Netherlands, Dordrecht,

 2017). doi:10.1007/978-94-024-1069-3_8.

 31. Jiang, D. et al. InteractionGraphNet: A Novel and Efficient Deep Graph Representation Learning Framework

 for Accurate Protein–Ligand Interaction Predictions. J. Med. Chem. 64, 18209–18232 (2021).

 32. Sim, J., Kim, D., Kim, B., Choi, J. & Lee, J. Recent advances in AI-driven protein-ligand interaction predictions.

 Curr. Opin. Struct. Biol. 92, 103020 (2025).

 33. Van Kooyk, Y. & Rabinovich, G. A. Protein-glycan interactions in the control of innate and adaptive immune

 responses. Nat. Immunol. 9, 593–601 (2008).

 34. Sun, X., Setrerrahmane, S., Li, C., Hu, J. & Xu, H. Nucleic acid drugs: recent progress and future perspectives.

 Signal Transduct. Target. Ther. 9, 316 (2024).

 35. Liu, H. et al. PPB-Affinity: Protein-Protein Binding Affinity dataset for AI-based protein drug discovery. Sci.

 Data 11, 1316 (2024).

 36. Stahl, K. et al. Modelling protein complexes with crosslinking mass spectrometry and deep learning. Nat. Com-

mun. 15, 7866 (2024).

 37. Baek, M. et al. Accurate prediction of protein–nucleic acid complexes using RoseTTAFoldNA. Nat. Methods

 21, 117–121 (2024).

 27





 38. Shen,

C.

et

al.

Boosting

Protein–Ligand

Binding

Pose

Prediction

and

Virtual

Screening

Based

on

Residue–

Atom Distance Likelihood Potential and Graph Transformer. J. Med. Chem. 65, 10691–10706 (2022).

 39. Koh, H. Y., Nguyen, A. T. N., Pan, S., May, L. T. & Webb, G. I. Physicochemical graph neural network for

 learning protein–ligand interaction fingerprints from sequence data. Nat. Mach. Intell. 6, 673–687 (2024).

 40. Zhu, Y. et al. A Generalist Cross-Domain Molecular Learning Framework for Structure-Based Drug Discovery.

 Preprint at https://doi.org/10.48550/arXiv.2503.04362 (2025).

 41. Kong, X., Huang, W. & Liu, Y. Generalist Equivariant Transformer Towards 3D Molecular Interaction Learn-

ing. Preprint at https://doi.org/10.48550/arXiv.2306.01474 (2024).

 42. Groom, C. R., Bruno, I. J., Lightfoot, M. P. & Ward, S. C. The Cambridge Structural Database. Acta Crystallogr.

 Sect. B Struct. Sci. Cryst. Eng. Mater. 72, 171–179 (2016).

 43. Su, M. et al. Comparative Assessment of Scoring Functions: The CASF-2016 Update. J. Chem. Inf. Model. 59,

 895–913 (2019).

 44. Wang,

R.,

Fang,

X.,

Lu,

Y.

&

Wang,

S.

The

PDBbind

Database:

Collection

of

Binding

Affinities

for

Pro-

tein−Ligand Complexes with Known Three-Dimensional Structures. J. Med. Chem. 47, 2977–2980 (2004).

 45. Pierce, B. G., Hourai, Y. & Weng, Z. Accelerating Protein Docking in ZDOCK Using an Advanced 3D Convo-

lution Library. PLoS ONE 6, e24657 (2011).

 46. Wang, X., Flannery, S. T. & Kihara, D. Protein Docking Model Evaluation by Graph Neural Networks. Front.

 Mol. Biosci. 8, 647915 (2021).

 47. Chen, X., Morehead, A., Liu, J. & Cheng, J. A gated graph transformer for protein complex structure quality

 assessment and its performance in CASP15. Bioinformatics 39, i308–i317 (2023).

 48. Ullanat, V., Jing, B., Sledzieski, S. & Berger, B. Learning the language of protein-protein interactions. Preprint

 at https://doi.org/10.1101/2025.03.09.642188 (2025).

 49. Pierce, B. & Weng, Z. A combination of rescoring and refinement significantly improves protein docking per-

formance. Proteins Struct. Funct. Bioinforma. 72, 270–279 (2008).

 50. Olechnovič, K. & Venclovas, Č. VoroMQA: Assessment of protein structure quality using interatomic contact

 areas. Proteins Struct. Funct. Bioinforma. 85, 1131–1145 (2017).

 51. Szklarczyk, D. et al. The STRING database in 2023: protein–protein association networks and functional en-

richment analyses for any sequenced genome of interest. Nucleic Acids Res. 51, D638–D646 (2023).

 52. Greenshields-Watson, A., Vavourakis, O., Spoendlin, F. C., Cagiada, M. & Deane, C. M. Challenges and com-

promises: Predicting unbound antibody structures with deep learning. Curr. Opin. Struct. Biol. 90, 102983 (2025).

 53. Schneider, C., Raybould, M. I. J. & Deane, C. M. SAbDab in the age of biotherapeutics: updates including

 SAbDab-nano, the nanobody structure tracker. Nucleic Acids Res. 50, D1368–D1372 (2022).

 54. Ge, J. et al. Deep-learning-based prediction framework for protein-peptide interactions with structure generation

 pipeline. Cell Rep. Phys. Sci. 5, 101980 (2024).

 55. Shen, C. et al. A generalized protein–ligand scoring framework with balanced scoring, docking, ranking and

 screening powers. Chem. Sci. 14, 8129–8146 (2023).

 28





 56. Mysinger, M. M., Carchia, M., Irwin, John. J. & Shoichet, B. K. Directory of Useful Decoys, Enhanced (DUD-

E): Better Ligands and Decoys for Better Benchmarking. J. Med. Chem. 55, 6582–6594 (2012).

 57. Bauer, M. R., Ibrahim, T. M., Vogel, S. M. & Boeckler, F. M. Evaluation and Optimization of Virtual Screening

 Workflows with DEKOIS 2.0 – A Public Library of Challenging Docking Benchmark Sets. J. Chem. Inf. Model.

 53, 1447–1462 (2013).

 58. Cao, D. et al. Generic protein–ligand interaction scoring by integrating physical prior knowledge and data aug-

mentation modelling. Nat. Mach. Intell. 6, 688–700 (2024).

 59. Smith, S. & De Lange, T. Tankyrase promotes telomere elongation in human cells. Curr. Biol. 10, 1299–1302

 (2000).

 60.Karlberg, T. et al. Structural Basis for the Interaction between Tankyrase-2 and a Potent Wnt-Signaling Inhibitor.

 J. Med. Chem. 53, 5352–5355 (2010).

 61. Gromiha, M. M. & Harini, K. Protein-nucleic acid complexes: Docking and binding affinity. Curr. Opin. Struct.

 Biol. 90, 102955 (2025).

 62. Manigrasso, J., Marcia, M. & De Vivo, M. Computer-aided design of RNA-targeted small molecules: A growing

 need in drug discovery. Chem 7, 2965–2988 (2021).

 63. Jiang, D. et al. Assessing the performance of MM/PBSA and MM/GBSA methods. 10. Prediction reliability of

 binding

affinities

and

binding

poses

for

RNA–ligand

complexes.

Phys.

Chem.

Chem.

Phys.

26,

10323–10335

 (2024).

 64. Gerstein, H. C. & Rutty, C. J. Insulin Therapy: The Discovery That Shaped a Century. Can. J. Diabetes 45,

 798–803 (2021).

 65. Martian, P. C. et al. Cyclic peptides: A powerful instrument for advancing biomedical nanotechnologies and

 drug development. J. Pharm. Biomed. Anal. 252, 116488 (2025).

 66. Zhao, H. et al. Comprehensive Evaluation of 10 Docking Programs on a Diverse Set of Protein–Cyclic Peptide

 Complexes. J. Chem. Inf. Model. 64, 2112–2124 (2024).

 67. Garcia Jimenez, D., Poongavanam, V. & Kihlberg, J. Macrocycles in Drug Discovery─Learning from the Past

 for the Future. J. Med. Chem. 66, 5377–5396 (2023).

 68. L’Exact, M. et al. Beyond Rule-of-five: Permeability Assessment of Semipeptidic Macrocycles. Biochim. Bio-

phys. Acta BBA - Biomembr. 1865, 184196 (2023).

 69. De

Schutter,

K.

&

Van

Damme,

E.

Protein-Carbohydrate

Interactions

as

Part

of

Plant

Defense

and

Animal

 Immunity. Molecules 20, 9029–9053 (2015).

 70. Abayakoon,

P.

et

al.

Structural

and

Biochemical

Insights

into

the

Function

and

Evolution

of

Sulfoquinovo-

sidases. ACS Cent. Sci. 4, 1266–1273 (2018).

 71. Nguyen, T. B., Pires, D. E. V. & Ascher, D. B. CSM-carbohydrate: protein-carbohydrate binding affinity pre-

diction and docking scoring function. Brief. Bioinform. 23, bbab512 (2022).

 72. Siva Shanmugam, N. R., Jino Blessy, J., Veluraja, K. & Gromiha, M. M. Prediction of protein–carbohydrate

 complex binding affinity using structural features. Brief. Bioinform. 22, bbaa319 (2021).

 29





 73. Pires, D. E. V. & Ascher, D. B. CSM-lig: a web server for assessing and comparing protein–small molecule

 affinities. Nucleic Acids Res. 44, W557–W561 (2016).

 74. Copoiu, L., Torres, P. H. M., Ascher, D. B., Blundell, T. L. & Malhotra, S. ProCarbDB: a database of carbohy-

drate-binding proteins. Nucleic Acids Res. 48, D368–D375 (2020).

 75. Siva Shanmugam, N. R., Jino Blessy, J., Veluraja, K. & Michael Gromiha, M. ProCaff: protein–carbohydrate

 complex binding affinity database. Bioinformatics 36, 3615–3617 (2020).

 76. Gao, M., Moumbock, A. F. A., Qaseem, A., Xu, Q. & Günther, S. CovPDB: a high-resolution coverage of the

 covalent protein–ligand interactome. Nucleic Acids Res. 50, D445–D450 (2022).

 77. Guo, X.-K. & Zhang, Y. CovBinderInPDB: A Structure-Based Covalent Binder Database. J. Chem. Inf. Model.

 62, 6057–6068 (2022).

 78. Du, H. et al. CovalentInDB 2.0: an updated comprehensive database for structure-based and ligand-based co-

valent inhibitor design and screening. Nucleic Acids Res. 53, D1322–D1327 (2025).

 79. Szymborski, J. & Emad, A. A flaw in using pre-trained pLLMs in protein-protein interaction inference models.

 Preprint at https://doi.org/10.1101/2025.04.21.649858 (2025).

 80. Méndez-Lucio, O., Ahmad, M., Del Rio-Chanona, E. A. & Wegner, J. K. A geometric deep learning approach

 to predict binding conformations of bioactive molecules. Nat. Mach. Intell. 3, 1033–1039 (2021).

 81. Hayes, T. et al. Simulating 500 million years of evolution with a language model. Science 387, 850–858 (2025).

 82. Ji, Y., Zhou, Z., Liu, H. & Davuluri, R. V. DNABERT: pre-trained Bidirectional Encoder Representations from

 Transformers model for DNA-language in genome. Bioinformatics 37, 2112–2120 (2021).

 30



















 Tables

 Table 1.PPI Benchmark Test Resultsa.

 &D"E)GH

!"#AB

KA/EM"G N!&O !PO

BOV

;C:Z

BKKeIiMO e;C:d

IKE"kP

;C;<

M"E"!kP

e;C<;

aCEc

dCIc

dCI;

dCcg

aCad

dCac

dCad

dC<d

lNPKm:

e;C;g

<a<CdZ EdCaE

!nKV

o)"&D"EA

!"$%

;CcI

&"’(

:C:c

&")(

<CIZ

I"D-)GH

&DEAAG)GH

&QA/ER/GS TPBB8

&QA/ER/GS TV"QS:;8

&N TV"QS<8

&N TV"QSZ8

&N TV"QS<;8

>)?S TV"QS<8

&N<@

&NZ@ &N<;@

PAAE/HAS N/G-

;Cc;

;C<<

;C<I

!"#$

;Ca;

e

;CIc

e;C;I

e;C<Z

;C<d

;C:g

;C;;@ ;C;;@ aCg;@ :ICZg@

<C:d@ ZC;I@ <:CII@ aZCZd

;C;;@ <C:d@ :CZa@ :cC;Z@

:CZa@ ICaa@ <ZC<E@ aICac

ZCd<@ <ZCd<@ :;C;;@ aZCd<@

IC;I@ EC;E@ :ZCdI@ a;C:<

:cC;Z@ c<Cdd@ IaC:E@ IECI:@

<C:d@ ICaa@ <ICcI@ :IC::

e;C<g

;C;;@ ;C;;@ ;C;;@ :ICZg@

ZC;I@ gCgI@ :<CZ:@ a<C<a

e

e

e

e

e

:CZa@ ICaa@ <ICcI@ aIC<Z

!"**

&!!"!!+ &!!"!!+ &!!"!!+ &!!"!!+ &*"&%+ )("%&+ $&"##+ (&"*$

aBoth GET and MINT were trained using the same training data as BioScore. Since MINT is designed exclusively

 for protein–protein complexes, it was fine-tuned on the same PPI training data as BioScore, using the pretrained

 weights as released in the original MINT publication. In contrast, GNN-DOVE and DProQA were evaluated using

 the original model weights provided in their respective publications, as their training strategies differ from ours.

 Additionally, MINT accepts only sequence-based inputs and therefore lacks the capability to score different con-

formations of the same sequence, which limits its docking evaluation capability.

 31











 Figures

a

Protein-Ligand Interaction

Protein-Protein Interaction

Protein-Nucleic Acid Interaction

Nucleic Acid-Ligand Interaction

BioScore: A Foundational Scoring Function For Generalized Biomolecular Complexes

Scoring Power

Ranking Power

Docking Power

Screening Power

∆Gbind 	𝟏	

∆Gbind 	𝟐

∆Gbind 	𝟏	

> ∆Gbind 	𝟏′

√

×

√

×

b

Unified Representation

c

Interface-Masking Encoding Strategy

Block-level

Atom-level

intra edges

inter edges

Ligand

Protein

Nucleic acid

determined by distance cut-off

d

Complex Graph

Pairwise Concatenation

Mixture Density Network

Feature

Dist.

A

1

1

B

1

2

1 …

1

2

N

2

2 …

… …

N

N

i

L n e a r

α

μ

σ

PDBbind

e

Dual-Tower Scoring Module

f

Unified Feature Extraction

p Scoring & Ranking pipeline

p Docking & Screening pipeline

𝑺𝒄𝒐𝒓𝒆 = −𝑼𝒄𝒑𝒍𝒙 + 𝜶𝜽 ∗ 𝒍𝒐𝒈(𝒏𝒊𝒋|𝒅𝒊𝒋<𝒄𝒖𝒕𝒐𝒇𝒇)

i

L n e a r

i

L n e a r

i

L n e a r

A t o m - L e v e l

C r o s s A

t t e n t i o n

M e a n

S o f t

m a x

x

S u m

+

x

S u m

+

x N

E q u i v a r i a n t L a y e r N o r m

E q u i v a r i a n t F e e d

- F o r w a r d

E q u i v a r i a n t L a y e r N o r m

. . .

l

B o c k E m b e d d n g

i

32



























 Figure 1. Overview of BioScore.

 (A)

BioScore

Description.

BioScore

accepts

complex

structure

inputs

across

diverse

biomolecular

systems

and

 provides four core capabilities: scoring, ranking, docking, and screening.

 (B) Dual-Scale Representation. BioScore incorporates both atomic- and block-level information, where blocks cor-

respond to atoms for small molecules, amino acid residues for proteins, and nucleotides for nucleic acids.

 (C) Interface-Masking Encoding and Distance-Threshold-Based Edge Construction. BioScore intentionally masks

 inter-molecular edges and retains only intra-molecular edges, enhancing the model’s ability to capture and fit true

 spatial distances.

 (D) Pretraining Strategy. The model trains a mixture density network by minimizing the negative log-likelihood to

 maximize the probability density of atom pair distances, enabling docking and screening capabilities.

 (E) Fine-Tuning Strategy and Dual-Tower Scoring Module. BioScore employs a dual-tower design, with one branch

 for docking and screening tasks and another for scoring and ranking tasks. In the docking/screening pathway, the

 model constructs statistical potentials based on the inverse Boltzmann distribution, outputs energy via averaging

 (instead of summation), and incorporates an interaction edge count–aware confidence score as an auxiliary term.

 In the scoring/ranking pathway, the model fits the nonlinear relationship between atom pair representations and

 binding free energy using a neural network, outputs the mean score as the primary output, and adds an interaction-

aware confidence term.

 (F) Feature Extraction Module. BioScore integrates a general equivariant Transformer for feature extraction.

 33











 a Data Curation and Preparation

a) Resolution ≤ 3.5 Å (X-ray only)

b) Affinity measured as Kd

a) Strict dimers

c) No undefined amino acid residues

b) Clearly defined affinity

d) No non-protein macromolecular polymers

Initial dataset: PDBbind

e) Chain length < 500 aa

f) Sequence identity ≤ 30%

2852 PPIs

913 PPIs

177 PPIs

b Preparation of the PPI Benchmark-Socring power

A: 0 -50 aa

B: 50 -250 aa C: 250 -500 aa

A-B: 46 PPIs

A-C: 27 PPIs

Random sample

B-B: 58 PPIs

B-C: 46 PPIs

177 PPIs

79 PPIs

c Preparation of the PPI Benchmark-Docking power

Receptor

ZDOCK

Compute DockQ

DockQ-based

diversity sampling

30,000 decoys for each target total 2370,000 decoys

79 PPIs

Ligand

100 decoys for each target

total 7979 poses

 d Preparation of the PPI Benchmark-Screening power

Cross Docking

Receptor

ZDOCK

K-means

Random Sample

600 decoys for each binder

(True / Pseudo)

 79 PPIs

Ligand

100 decoys for each binder total 613900 poses

Figure 2. Workflow for Constructing the PPI Benchmark.

 (A) Filtering and selection of the foundational complex dataset. A total of 177 protein–protein complexes were

 selected from PDBbind based on multiple criteria, and further filtered by chain length diversity to obtain a final set

 of 79 complexes as the foundational dataset.

 34







 (B) Construction of the scoring test set. The scoring test set consists of 79 native complexes with corresponding

 experimental binding affinity annotations.

 (C) Construction of the docking test set. For each native complex, ZDOCK was used to generate decoy confor-

mations, and a total of 7,979 decoys were selected to ensure a balanced distribution of DockQ scores.

 (D) Construction of the screening test set. The screening test set was created by cross-docking 79 receptor–ligand

 pairs. K-means clustering and sampling were used to generate a total of 613,900 conformations.

 35







 a

c

d

e

b

f

36







 Figure 3. Comprehensive Evaluation of BioScore on Protein–Protein Complex Systems.

 (A) Docking performance on the PPI Benchmark. Success rate of identifying high-quality conformations (DockQ

 score ≥ 0.8) based on scoring.

 (B) Docking performance on the PPI Benchmark. Distribution of conformation quality (DockQ scores) for top 1

 and top 5 ranked decoys.

 (C) Screening performance on the PPI Benchmark. Distribution of rank values for the true ligand proteins of 79

 target proteins; lower rank values indicate better ranking.

 (D) Antigen–antibody scoring performance. Binding affinity prediction results of BioScore and baseline models.

 (E) Peptide–MHC-I screening evaluation. Test results of different models based on AUROC and AUPR metrics.

 (F) BioScore performance on peptide–MHC-I screening. Detailed evaluation metrics for different targets.

 37







 a

c

e

f

CASF2016 – Scoring Power

CASF2016 – Docking Power

Distance Map

Energy Contribution Map

CASF2016 – Ranking Power

CASF2016 – Screening Power

b

d

g

Tyr1050

lle1075

Phe1035

Pro1034

Phe1061

Gly1032

Ser1068

Figure 4. BioScore Performance on the Protein–Small Molecule Benchmark CASF-2016.

 (A) Scoring performance on CASF-2016, evaluated by the Pearson correlation coefficient.

 (B) Ranking performance on CASF-2016, evaluated by the Spearman correlation coefficient.

 (C) Docking performance on CASF-2016, evaluated by the docking hit rate (including native poses).

 (D) Screening performance on CASF-2016, evaluated by enrichment factors.

 (E) The distance map of residue-atom interactions for the 3KR8 complex.

 (F) The energy contribution map of residue-atom interactions for the 3KR8 complex, as calculated by BioScore.

 (G) Visualization of key molecular interactions in the 3KR8 complex. Highlighted residues denote critical interac-

tion sites; hydrogen bonds are represented by black dashed lines.

 Only the top 10 methods for each test are shown here. Additional methods and results for all test metrics are pro-

vided in the Supplementary Information.

 38









 a

PNI train set

PNI test set

NLI test set

b

81 (29.3%)

2

5 162 (29.2%)

18 (13.4%)

193 (69.9%)

387 (69.9%)

134 (86.6%)

DNA

RNA

DNA / RNA Hybrid

c

Protein-DNA / RNA Interaction

d

DNA / RNA-Ligand Interaction

e

RNA-Ligand Interaction

f

Protein-DNA / RNA Interaction

g

DNA / RNA-Ligand Interaction

h

RNA-Ligand Interaction

RMSE = 1.58 MAE = 1.24

RMSE = 1.91 MAE = 1.60

RMSE = 2.02 MAE = 1.75

Figure 5. BioScore Evaluation on Protein–Nucleic Acid and Nucleic Acid–Small Molecule Complexes.

 (A) Data distribution of DNA, RNA, and mixed DNA–RNA complexes across the PNI training set, PNI test set,

 and NLI test set.

 (B) Distribution of experimental binding affinity values in the PNI training set.

 (C) Scoring performance on the PNI test set, evaluated by the Spearman correlation coefficient.

 (D) Scoring performance on the NLI test set, evaluated by the Pearson correlation coefficient.

 (E) Scoring performance on the RNA–small molecule subset of the NLI test set, evaluated by the Pearson correla-

tion coefficient.

 (F) Detailed scoring results of BioScore on the PNI test set.

 39







 (G) Detailed scoring results of BioScore on the NLI test set.

 (H) Detailed scoring results of BioScore on the RNA–small molecule test set.

 40







 a

b

d

g

c

?

Protein-Ligand Interaction

Protein-Protein Interaction

Protein-Cyclopeptide Interaction

Protein-Macrocycle Interaction

e

f

RMSE = 1.36 MAE = 1.09

Protein-Carbohydrate Interaction

h

Figure 6. BioScore Performance on Specialized Biomolecular Complexes (Protein–Cyclic Peptide, Protein–

Non-Peptidic Macrocycle, and Protein–Carbohydrate Systems).

 (A) Schematic of the chemical space positions of cyclic peptides and non-peptidic macrocycles in complex with

 proteins, highlighting their location at the interface between protein–protein and protein–small molecule systems.

 (B) Structural illustration of protein–cyclic peptide complexes and standalone cyclic peptide molecules.

 (C) Protein–cyclic peptide scoring performance on the CPSet benchmark.

 41







 (D) Structural illustration of protein–non-peptidic macrocycle complexes and standalone non-peptidic macrocycle

 molecules.

 (E) Scoring performance on the protein–non-peptidic macrocycle benchmark.

 (F) Structural illustration of protein–carbohydrate complexes and standalone carbohydrate molecules.

 (G) Scoring performance on the protein–carbohydrate benchmark.

 42



































































 Supporting Information

 BioScore: A Foundational Scoring Function For Diverse Biomolecular

 Complexes

 Yuchen Zhu#1, Jihong Chen#1, Yitong Li#1, Xiaomin Fang2, Xianbin Ye2, Jingzhou He2, Xujun Zhang1, Jingxuan

 Ge1, Chao Shen3, Xiaonan Zhang2*, Tingjun Hou1,3,4*, Chang-Yu Hsieh1,3,4*

 1 College of Pharmaceutical Sciences, Zhejiang University, Hangzhou, 310058, China

 2 Baidu Online Network Technology (Beijing) Co., Ltd. Beijing, 100085, China

 3 The First Affiliated Hospital, College of Medicine, Zhejiang University , Hangzhou , 310058, China

 4 Zhejiang Provincial Key Laboratory for Intelligent Drug Discovery and Development, Jinhua, 321016,

 Zhejiang, China

 Chang-Yu Hsieh

 E-mail: kimhsieh@zju.edu.cn

 Tingjun Hou

 E-mail: tingjunhou@zju.edu.cn

 Xiaonan Zhang

 E-mail: zhangxiaonan@baidu.com

 #These authors contributed equally.

 43















 1. Supplementary Tables

 Table S1. Summary of Baseline Methods

Method

GET

GNN-DOVE

DProQA

VoroMQA

ZRANK2

MINT

AutoDock Vina

RTMScore

EquiScore

Glide SP

PIGNet

3D-GNN

TANKBind

DeepDock

Kdeep

deltaVinaRF

RFScorev4

NNScore2.0

OnionNet

pafuncy

PIGNet2

ASE@MOE

ASP@GOLD

Affinity-dG@MOE

Alpha-HB@MOE

ChemPLP@GOLD

ChemScore@GOLD

ChemScore@SYBYL

D-Score@SYBYL

DrugScore2018

DrugScoreCSD

G-Score@SYBYL

GBVI/WSA-dG@MOE

GlideScore-SP

GlideScore-XP

GoldScore@GOLD

Jain@DS

LUDI1@DS

LUDI2@DS

LUDI3@DS

LigScore1@DS

LigScore2@DS

 Test Type

PLI,PPI,PNI,NLI

PPI

PPI

PPI

PPI

PPI

PLI

PLI

PLI-DUD-E/DEKOIS2.0

PLI

PLI

PLI-DUD-E/DEKOIS2.0

PLI-DUD-E/DEKOIS2.0

PLI

PLI-DUD-E/DEKOIS2.0

PLI

PLI-DUD-E/DEKOIS2.0

PLI-DUD-E/DEKOIS2.0

PLI-DUD-E/DEKOIS2.0

PLI-DUD-E/DEKOIS2.0

PLI

PLI-CASF2016/CPSet

PLI-CASF2016/CPSet

PLI-CASF2016/CPSet

PLI-CASF2016/CPSet

PLI-CASF2016

PLI-CASF2016/CPSet

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016/CPSet

PLI-CASF2016/CPSet

PLI-CASF2016/CPSet

PLI-CASF2016/CPSet

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

 44





 London-dG@MOE

PLP1@DS

PLP2@DS

PMF04@DS

PMF@DS

PMF@SYBYL

X-Score

X-ScoreHM

X-ScoreHP

X-ScoreHP

X-ScoreHS

EGNN

SchNet

LEFTNet

TorchMD-Net

DOCK6

PLANTS

rDock

Surflex

MM/GBSA

Gold@plp

Rosetta

CSM-carbohydrate

PCAPRED

CSM-lig

NNscore (pdbbind2016)

RFscore (v3 pdbbind2016)

PLEC score (pdbbind2016)

 PLI-CASF2016/CPSet

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PLI-CASF2016

PNI，NLI，Protein–Macrocycle

PNI，NLI，Protein–Macrocycle

PNI，NLI，Protein–Macrocycle

PNI，NLI，Protein–Macrocycle

NLI

NLI

NLI-RNA-Ligand,PLI-CPSet

NLI-RNA-Ligand,PLI-CPSet

NLI

PLI-CPSet

PLI-CPSet

PLI-PCAPRED

PLI-PCAPRED

PLI-PCAPRED

PLI-PCAPRED

PLI-PCAPRED

PLI-PCAPRED

 PLI: Protein–Ligand Interaction. PPI: Protein–Protein Interaction. PNI: Protein–Nucleic Acid Interaction. NLI:

Nucleic Acid–Ligand Interaction. Protein–Macrocycle: Protein–Non-Peptidic Macrocycle Test. RNA-Ligand:

The test subset includes only 29 RNA–small molecule complexes. For methods that are only involved in certain

subsets of a specific interaction type, this will be explicitly indicated. For example: PLI-DUD-E/DEKOIS2.0. De- scriptions of specific test sets can be found in Table S2. Some method results are obtained directly from the corre- sponding publications1–6.

Table S2. Details of Evaluation Test Sets

 Dataset

 Source

 Type

 CASF-2016

 Ref1

 PLI

 Power

scoring

ranking

docking

screening

 Processed

284

284

22,760

1,622,628

 DEKOIS 2.0

 DUD-E

 Ref7

 Ref8

 PLI

 screening

 867,020

 PLI

 screening

11,903,802

 PPI Benchmark

 Ours

 PPI

 scoring

docking

screening

 79

7,979

613,900

 45





 SAbDab

 Peptide-MHC I

 PNI test

 NLI test

 Ref9

 Ref10

 Ref11

 Ref11

 PPI

 scoring

 150

 PPI

 screening

 42,454

 PNI

 scoring

 NLI

 scoring

 Protein–Non-Peptidic Macrocycle Test

 Ours

 PLI

 scoring

 CPSet

 PCAPRED

 Ref12

 Ref13

 PLI

 scoring

 554

 134

 261

 270

 PLI

 scoring

 43

 46









 Table S3. Ablation Study Results on Protein–Protein Complexes

 Docking – PPI Benchmark

 Screening – PPI Benchmark

 Model

 Spearman

 Spearman

 SR

 SR

 SR

 Hit

 (All)

 (Top 20)

 (Top 1)

 (Top 5)

 (Top 10)

 (Top 1)

 Aver-

SR1%

 SR5%

 SR10%

 age

 Rank

 Ablation 1

 0.5617

 0.4134

 63.29%

 89.87%

 96.20%

 88.61%

 6.33%

 16.46%

 24.05%

 26.15%

 Ablation 2

 -0.2361

 0.3458

 26.58%

 53.16%

 67.09%

 26.58%

 2.53%

 7.59%

 13.92%

 43.23

 Ablation 3

 0.4083

 0.5020

 100.00%

 100.00%

 100.00%

 100.00%

 1.27%

 12.66%

 18.99%

 32.39

 BioScore

 0.6382

 0.5545

 100.00%

 100.00%

 100.00%

 100.00%

 15.19%

 32.91%

 41.77%

 21.54

 Ablation 1: Without interface-masking encoding strategy; inter-molecular edges are introduced into the complex

 geometry graph. Ablation 2: Traditional statistical potential–based scoring strategy; uses the summation of statis-

tical potentials as the final score. Ablation 3: Without interaction edge count–aware confidence score; final score

 is based solely on the mean of statistical potentials.

 Table S4. Ablation Study Results on Protein–Small Molecule Complexes

 Docking – CASF2016

 Screening – CASF2016

 Model

 SR

 SR

 SR

 Hit

 Hit

 Hit

 (Top 1)

 (Top 5)

 (Top 10)

 (Top 1)

 (Top 2)

 (Top 5)

 SR1%

 SR5%

 SR10%

 EF1%

 EF5%

EF10%

 Ablation 1

 22.11%

 34.04%

 52.98%

 78.25%

 87.37%

 94.74%

 8.77%

 22.81%

 31.58%

 1.81

 1.71

 1.61

 Ablation 2

 42.46%

 58.95%

 79.30%

 72.98%

 80.00%

 91.93%

 0.00%

 3.51%

 8.77%

 1.23

 1.48

 1.43

 Ablation 3

 62.46%

 80.00%

 94.04%

 94.39%

 96.84%

 99.30%

 19.30%

 40.35%

 49.12%

 14.54

 6.07

 4.03

 BioScore

 65.26%

 82.46%

 96.14%

 96.14%

 97.89%

 99.30%

 68.42%

 80.70%

 89.47%

 29.11

 9.95

 5.96

 Ablation 1: Without interface-masking encoding strategy; inter-molecular edges are introduced into the complex

 geometry graph. Ablation 2: Traditional statistical potential–based scoring strategy; uses the summation of statis-

tical potentials as the final score. Ablation 3: Without interaction edge count–aware confidence score; final score

 is based solely on the mean of statistical potentials.

 47







 Table S5. Inference Time Statistics for Different Scoring Methods

 Method

GET

GNN-DOVE

DProQA

VoroMQA

ZRANK2

MINT

AutoDock Vina

RTMScore

BioScore

 Inference Time per Complex (s)

0.0156

0.3283

0.7681

3.8648

0.0629

0.0001

2.1300

0.1266

0.0086

 Table S6. Description of All Pretraining and Fine-Tuning Datasets for BioScore

 Dataset

 Type

 Raw

 Period

 PDBbind

(version 2020)

 SAbDab

CSM-carbohydrate

 PLI

 19,443

 PPI

 2,852

 PNI

 PPI

PLI

 1,052

 736

327

 pretrain

fintune

pretrain

finetune

pretrain

finetune

finetune

finetune

 Processed

 (train / valid)

16,223 / 1,500

12,351 / 1,500

1,776 / 163

1,776 / 163

276 / 92

276 / 92

112 / 10

327 / 0

 Table S7. Scoring Performance Results for Antigen–Antibody Complexes

 Model

 Pearson

 Spear-

man

 RMSE

 MAE

 GET

 0.3659

 0.3354

 1.9637

 1.4849

 MINT

 0.0462

 0.0434

 1.6497

 1.2592

 BioScore

 0.4628

 0.4318

 1.5133

 1.2000

 48

















 Table S8. CASF-2016 Benchmark Results on Protein–Small Molecule Complexes

 CD"EFGH

IJG.FGH

MAJEN"G I!CO

!PO

C4AJERJG

MS

L"D.FGH

TFUV WX"4VY=

!"@AB

BF"CD"EA

MShiAU

LAA4L"D.

IX!CD"EA

hAGCD"EA

MShiAUg

PCOk!lOV

PCMkhlmLV

PnnFGFUoM@hk!lOV

PB4pJMTBk!lOV

PTU"@"D.VrFGJV

spARMmMkhlmLV

@Ca@Y

@CcfY

@Cdf@

@Cd??

@CccE

@Ccdc

@C?eY

@CfYc

@C??g

@C?fe

@Cf@d

@CfYd

spARCD"EAkhlmLV

@C?cd

spARCD"EAkCtBtmV

@C?e

LMCD"EAkCtBtmV

LETHCD"EAg@YaV

LETHCD"EAsCLV

hMCD"EAkCtBtmV

@C?EY

@Cf@g

@C?ef

@C?cg

hBrSuYCPM@hk!lOV @Cdef

hBF@ACD"EAMCMV

hBF@ACD"EAMZMV

h"B@CD"EAkhlmLV

[JFGkLCV

myLSYkLCV

myLSgkLCV

myLSEkLCV

mFHCD"EAYkLCV

mFHCD"EAgkLCV

@C?YE

@Cdfc

@CdYf

@Cd?c

@Cded

@C?gf

@C?@g

@Cdg?

@C?d

m"G@"GM@hk!lOV

@Cd@?

MmMYkLCV

MmMgkLCV

M!A@dkLCV

M!AkLCV

M!AkCtBtmV

ZMCD"EAV

ZMCD"EAT!V

ZMCD"EATM

ZMCD"EATMV

ZMCD"EATCV

]rFGJIAg@V

M

@C?fE

@CgYg

@Cdgg

@Cgfg

@CfEY

@Cf@e

@CfgY

M

@Cfge

@Cfg?

YCE@

YC@@

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

M

@Cc@d

@Cfag

@Cdg?

@C?ge

@Cf?e

@Cf?Y

@CdEe

@C??E

@Cf@d

@C?E?

@C?ga

@CfEE

@C?gf

@C?eE

@C?cc

@Cf@c

@CfE

@C?eY

@Cdae

@CdYe

@Cg?c

@Cgad

@C?gY

@CfYg

@Cfge

@C?Eg

@C?ee

@Cf@a

@C?eE

@C?ag

@C?ae

@CdaY

@C?Ec

@Cdde

@Cf@d

@Cf@E

M

@C?cE

@C?dc

@C?aa

@CcEc

M

M

M

M

M

@Cdff

@C?ag

@CfYe

@C??a

@C??c

@Cf?c

@C??a

@CfYc

@C?ea

@CfEc

@CffE

@Cf@e

@C?@d

@Cdg?

@Cg??

@CgaE

@C?d?

@Cfd

@Cf?c

@C?fd

@Cf@f

@Cfg

@Cf@e

@Cf@?

@CfYc

@Cdec

@C??e

@Cdca

@CfEa

@CfdY

M

@Cf@c

@C?cc

@CfYg

efCY>

acC@>

acC@>

ecCE>

ecCf>

eEC@>

?@C?>

aYCY>

fEC?>

cYCf>

e@Cg>

afC@>

a@Cd>

?cCe>

gfC@>

aEC?>

acCd>

ddCg>

acC@>

acCc>

aECe>

c?CY>

??Ca>

fECg>

fEC?>

?EC@>

cfCa>

a?Cf>

fECg>

agCa>

ceCE>

dfCE>

dgCa>

dcCc>

fEC?>

f?CE>

M

?fCY>

?eCf>

E@Cg>

CDEAAGFGH

CIY>

CI?>

CIY@>

OAY>

OA?>

OAY@>

faCd> a@Cc> aeC?> geCYY

eCe?

?Cef

??Cd>

dECe>

ffCc>

cYCd>

ffCc>

M

M

M

M

M

M

M

M

M

M

cC@> YgCE> gaCY>

ggCa> deCY> faCd>

YeCE> dECe> ?@Ce>

aCa> gYCY> d@Cd>

geCa> d@Cd> ?@Ce>

YeCf@

YfCdY

gaC@@

gaCYf

gdCe@

YCdd

fCea

?C@c

YCc@

cCc@

E?CY> fYCd> fdCe> YYCeY

gaCY> d?Cf> ?cCe>

YCa> Y?Ca> EYCf>

?CE> YcC?> gfCE>

Y?Ca> EYCf> EaCf>

ggCa> EECE> deCY>

EC?> YgCE> gfCE>

gfCE> d?Cf> ?eCf>

aCf?

@Cce

YCgd

ECff

?Ce@

@Cae

cCfg

EfCa> ?dCd> fECg> YYCdd

gfCE> d?Cf> ?gCf>

Y?Ca> E?CY> dgCY>

cC@> Y?Ca> EECE>

YdC@> geCa> dgCY>

Y@C?> gaCY> d@Cd>

cC@> YdC@> EECE>

ggCa> EfCa> deCY>

gfCE> dgCY> ?@Ce>

cC@> gfCE> dgCY>

Y?Ca> EYCf> d?Cf>

aCa> geCa> ?gCf>

YdC@> YeCE> EECE>

YdC@> gfCE> d@Cd>

cC@> YeCE> gaCY>

cC@> Y?Ca> gaCY>

aCa> YeCE> EYCf>

M

M

M

EC?> YcC?> geCa>

?CE> YgCE> gaCY>

?CE> YdC@> gdCf>

aCaE

dCgc

YCE?

ECY@

gCEd

YCa?

fCEg

fCag

gC@?

ECea

YCaY

ECYc

ECcf

YCdf

gCfa

ECgY

M

YCce

gCYc

YCcf

M

M

M

M

M

YCYY

ECe?

gCcc

YCf?

dC@Y

?Cge

ECe?

YCgf

YCf?

gCg?

gCec

YC@f

ECfY

?CaE

dCc?

gCaf

YCEY

gCYd

gC@@

YCY?

ECfa

EC?E

gCE@

gCaa

gCdE

YCfa

YCcf

YCcc

YCEY

YCEe

M

YC?d

YCgf

YCYg

M

M

M

M

M

YCga

ECY@

gCgf

gC@g

gCac

EC?e

gCeg

YCdY

YCEd

YCae

gC?d

YCYY

gCcc

ECea

EC?Y

YCea

YC?f

YCaY

YCfE

YCd@

gCcd

gCad

gC@e

gCEe

gCde

YCc?

YC?e

YCfa

YCgE

YCEY

M

YCYE

YCgf

YCY?

Baseline model results are sourced from the corresponding publications1,4,5,14–16.

 49









 Table S9. Controlled Comparison on the PPI Benchmark

 Scor-

ing

 Docking

 Screening

 Pear-

son

 RMSE

MAE

 Spear-

man

 (All)

 Spear-

man

 (Top 20)

 SR

 SR

 SR

 Hit

 (Top 1)

 (Top 5)

 (Top 10)

 (Top 1)

 Aver-

SR1%

 SR5%

 SR10%

 age

 Rank

 Model

 Bi-

oScore-

0.22

 2.43

 1.88

 0.67

 0.56

 97.47%

 98.73%

 100%

 98.73%

 8.86%

 21.52%

 31.65%

 24.56

 PPI

 Bi-

oScore-

0.46

 2.24

 1.65

 0.64

 0.55

 100.00%

 100.00%

 100.00%

 100.00%

 15.19%

 32.91%

 41.77%

 21.54

 PPI+PLI

 BioScore-PPI indicates that only PPI data were used during both pretraining and fine-tuning. BioScore-PPI+PLI

 indicates that mixed PLI and PPI data were used during pretraining, and PPI data were used during fine-tuning.

 Table S10. Controlled Comparison on the SAbDab Test Set

 Model

 BioScore-PPI

 BioScore-PPI+PLI

 Pearson

 0.24

 0.46

 Scoring

 RMSE

 1.66

 1.51

 MAE

 1.35

 1.20

 BioScore-PPI refers to the setting where only PPI data were used during pretraining, while BioScore-PPI+PLI

 denotes the use of mixed PPI and PLI data during pretraining. To avoid data leakage, both models were fine-

tuned on the SAbDab training set that had been pre-partitioned specifically for leakage prevention.

 50































 Table S11. Controlled Comparison on the CASF-2016 Benchmark

 Scoring

 Ranking

 Docking

 Screening

 RMSE

MAE

 Spearman

 PI

 Hit

 (Top 1)

 SR1%

 SR5%

 SR10%

 EF1%

 EF5%

 EF10%

 Model

 Bi-

Pear-

son

 oScore-

0.80

 1.29

 0.96

 0.56

 0.68

 95.44%

 61.40%

 85.96%

 92.98%

 28.98

 10.32

 6.07

 PLI

 Bi-

oScore-

0.80

 1.30

 1.00

 0.70

 0.74

 96.14%

 68.42%

 80.70%

 89.47%

 29.11

 9.95

 5.96

 PPI+PLI

 BioScore-PLI indicates that only PLI data were used during both pretraining and fine-tuning. BioScore-PPI+PLI

 indicates that mixed PLI and PPI data were used during pretraining, and PLI data were used during fine-tuning.

 Table S12. CPSet Benchmark Results

 Model

 BioScore-PLI

 BioScore-PPI

 BioScore-PPI+PLI

 Pearson

 0.52

 0.24

 0.60

 Scoring

 RMSE

 1.50

 1.77

 1.41

 MAE

 1.23

 1.44

 1.11

 BioScore-PPI indicates that only PPI data were used during both pretraining and fine-tuning. BioScore-PLI indi-

cates that only PLI data were used during both pretraining and fine-tuning. BioScore-PPI+PLI indicates that

 mixed PLI and PPI data were used during pretraining, and PPI data were used during fine-tuning.

 51



































 Table S13. Test Results of Different Fine-Tuning Strategies Across Multiple Complex Systems

 Model

 BioScore-

 Finetune-mix

 BioScore-

 Finetune-specific

 PPI-Scoring

 PLI-Scoring

 PLI-Ranking

 CPSet-Scoring

 Pearson

RMSE

MAE

 Pearson

RMSE

MAE

 Spearman

 PI

 Pearson

RMSE

MAE

 0.32

 2.10

 1.60

 0.79

 1.35

 1.01

 0.64

 0.65

 0.52

 1.58

 1.24

 0.46

 2.24

 1.65

 0.80

 1.30

 1.00

 0.70

 0.74

 0.60

 1.41

 1.11

 BioScore-Finetune-mix indicates that mixed PLI and PPI data were used during fine-tuning. BioScore-Finetune-

specific indicates that only domain-specific data were used during fine-tuning. Both strategies use mixed PLI and

 PPI data during pretraining.

 Table S14. PNI Scoring Test Set Results

 Model

 Pearson

RMSE

MAE

 GET

 -0.0641

 7.0047

3.9051

 EGNN

 0.1484

 2.1838

1.6863

 SchNet

 0.2201

 2.2666

1.7683

 LEFTNet

 0.0077

 3.6586

2.6018

 TorchMD-Net

0.1859

 2.4497

1.9066

 BioScore

 0.3761

 1.5753

1.2434

 52



































 Table S15. NLI Scoring Test Set Results

 Model

 Pearson

RMSE

MAE

 GET

 0.3589

3.2319

2.7872

 EGNN

 0.3901

2.2046

1.7716

 SchNet

 0.3673

2.4325

2.0900

 LEFTNet

 0.3400

2.9245

2.4267

 TorchMD-Net

0.2134

3.0295

2.5673

 BioScore

 0.4504

1.9070

1.5965

 Table S16. Test Results on Protein–Non-Peptidic Macrocycle Complexes

 Model

 Pear-

Spear-

son

 man

 RMSE

MAE

 GET

 0.5245

0.5360

1.5902

1.3091

 EGNN

 0.5069

0.5264

1.4761

1.2154

 SchNet

 0.5266

0.5198

1.4790

1.2343

 LEFTNet

 0.4749

0.4818

1.4824

1.2172

 TorchMD-Net

 0.5451

0.5605

1.5064

1.2239

 AutoDock Vina

0.4560

0.4667

2.1260

1.6621

 BioScore

 0.6195

0.6376

1.3638

1.0875

 53













 Table S17. Test Results on Protein–Carbohydrate Complexes

 Pear-

Spear-

Model

 CSM-carbohydrate

 PCAPRED

 CSM-lig

 NNscore (pdbbind2016)

 son

 0.67

 0.46

 0.20

 0.40

 RFscore (v3 pdbbind2016)

 0.36

 PLEC score (pdbbind2016)

 0.49

 Autodock Vina

 BioScore

 0.28

 0.76

 man

 0.64

 0.58

 0.14

 0.36

 0.33

 0.56

 0.29

 0.72

 RMSE

MAE

 1.72

 1.29

 2.73

 1.79

 5.07

 4.04

 2.49

 2.01

 2.19

 1.78

 2.49

 1.77

 2.54

 1.86

 1.09

 0.79

 Baseline model results are sourced from the work by Nguyen et al.3

 Table S18. BioScore Hyperparameter Settings

 Hyperparameters

 Setting



Learning rate (Pretrain)

 Learning rate (Finetune)

 Weight decay (Pretrain)

 Weight decay (Finetune)

 Maximum number of epochs

 Patience of early stopping

 Hidden dimension of GET layer

 -3

10

-4

10

-8

10

-5

10

200

 10

 128

 Upperbound of the number of nodes in a batch

 2500

 Number of GET layers

 Number of attention heads

 3

 4

 54



















 2. Supplementary Figures

 Figure S1. Validation Curves for Ablation Experiment 1 (without interface-masking encoding) and BioScore

 (with interface-masking encoding) during Mixed Pretraining on PLI and PPI Data.

 55







 Figure S2. Evaluation of 14 Scoring Methods on DUD-E. (A–D) Ranking of all methods by mean values for

 BEDROC (α=80.5), 0.5% EF, 1.0% EF, and 5.0% EF, respectively.

 56











 Figure S3. Evaluation of 14 Scoring Methods on DEKOIS2.0. (A–D) Ranking of all methods by mean values for

 BEDROC (α=80.5), 0.5% EF, 1.0% EF, and 5.0% EF, respectively.

 57











 3. PPI Benchmark

 To construct a comprehensive benchmark for scoring functions targeting protein–protein complexes, we per-

formed an initial filtering of complexes from PDBbind (version 2020) based on the following criteria: (1) the pro-

tein–protein interaction structure must consist of two heteromeric chains, with a sequence similarity between the

 chains of no more than 30%; (2) all structures must be non-NMR resolved, with a resolution better than 3.5 Å; (3)

 no non-protein macromolecular polymers (such as nucleic acids) may be present; (4) no missing amino acids are

 allowed in the structures; (5) both chains must have fewer than 500 residues; and (6) a clear binding affinity label

 must be available, with the type being "Kd." As a result, we selected 177 protein–protein complexes from 2,852

 entries in the PDBbind protein–protein dataset that met these criteria.

 Next, we categorized the protein chains within the complexes based on sequence length into three groups: A

 (<50 amino acids), B (50–250 amino acids), and C (250–500 amino acids). Based on the lengths of the interacting

 heteromeric chains (i.e., receptor and ligand chains), we further divided the complexes into four groups: A-B, A-

C, B-B, and B-C. We then randomly selected 20 PPIs from each group, substituting entries with others from the

 same group if necessary to meet the downstream benchmark construction requirements (notably, for the A-C

 group, only 19 complexes met the criteria for constructing the protein–protein docking benchmark). Following

 this process, a final set of 79 high-quality protein–protein complexes with diverse sequence length distributions

 was curated and designated as the foundational complex dataset for our PPI benchmark.

 To comprehensively evaluate the different capabilities of scoring functions, we followed the design princi-

ples of CASF-20161. We first constructed a scoring power benchmark by using the structures and corresponding

 experimental binding affinity annotations from the foundational complex dataset. This benchmark evaluates the

 ability of a scoring function to predict the binding affinity of protein–protein complexes. It is important to note

 that, due to the lack of sufficient data in PDBbind where a single protein receptor is associated with multiple pro-

tein ligands, it is not feasible to construct a ranking power benchmark for the PPI dataset similar to that of CASF-

2016.

 We further constructed a docking power benchmark based on the foundational complex dataset to evaluate

 the ability of scoring functions to distinguish native-like from non-native binding conformations. We used

 ZDOCK 3.0.217 to generate decoy conformations for the 79 heterodimeric targets. In the decoy generation and

 sampling process, the longer chain was designated as the receptor and the shorter chain as the ligand. Using a 6-

degree Euler angle increment, each ZDOCK run produced 6,000 models per complex, and each complex under-

went five independent ZDOCK runs. For each run, the monomers were randomly rotated and translated in space

 to ensure all generated decoy models were distinct. For each target, we computed DockQ scores for all 30,000

 models and binned the docking poses into 20 intervals based on their DockQ scores (ranging from 0 to 1) with a

 bin width of 0.05. For each target, we selected five models from each DockQ bin, following the principle of max-

imizing DockQ diversity. Due to the scarcity of decoy models with DockQ > 0.9, we combined the bins for 0.9 <

 DockQ < 0.95 and DockQ > 0.95 into a single bin, from which 10 models were selected. This procedure yielded

 100 decoy models per target. It is important to note that some complexes did not have sufficient decoy models in

 58





 every DockQ bin to meet the sampling requirements. These PPIs were replaced with entries from the same se-

quence length group, with corresponding substitutions made in the protein–protein foundational dataset to main-

tain the completeness and consistency of the PPI benchmark. As a result, the A-C group in the final foundational

 dataset contains only 19 complexes (the number of complexes that met the criteria).

 Finally, we further performed cross-docking of the 79 receptor proteins and their partner proteins in the

 foundational complex dataset using ZDOCK. Given the potentially large number of receptor–ligand pairs, we re-

duced the number of docking poses generated by ZDOCK for each ligand to 600. Using the K-means clustering

 method, we grouped the 600 docking poses based on ligand conformational similarity, measured by Root Mean

 Square Deviation (RMSD) values, into 100 clusters. From each cluster, we randomly selected one representative

 pose to ensure that each receptor–ligand pair’s decoy dataset contained 100 diverse binding conformations. In the

 post-processing step, we standardized chain identifiers by renaming receptor chains as "A" and ligand chains as

 "B" to avoid duplicate native chain IDs during cross-docking. Importantly, to mitigate the risk of false negatives

 in the cross-docking evaluation, we performed 90% sequence identity clustering of receptor chains using CD-HIT

 and treated ligands within the same cluster as potential false-negative ligands, which were excluded from the

 screening evaluation. This process yielded a screening power benchmark comprising 613,900 docking confor-

mations for assessing a scoring function’s ability to distinguish active from inactive ligands.



Final Selected 79 PDB IDs and Groupings

 Total

 ['6f0f', '1j2j', '1mzw', '5yip', '4js0', '3h8k', '2vay', '5wuj', '6j4s', '6e3j', '2wh6', '5gtb', '6jjw', '5h3j', '5inb', '2gww',

 '5h9b', '3ukz', '5ky4', '2qxv', '6bw9', '4uyq', '2hth', '3ul4', '1gua', '4dbg', '3u43', '3fpu', '1kac', '6ne4', '2v9t', '5ml9',

 '2uyz', '4eig', '1lw6', '3vv2', '3zu7', '5jw7', '5g15', '2f4m', '4z9k', '4d0n', '6hul', '1tdq', '2qc1', '2v8s', '2omz', '2voh',

 '3gj6', '3kj0', '3tz1', '4d0g', '4rey', '4y61', '1pjm', '1pjn', '1syq', '1rkc', '1t01', '3ukx', '3ul0', '3ul1', '5ky5', '6iu7',

 '6iua', '6k06', '1emv', '1p69', '2vlp', '2vln', '3kuc', '2sic', '1jiw', '2b7c', '2omw', '2v3b', '2z58', '3vyr', '4m0w']

 Group: A-B

 ['1j2j', '1mzw', '2voh', '2vay', '3h8k', '3gj6', '2wh6', '3kj0', '3tz1', '4js0', '4d0g', '4rey', '5h3j', '5wuj', '5gtb', '6e3j',

 '5yip', '6j4s', '6f0f', '6jjw']

 Group: A-C

 ['1pjm', '1pjn', '1syq', '1rkc', '1t01', '2gww', '2qxv', '3ukx', '3ul0', '3ukz', '3ul1', '5inb', '5ky5', '5ky4', '5h9b', '6bw9',

 '6iu7', '6iua', '6k06']

 Group: B-B

 ['1gua', '1kac', '1emv', '1p69', '2hth', '2qc1', '2v8s', '2v9t', '2uyz', '2vlp', '2vln', '3fpu', '3kuc', '4dbg', '3ul4', '3u43',

 '4eig', '4uyq', '5ml9', '6ne4']

 Group: B-C

 ['2sic', '1jiw', '1lw6', '1tdq', '2b7c', '2f4m', '2omw', '2omz', '2v3b', '2z58', '3vyr', '3zu7', '3vv2', '4d0n', '4m0w',

 '4y61', '4z9k', '5jw7', '5g15', '6hul']

 59







 Ligands within the same cluster are considered potential false-negative ligands and are excluded from the screen-

ing evaluation.

 Cluster 3 ['2omz', '2omw']; Cluster 7 ['3ul1', '3ukz', '6iu7', '6iua', '1pjn', '3ul0', '1pjm', '3ukx', '6k06']; Cluster 18

 ['5ky4', '5ky5']; Cluster 21 ['3vv2', '2z58']; Cluster 35 ['1lw6', '2sic']; Cluster 43 ['2gww', '1syq', '1t01', '1rkc'];

 Cluster 67 ['1kac', '1p69']; Cluster 78 ['1gua', '3kuc']; Cluster 110 ['1emv', '2vln', '2vlp'].

 60









 4. Basic Evaluation Methods

 Following CASF-2016, there are four different tasks assessed in our evaluation, including the scoring, docking,

 ranking, and screening powers. Here, we introduce the primary assessment indicators for each of the four powers

 in our evaluations.

 “Scoring power” refers to the ability of a scoring function to produce binding scores in a linear correlation

 with experimental binding data. The Pearson’s correlation coefficient between the computed binding scores and

 the experimental binding constants was calculated as a quantitative measure of the scoring power. Root Mean

 Square Error (RMSE) and Mean Absolute Error (MAE) were also used to evaluate the predictive accuracy of the

 scoring function.

 “Ranking power” refers to the ability of a scoring function to correctly rank the known ligands of a certain

 target by their binding affinities when the precise binding poses of those ligands are given. The Spearman’s rank

 correlation coefficient and Predictive Index (PI) were used as the main quantitative indicators of ranking power.

 “Docking power” refers to the ability of a scoring function to identify the native ligand binding pose among

 in-silico-generated decoys. Spearman's rank correlation coefficient is one of the most commonly used metrics for

 evaluating docking power. “Spearman’s top-k” represents the ability of the scoring function to rank decoys within

 the top k based on their dockQ scores, it evaluates the scoring function’s capability to identify higher-quality con-

formations within a set of high-quality but slightly different decoys. Success rate(SR) and hit rate(Hit) are two

 additional key indicators for evaluating docking power. The success rate refers to the percentage of successful

 predictions that the native pose ranked within the top k of all scored poses, while the hit rate is a metric where the

 complex can be marked as a successful prediction if one of the RMSD values between the best-scored poses and

 the native pose is below the predefined threshold (usually 2.0Å), for the PPI system, the DockQ score (with a

 threshold of 0.8) is used as the metric.

 “Screening power” refers to the ability of a scoring function to identify the true binders to a given target

 among a pool of random ligands, and was evaluated essentially in a cross-docking trial. The indicator of the

 screening power includes the success rate (SR) of identifying the highest-affinity binder among the k% top-

ranked ligands, and the enrichment factor (EF) which is defined as the percentage of true binders observed among

 all of the true binders for a given percentile of the top-ranked candidates. We also considered the ranking of the

 true ligand with the highest affinity among all ligands, using the Average Rank to represent the average perfor-

mance across all targets for intuitive presentation. A higher rank indicates better ability of the scoring function to

 identify the true ligand. In addition, Area Under the Receiver Operating Characteristic Curve (AUROC), Area

 Under the Precision-Recall Curve (AUPR), and Boltzmann-Enhanced Discrimination of Receiver Operating

 Characteristic (BEDROC) were also considered to assess the screening power of scoring functions, with AUROC

 providing an overall measure of discriminative power,

AUPR offering a more focused evaluation on how well

 the function performs in predicting relevant hits, especially when the positive class is scarce, and BEDROC

 providing a further evaluation that emphasizes early enrichment of true positives, which is crucial for prioritizing

 the most relevant candidates in screening.

 61





 5. Description of Baseline Methods

 (1) GET

 We obtained results of GET using the open-source codes at https://github.com/thunlp-mt/get and retrained with

 default settings. Following GET, basic baselines such as EGNN, TorchMD-Net, and LEFTNet were obtained

 from their respective open-source codes, and SchNet was implemented using PyTorch Geometric. The retraining

 procedures and data types for the aforementioned models align with the specifications outlined in the original

 GET methodology. For the PLI and PPI tests, a hybrid dataset comprising both PLI and PPI data was utilized for

 training. In tasks related to nucleic acids, a combined training approach incorporating PLI, PPI, and PNI datasets

 was employed.

 (2) GNN-DOVE

 We obtained results of GNN-DOVE using the open-source codes and weights at https://github.com/ki-

haralab/GNN_DOVE with default settings.



(3) DProQA

 We obtained results of DProQA using the open-source codes and weights at https://github.com/jianlin-

cheng/DProQA with default settings.



(4) MINT

 We obtained the embeddings of MINT using the open-source codes and pretrained weights at

 https://github.com/VarunUllanat/mint with default settings, and then finetuned the downstream MLP to predict

 the binding affinity of protein complexes.

 (5) VoroMQA

 Software version: Voronota 1.22.3149-1. We applied the default settings of voronota-voromqa to score the qual-

ity of complex structures.

 (6) ZRANK2

 Software version: ZRANK 2.0, Pymol 2.4.1. Complex preparation: Hydrogen atoms were added with Pymol

 2.4.1 and new complex PBD files with Hydrogen atoms were generated as input of ZRANK2. We scored the

 complexes by ZRANK2 without the parameter “-R” for initial-stage docked models.

 (7) Autodock Vina

 Software version: AutoDock Vina 1.2.3, MGLTOOLS 1.5.7. Ligand preparation: The ligands are processed into

 PDBQT files with hydrogen atoms added using the MGLTOOLS prepare_ligand4 scripts. Protein preparation:

 The proteins were processed into PDBQT files with hydrogen atoms added using the MGLTOOLS prepare_re-

ceptor4 scripts. The score_only mode was used to score the binding affinity of complexes without changing the

 pose.

 The evaluation results of other scoring tools mentioned in this paper are based on data from the corresponding

 publications.

 62









 63









 6. References

 1.

Su, M. et al. Comparative Assessment of Scoring Functions: The CASF-2016 Update. J. Chem. Inf. Model.

 59, 895–913 (2019).

 2.

Jiang, D. et al. Assessing the performance of MM/PBSA and MM/GBSA methods. 10. Prediction reliability

 of binding affinities and binding poses for RNA–ligand complexes. Phys. Chem. Chem. Phys. 26, 10323–10335

 (2024).

 3.

Nguyen, T. B., Pires, D. E. V. & Ascher, D. B. CSM-carbohydrate: protein-carbohydrate binding affinity pre-

diction and docking scoring function. Brief. Bioinform. 23, bbab512 (2022).

 4.

Moon, S., Zhung, W., Yang, S., Lim, J. & Kim, W. Y. PIGNet: a physics-informed deep learning model to-

ward generalized drug–target interaction predictions. Chem. Sci. 13, 3661–3673 (2022).

 5.

Moon, S., Hwang, S.-Y., Lim, J. & Kim, W. Y. PIGNet2: a versatile deep learning-based protein–ligand in-

teraction prediction model for binding affinity scoring and virtual screening. Digit. Discov. 3, 287–299 (2024).

 6.

Cao, D. et al. Generic protein–ligand interaction scoring by integrating physical prior knowledge and data

 augmentation modelling. Nat. Mach. Intell. 6, 688–700 (2024).

 7.

Bauer, M. R., Ibrahim, T. M., Vogel, S. M. & Boeckler, F. M. Evaluation and Optimization of Virtual

 Screening Workflows with DEKOIS 2.0 – A Public Library of Challenging Docking Benchmark Sets. J. Chem.

 Inf. Model. 53, 1447–1462 (2013).

 8.

Mysinger, M. M., Carchia, M., Irwin, John. J. & Shoichet, B. K. Directory of Useful Decoys, Enhanced

 (DUD-E): Better Ligands and Decoys for Better Benchmarking. J. Med. Chem. 55, 6582–6594 (2012).

 9.

Schneider, C., Raybould, M. I. J. & Deane, C. M. SAbDab in the age of biotherapeutics: updates including

 SAbDab-nano, the nanobody structure tracker. Nucleic Acids Res. 50, D1368–D1372 (2022).

 10.

Ge, J. et al. Deep-learning-based prediction framework for protein-peptide interactions with structure genera-

tion pipeline. Cell Rep. Phys. Sci. 5, 101980 (2024).

 11.

Wang, R., Fang, X., Lu, Y. & Wang, S. The PDBbind Database: Collection of Binding Affinities for Pro-

tein−Ligand Complexes with Known Three-Dimensional Structures. J. Med. Chem. 47, 2977–2980 (2004).

 12.

Zhao, H. et al. Comprehensive Evaluation of 10 Docking Programs on a Diverse Set of Protein–Cyclic Pep-

tide Complexes. J. Chem. Inf. Model. 64, 2112–2124 (2024).

 13.

Siva Shanmugam, N. R., Jino Blessy, J., Veluraja, K. & Gromiha, M. M. Prediction of protein–carbohydrate

 complex binding affinity using structural features. Brief. Bioinform. 22, bbaa319 (2021).

 14.

Méndez-Lucio, O., Ahmad, M., Del Rio-Chanona, E. A. & Wegner, J. K. A geometric deep learning ap-

proach to predict binding conformations of bioactive molecules. Nat. Mach. Intell. 3, 1033–1039 (2021).

 15.

Shen, C. et al. Boosting Protein–Ligand Binding Pose Prediction and Virtual Screening Based on Residue–

Atom Distance Likelihood Potential and Graph Transformer. J. Med. Chem. 65, 10691–10706 (2022).

 16.

Shen, C. et al. A generalized protein–ligand scoring framework with balanced scoring, docking, ranking and

 screening powers. Chem. Sci. 14, 8129–8146 (2023).

 64





 17.

Pierce, B. G., Hourai, Y. & Weng, Z. Accelerating Protein Docking in ZDOCK Using an Advanced 3D Con-

volution Library. PLoS ONE 6, e24657 (2011).

 65