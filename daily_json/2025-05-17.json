[
    {
        "title": "DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling",
        "summary": "Diffusion Transformer (DiT), a promising diffusion model for visual\ngeneration, demonstrates impressive performance but incurs significant\ncomputational overhead. Intriguingly, analysis of pre-trained DiT models\nreveals that global self-attention is often redundant, predominantly capturing\nlocal patterns-highlighting the potential for more efficient alternatives. In\nthis paper, we revisit convolution as an alternative building block for\nconstructing efficient and expressive diffusion models. However, naively\nreplacing self-attention with convolution typically results in degraded\nperformance. Our investigations attribute this performance gap to the higher\nchannel redundancy in ConvNets compared to Transformers. To resolve this, we\nintroduce a compact channel attention mechanism that promotes the activation of\nmore diverse channels, thereby enhancing feature diversity. This leads to\nDiffusion ConvNet (DiCo), a family of diffusion models built entirely from\nstandard ConvNet modules, offering strong generative performance with\nsignificant efficiency gains. On class-conditional ImageNet benchmarks, DiCo\noutperforms previous diffusion models in both image quality and generation\nspeed. Notably, DiCo-XL achieves an FID of 2.05 at 256x256 resolution and 2.53\nat 512x512, with a 2.7x and 3.1x speedup over DiT-XL/2, respectively.\nFurthermore, our largest model, DiCo-H, scaled to 1B parameters, reaches an FID\nof 1.90 on ImageNet 256x256-without any additional supervision during training.\nCode: https://github.com/shallowdream204/DiCo.",
        "url": "http://arxiv.org/abs/2505.11196v1",
        "published_date": "2025-05-16T12:54:04+00:00",
        "updated_date": "2025-05-16T12:54:04+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Yuang Ai",
            "Qihang Fan",
            "Xuefeng Hu",
            "Zhenheng Yang",
            "Ran He",
            "Huaibo Huang"
        ],
        "tldr": "This paper introduces Diffusion ConvNet (DiCo), a convolutional neural network architecture for diffusion models that achieves state-of-the-art image generation performance with significant efficiency gains compared to Diffusion Transformers (DiT). It addresses the channel redundancy issue in ConvNets using a compact channel attention mechanism.",
        "tldr_zh": "本文介绍了扩散卷积神经网络 (DiCo)，一种用于扩散模型的卷积神经网络架构，与扩散 Transformer (DiT) 相比，它在图像生成方面实现了最先进的性能，并显着提高了效率。它使用紧凑的通道注意力机制解决了卷积神经网络中的通道冗余问题。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 9
    },
    {
        "title": "A Fourier Space Perspective on Diffusion Models",
        "summary": "Diffusion models are state-of-the-art generative models on data modalities\nsuch as images, audio, proteins and materials. These modalities share the\nproperty of exponentially decaying variance and magnitude in the Fourier\ndomain. Under the standard Denoising Diffusion Probabilistic Models (DDPM)\nforward process of additive white noise, this property results in\nhigh-frequency components being corrupted faster and earlier in terms of their\nSignal-to-Noise Ratio (SNR) than low-frequency ones. The reverse process then\ngenerates low-frequency information before high-frequency details. In this\nwork, we study the inductive bias of the forward process of diffusion models in\nFourier space. We theoretically analyse and empirically demonstrate that the\nfaster noising of high-frequency components in DDPM results in violations of\nthe normality assumption in the reverse process. Our experiments show that this\nleads to degraded generation quality of high-frequency components. We then\nstudy an alternate forward process in Fourier space which corrupts all\nfrequencies at the same rate, removing the typical frequency hierarchy during\ngeneration, and demonstrate marked performance improvements on datasets where\nhigh frequencies are primary, while performing on par with DDPM on standard\nimaging benchmarks.",
        "url": "http://arxiv.org/abs/2505.11278v1",
        "published_date": "2025-05-16T14:13:02+00:00",
        "updated_date": "2025-05-16T14:13:02+00:00",
        "categories": [
            "stat.ML",
            "cs.CV",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Fabian Falck",
            "Teodora Pandeva",
            "Kiarash Zahirnia",
            "Rachel Lawrence",
            "Richard Turner",
            "Edward Meeds",
            "Javier Zazo",
            "Sushrut Karmalkar"
        ],
        "tldr": "This paper analyzes the frequency bias in diffusion models, showing that high-frequency components are degraded faster during the forward process, leading to suboptimal generation. They propose and demonstrate an improved forward process that corrupts all frequencies equally, resulting in better performance on datasets with high-frequency importance.",
        "tldr_zh": "该论文分析了扩散模型中的频率偏见，表明前向过程中高频分量退化更快，导致生成效果不佳。他们提出并展示了一种改进的前向过程，该过程以相同的速率破坏所有频率，从而在具有高频重要性的数据集上获得更好的性能。",
        "relevance_score": 8,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 8
    },
    {
        "title": "Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models",
        "summary": "Diffusion models have made substantial advances in image generation, yet\nmodels trained on large, unfiltered datasets often yield outputs misaligned\nwith human preferences. Numerous methods have been proposed to fine-tune\npre-trained diffusion models, achieving notable improvements in aligning\ngenerated outputs with human preferences. However, we argue that existing\npreference alignment methods neglect the critical role of handling\nunconditional/negative-conditional outputs, leading to a diminished capacity to\navoid generating undesirable outcomes. This oversight limits the efficacy of\nclassifier-free guidance~(CFG), which relies on the contrast between\nconditional generation and unconditional/negative-conditional generation to\noptimize output quality. In response, we propose a straightforward but\nversatile effective approach that involves training a model specifically\nattuned to negative preferences. This method does not require new training\nstrategies or datasets but rather involves minor modifications to existing\ntechniques. Our approach integrates seamlessly with models such as SD1.5, SDXL,\nvideo diffusion models and models that have undergone preference optimization,\nconsistently enhancing their alignment with human preferences.",
        "url": "http://arxiv.org/abs/2505.11245v1",
        "published_date": "2025-05-16T13:38:23+00:00",
        "updated_date": "2025-05-16T13:38:23+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Fu-Yun Wang",
            "Yunhao Shui",
            "Jingtan Piao",
            "Keqiang Sun",
            "Hongsheng Li"
        ],
        "tldr": "The paper introduces Diffusion-NPO, a method to improve preference alignment in diffusion models by specifically addressing negative preferences, leading to better generation quality and seamless integration with existing models.",
        "tldr_zh": "该论文介绍了Diffusion-NPO，一种通过专门处理负面偏好来提高扩散模型中偏好对齐的方法，从而实现更好的生成质量并与现有模型无缝集成。",
        "relevance_score": 9,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Towards Self-Improvement of Diffusion Models via Group Preference Optimization",
        "summary": "Aligning text-to-image (T2I) diffusion models with Direct Preference\nOptimization (DPO) has shown notable improvements in generation quality.\nHowever, applying DPO to T2I faces two challenges: the sensitivity of DPO to\npreference pairs and the labor-intensive process of collecting and annotating\nhigh-quality data. In this work, we demonstrate that preference pairs with\nmarginal differences can degrade DPO performance. Since DPO relies exclusively\non relative ranking while disregarding the absolute difference of pairs, it may\nmisclassify losing samples as wins, or vice versa. We empirically show that\nextending the DPO from pairwise to groupwise and incorporating reward\nstandardization for reweighting leads to performance gains without explicit\ndata selection. Furthermore, we propose Group Preference Optimization (GPO), an\neffective self-improvement method that enhances performance by leveraging the\nmodel's own capabilities without requiring external data. Extensive experiments\ndemonstrate that GPO is effective across various diffusion models and tasks.\nSpecifically, combining with widely used computer vision models, such as YOLO\nand OCR, the GPO improves the accurate counting and text rendering capabilities\nof the Stable Diffusion 3.5 Medium by 20 percentage points. Notably, as a\nplug-and-play method, no extra overhead is introduced during inference.",
        "url": "http://arxiv.org/abs/2505.11070v1",
        "published_date": "2025-05-16T10:04:57+00:00",
        "updated_date": "2025-05-16T10:04:57+00:00",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Renjie Chen",
            "Wenfeng Lin",
            "Yichen Zhang",
            "Jiangchuan Wei",
            "Boyuan Liu",
            "Chao Feng",
            "Jiao Ran",
            "Mingyu Guo"
        ],
        "tldr": "The paper introduces Group Preference Optimization (GPO), a self-improvement method for text-to-image diffusion models that addresses the data sensitivity issue of Direct Preference Optimization (DPO) by using groupwise preferences and reward standardization, leading to improved performance without requiring external data.",
        "tldr_zh": "该论文介绍了组偏好优化（GPO），这是一种用于文本到图像扩散模型的自我改进方法，通过使用组偏好和奖励标准化来解决直接偏好优化（DPO) 的数据敏感性问题，从而在不需要外部数据的情况下提高性能。",
        "relevance_score": 8,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 8
    },
    {
        "title": "DDAE++: Enhancing Diffusion Models Towards Unified Generative and Discriminative Learning",
        "summary": "While diffusion models have gained prominence in image synthesis, their\ngenerative pre-training has been shown to yield discriminative representations,\npaving the way towards unified visual generation and understanding. However,\ntwo key questions remain: 1) Can these representations be leveraged to improve\nthe training of diffusion models themselves, rather than solely benefiting\ndownstream tasks? 2) Can the feature quality be enhanced to rival or even\nsurpass modern self-supervised learners, without compromising generative\ncapability? This work addresses these questions by introducing\nself-conditioning, a straightforward yet effective mechanism that internally\nleverages the rich semantics inherent in denoising network to guide its own\ndecoding layers, forming a tighter bottleneck that condenses high-level\nsemantics to improve generation. Results are compelling: our method boosts both\ngeneration FID and recognition accuracy with 1% computational overhead and\ngeneralizes across diverse diffusion architectures. Crucially,\nself-conditioning facilitates an effective integration of discriminative\ntechniques, such as contrastive self-distillation, directly into diffusion\nmodels without sacrificing generation quality. Extensive experiments on\npixel-space and latent-space datasets show that in linear evaluations, our\nenhanced diffusion models, particularly UViT and DiT, serve as strong\nrepresentation learners, surpassing various self-supervised models.",
        "url": "http://arxiv.org/abs/2505.10999v1",
        "published_date": "2025-05-16T08:47:16+00:00",
        "updated_date": "2025-05-16T08:47:16+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Weilai Xiang",
            "Hongyu Yang",
            "Di Huang",
            "Yunhong Wang"
        ],
        "tldr": "The paper introduces a self-conditioning mechanism (DDAE++) to improve diffusion models for both generative and discriminative tasks, achieving better FID and recognition accuracy with minimal overhead and surpassing existing self-supervised learning methods in representation learning.",
        "tldr_zh": "该论文介绍了一种自调节机制(DDAE++)，以改进扩散模型在生成和判别任务中的表现，以最小的开销实现了更好的FID和识别精度，并在表征学习方面超越了现有的自监督学习方法。",
        "relevance_score": 8,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]