[
    {
        "title": "DC-AR: Efficient Masked Autoregressive Image Generation with Deep Compression Hybrid Tokenizer",
        "summary": "We introduce DC-AR, a novel masked autoregressive (AR) text-to-image\ngeneration framework that delivers superior image generation quality with\nexceptional computational efficiency. Due to the tokenizers' limitations, prior\nmasked AR models have lagged behind diffusion models in terms of quality or\nefficiency. We overcome this limitation by introducing DC-HT - a deep\ncompression hybrid tokenizer for AR models that achieves a 32x spatial\ncompression ratio while maintaining high reconstruction fidelity and\ncross-resolution generalization ability. Building upon DC-HT, we extend MaskGIT\nand create a new hybrid masked autoregressive image generation framework that\nfirst produces the structural elements through discrete tokens and then applies\nrefinements via residual tokens. DC-AR achieves state-of-the-art results with a\ngFID of 5.49 on MJHQ-30K and an overall score of 0.69 on GenEval, while\noffering 1.5-7.9x higher throughput and 2.0-3.5x lower latency compared to\nprior leading diffusion and autoregressive models.",
        "url": "http://arxiv.org/abs/2507.04947v1",
        "published_date": "2025-07-07T12:45:23+00:00",
        "updated_date": "2025-07-07T12:45:23+00:00",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yecheng Wu",
            "Junyu Chen",
            "Zhuoyang Zhang",
            "Enze Xie",
            "Jincheng Yu",
            "Junsong Chen",
            "Jinyi Hu",
            "Yao Lu",
            "Song Han",
            "Han Cai"
        ],
        "tldr": "The paper introduces DC-AR, a novel masked autoregressive text-to-image generation framework using a deep compression hybrid tokenizer (DC-HT) that achieves state-of-the-art results with improved computational efficiency compared to prior diffusion and autoregressive models.",
        "tldr_zh": "该论文介绍了DC-AR，一种新型的基于深度压缩混合令牌器（DC-HT）的掩码自回归文本到图像生成框架，与之前的扩散模型和自回归模型相比，它以更高的计算效率实现了最先进的结果。",
        "relevance_score": 9,
        "novelty_claim_score": 9,
        "clarity_score": 8,
        "potential_impact_score": 8,
        "overall_priority_score": 9
    },
    {
        "title": "QR-LoRA: Efficient and Disentangled Fine-tuning via QR Decomposition for Customized Generation",
        "summary": "Existing text-to-image models often rely on parameter fine-tuning techniques\nsuch as Low-Rank Adaptation (LoRA) to customize visual attributes. However,\nwhen combining multiple LoRA models for content-style fusion tasks,\nunstructured modifications of weight matrices often lead to undesired feature\nentanglement between content and style attributes. We propose QR-LoRA, a novel\nfine-tuning framework leveraging QR decomposition for structured parameter\nupdates that effectively separate visual attributes. Our key insight is that\nthe orthogonal Q matrix naturally minimizes interference between different\nvisual features, while the upper triangular R matrix efficiently encodes\nattribute-specific transformations. Our approach fixes both Q and R matrices\nwhile only training an additional task-specific $\\Delta R$ matrix. This\nstructured design reduces trainable parameters to half of conventional LoRA\nmethods and supports effective merging of multiple adaptations without\ncross-contamination due to the strong disentanglement properties between\n$\\Delta R$ matrices. Experiments demonstrate that QR-LoRA achieves superior\ndisentanglement in content-style fusion tasks, establishing a new paradigm for\nparameter-efficient, disentangled fine-tuning in generative models.",
        "url": "http://arxiv.org/abs/2507.04599v1",
        "published_date": "2025-07-07T01:31:01+00:00",
        "updated_date": "2025-07-07T01:31:01+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Jiahui Yang",
            "Yongjia Ma",
            "Donglin Di",
            "Hao Li",
            "Wei Chen",
            "Yan Xie",
            "Jianxun Cui",
            "Xun Yang",
            "Wangmeng Zuo"
        ],
        "tldr": "This paper introduces QR-LoRA, a parameter-efficient fine-tuning method for text-to-image models that uses QR decomposition to disentangle content and style attributes, enabling better content-style fusion.",
        "tldr_zh": "该论文介绍了 QR-LoRA，一种用于文本到图像模型的参数高效微调方法，它使用 QR 分解来解耦内容和样式属性，从而实现更好的内容-样式融合。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]