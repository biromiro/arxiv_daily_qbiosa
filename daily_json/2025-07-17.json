[
    {
        "title": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models",
        "summary": "We argue that diffusion models' success in modeling complex distributions is,\nfor the most part, coming from their input conditioning. This paper\ninvestigates the representation used to condition diffusion models from the\nperspective that ideal representations should improve sample fidelity, be easy\nto generate, and be compositional to allow out-of-training samples generation.\nWe introduce Discrete Latent Code (DLC), an image representation derived from\nSimplicial Embeddings trained with a self-supervised learning objective. DLCs\nare sequences of discrete tokens, as opposed to the standard continuous image\nembeddings. They are easy to generate and their compositionality enables\nsampling of novel images beyond the training distribution. Diffusion models\ntrained with DLCs have improved generation fidelity, establishing a new\nstate-of-the-art for unconditional image generation on ImageNet. Additionally,\nwe show that composing DLCs allows the image generator to produce\nout-of-distribution samples that coherently combine the semantics of images in\ndiverse ways. Finally, we showcase how DLCs can enable text-to-image generation\nby leveraging large-scale pretrained language models. We efficiently finetune a\ntext diffusion language model to generate DLCs that produce novel samples\noutside of the image generator training distribution.",
        "url": "http://arxiv.org/abs/2507.12318v1",
        "published_date": "2025-07-16T15:12:17+00:00",
        "updated_date": "2025-07-16T15:12:17+00:00",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Samuel Lavoie",
            "Michael Noukhovitch",
            "Aaron Courville"
        ],
        "tldr": "This paper introduces Discrete Latent Codes (DLCs), a novel image representation derived from Simplicial Embeddings for diffusion models. DLCs improve image generation fidelity, enable out-of-distribution sample generation, and facilitate text-to-image synthesis.",
        "tldr_zh": "本文介绍了一种新的图像表示方法，离散潜在码 (DLC)，它源于用于扩散模型的单纯嵌入。DLC 可以提高图像生成保真度，实现超出分布的样本生成，并促进文本到图像的合成。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 8,
        "potential_impact_score": 9,
        "overall_priority_score": 9
    }
]