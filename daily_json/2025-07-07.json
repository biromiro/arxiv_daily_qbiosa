[
    {
        "title": "LVLM-Composer's Explicit Planning for Image Generation",
        "summary": "The burgeoning field of generative artificial intelligence has fundamentally\nreshaped our approach to content creation, with Large Vision-Language Models\n(LVLMs) standing at its forefront. While current LVLMs have demonstrated\nimpressive capabilities in text-to-image generation, they often falter when\nconfronted with complex textual descriptions demanding precise compositional\nunderstanding and visual planning. This limitation particularly impacts the\naccurate rendering of multiple objects, their attributes, spatial\nrelationships, and specific poses within intricate scenes, as evidenced by\nbenchmarks like LongBench-T2I. To address these challenges, we introduce\nLVLM-Composer, a novel 10-billion parameter scale LVLM specifically engineered\nfor enhanced compositional image synthesis. Our method incorporates a\nHierarchical Semantic Planning Module for structured prompt decomposition and a\nFine-Grained Feature Alignment Mechanism for precise visual guidance during\ngeneration. We propose a multi-stage training paradigm, featuring Hierarchical\nSemantic-Visual Grounding Pre-training and Compositional Planning Reinforcement\nLearning with Self-Correction, to instill robust compositional reasoning.\nExtensive experiments on the LongBench-T2I benchmark, utilizing automatic\nevaluation by Gemini-2.0-Flash and InternVL3-78B, demonstrate LVLM-Composer's\nsuperior performance across critical compositional dimensions including object\naccuracy, composition fidelity, and pose accuracy, significantly outperforming\nstate-of-the-art baselines. An in-depth ablation study further validates the\nindispensable contribution of our proposed modules, while human evaluations\nconfirm the perceptual superiority of our generated images. LVLM-Composer\nrepresents a significant step towards truly controllable and compositionally\naccurate open-ended text-to-image generation.",
        "url": "http://arxiv.org/abs/2507.04152v1",
        "published_date": "2025-07-05T20:21:03+00:00",
        "updated_date": "2025-07-05T20:21:03+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Spencer Ramsey",
            "Jeffrey Lee",
            "Amina Grant"
        ],
        "tldr": "LVLM-Composer, a new 10B-parameter LVLM, enhances compositional text-to-image generation by using hierarchical semantic planning and fine-grained feature alignment, achieving state-of-the-art results on the LongBench-T2I benchmark.",
        "tldr_zh": "LVLM-Composer 是一种新的 10 亿参数的 LVLM，通过使用分层语义规划和细粒度特征对齐来增强组合文本到图像的生成，在 LongBench-T2I 基准测试中取得了最先进的结果。",
        "relevance_score": 10,
        "novelty_claim_score": 9,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 9
    }
]