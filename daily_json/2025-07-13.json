[
    {
        "title": "Warm Starts Accelerate Generative Modelling",
        "summary": "Iterative generative models, like diffusion and flow-matching, create\nhigh-fidelity samples by progressively refining a noise vector into data.\nHowever, this process is notoriously slow, often requiring hundreds of function\nevaluations. We introduce the warm-start model, a simple, deterministic model\nthat dramatically accelerates conditional generation by providing a better\nstarting point. Instead of starting generation from an uninformed N(0, I)\nprior, our warm-start model predicts an informed prior N(mu, sigma), whose\nmoments are conditioned on the input context. This \"warm start\" substantially\nreduces the distance the generative process must traverse, particularly when\nthe conditioning information is strongly informative. On tasks like image\ninpainting, our method achieves results competitive with a 1000-step DDPM\nbaseline using only 11 total function evaluations (1 for the warm start, 10 for\ngeneration). A simple conditional normalization trick makes our method\ncompatible with any standard generative model and sampler without modification,\nallowing it to be combined with other efficient sampling techniques for further\nacceleration. Our implementation is available at\nhttps://github.com/jonas-scholz123/warm-start-model.",
        "url": "http://arxiv.org/abs/2507.09212v1",
        "published_date": "2025-07-12T09:07:05+00:00",
        "updated_date": "2025-07-12T09:07:05+00:00",
        "categories": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Jonas Scholz",
            "Richard E. Turner"
        ],
        "tldr": "This paper introduces a \"warm-start\" method for accelerating conditional generative models (diffusion, flow-matching) by predicting a context-conditioned informed prior, significantly reducing the number of function evaluations required for high-fidelity sample generation, especially in image inpainting.",
        "tldr_zh": "本文介绍了一种\"热启动\"方法，通过预测上下文相关的先验信息来加速条件生成模型（扩散模型、流匹配模型），从而显著减少生成高保真样本所需的函数评估次数，尤其是在图像修复任务中。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Learning Diffusion Models with Flexible Representation Guidance",
        "summary": "Diffusion models can be improved with additional guidance towards more\neffective representations of input. Indeed, prior empirical work has already\nshown that aligning internal representations of the diffusion model with those\nof pre-trained models improves generation quality. In this paper, we present a\nsystematic framework for incorporating representation guidance into diffusion\nmodels. We provide alternative decompositions of denoising models along with\ntheir associated training criteria, where the decompositions determine when and\nhow the auxiliary representations are incorporated. Guided by our theoretical\ninsights, we introduce two new strategies for enhancing representation\nalignment in diffusion models. First, we pair examples with target\nrepresentations either derived from themselves or arisen from different\nsynthetic modalities, and subsequently learn a joint model over the multimodal\npairs. Second, we design an optimal training curriculum that balances\nrepresentation learning and data generation. Our experiments across image,\nprotein sequence, and molecule generation tasks demonstrate superior\nperformance as well as accelerated training. In particular, on the\nclass-conditional ImageNet $256\\times 256$ benchmark, our guidance results in\n$23.3$ times faster training than the original SiT-XL as well as four times\nspeedup over the state-of-the-art method REPA. The code is available at\nhttps://github.com/ChenyuWang-Monica/REED.",
        "url": "http://arxiv.org/abs/2507.08980v1",
        "published_date": "2025-07-11T19:29:02+00:00",
        "updated_date": "2025-07-11T19:29:02+00:00",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Chenyu Wang",
            "Cai Zhou",
            "Sharut Gupta",
            "Zongyu Lin",
            "Stefanie Jegelka",
            "Stephen Bates",
            "Tommi Jaakkola"
        ],
        "tldr": "This paper introduces a framework for incorporating representation guidance into diffusion models, demonstrating faster training and improved performance on image, protein sequence, and molecule generation tasks.",
        "tldr_zh": "本文介绍了一种将表示引导融入扩散模型的框架，在图像、蛋白质序列和分子生成任务上展示了更快的训练速度和改进的性能。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]