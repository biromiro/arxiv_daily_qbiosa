[
    {
        "title": "VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption",
        "summary": "Modern video generation frameworks based on Latent Diffusion Models suffer\nfrom inefficiencies in tokenization due to the Frame-Proportional Information\nAssumption. Existing tokenizers provide fixed temporal compression rates,\ncausing the computational cost of the diffusion model to scale linearly with\nthe frame rate. The paper proposes the Duration-Proportional Information\nAssumption: the upper bound on the information capacity of a video is\nproportional to the duration rather than the number of frames. Based on this\ninsight, the paper introduces VFRTok, a Transformer-based video tokenizer, that\nenables variable frame rate encoding and decoding through asymmetric frame rate\ntraining between the encoder and decoder. Furthermore, the paper proposes\nPartial Rotary Position Embeddings (RoPE) to decouple position and content\nmodeling, which groups correlated patches into unified tokens. The Partial RoPE\neffectively improves content-awareness, enhancing the video generation\ncapability. Benefiting from the compact and continuous spatio-temporal\nrepresentation, VFRTok achieves competitive reconstruction quality and\nstate-of-the-art generation fidelity while using only 1/8 tokens compared to\nexisting tokenizers.",
        "url": "http://arxiv.org/abs/2505.12053v1",
        "published_date": "2025-05-17T15:32:54+00:00",
        "updated_date": "2025-05-17T15:32:54+00:00",
        "categories": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Tianxiong Zhong",
            "Xingye Tian",
            "Boyuan Jiang",
            "Xuebo Wang",
            "Xin Tao",
            "Pengfei Wan",
            "Zhiwei Zhang"
        ],
        "tldr": "The paper introduces VFRTok, a novel video tokenizer that leverages a Duration-Proportional Information Assumption and Partial RoPE to achieve state-of-the-art video generation fidelity with significantly fewer tokens.",
        "tldr_zh": "该论文介绍了VFRTok，一种新型视频tokenizer，它利用持续时间比例信息假设和部分RoPE，以显着更少的token实现了最先进的视频生成保真度。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 9
    },
    {
        "title": "Self-NPO: Negative Preference Optimization of Diffusion Models by Simply Learning from Itself without Explicit Preference Annotations",
        "summary": "Diffusion models have demonstrated remarkable success in various visual\ngeneration tasks, including image, video, and 3D content generation. Preference\noptimization (PO) is a prominent and growing area of research that aims to\nalign these models with human preferences. While existing PO methods primarily\nconcentrate on producing favorable outputs, they often overlook the\nsignificance of classifier-free guidance (CFG) in mitigating undesirable\nresults. Diffusion-NPO addresses this gap by introducing negative preference\noptimization (NPO), training models to generate outputs opposite to human\npreferences and thereby steering them away from unfavorable outcomes. However,\nprior NPO approaches, including Diffusion-NPO, rely on costly and fragile\nprocedures for obtaining explicit preference annotations (e.g., manual pairwise\nlabeling or reward model training), limiting their practicality in domains\nwhere such data are scarce or difficult to acquire. In this work, we introduce\nSelf-NPO, a Negative Preference Optimization approach that learns exclusively\nfrom the model itself, thereby eliminating the need for manual data labeling or\nreward model training. Moreover, our method is highly efficient and does not\nrequire exhaustive data sampling. We demonstrate that Self-NPO integrates\nseamlessly into widely used diffusion models, including SD1.5, SDXL, and\nCogVideoX, as well as models already optimized for human preferences,\nconsistently enhancing both their generation quality and alignment with human\npreferences.",
        "url": "http://arxiv.org/abs/2505.11777v1",
        "published_date": "2025-05-17T01:03:46+00:00",
        "updated_date": "2025-05-17T01:03:46+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Fu-Yun Wang",
            "Keqiang Sun",
            "Yao Teng",
            "Xihui Liu",
            "Jiaming Song",
            "Hongsheng Li"
        ],
        "tldr": "The paper introduces Self-NPO, a novel negative preference optimization method for diffusion models that learns from the model itself, eliminating the need for external preference annotations and improving generation quality and alignment with human preferences.",
        "tldr_zh": "该论文介绍了一种名为Self-NPO的新型负偏好优化方法，用于扩散模型。该方法从模型本身学习，无需外部偏好标注，从而提高生成质量并与人类偏好对齐。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]