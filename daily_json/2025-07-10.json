[
    {
        "title": "Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation",
        "summary": "Disentangled and interpretable latent representations in generative models\ntypically come at the cost of generation quality. The $\\beta$-VAE framework\nintroduces a hyperparameter $\\beta$ to balance disentanglement and\nreconstruction quality, where setting $\\beta > 1$ introduces an information\nbottleneck that favors disentanglement over sharp, accurate reconstructions. To\naddress this trade-off, we propose a novel generative modeling framework that\nleverages a range of $\\beta$ values to learn multiple corresponding latent\nrepresentations. First, we obtain a slew of representations by training a\nsingle variational autoencoder (VAE), with a new loss function that controls\nthe information retained in each latent representation such that the higher\n$\\beta$ value prioritize disentanglement over reconstruction fidelity. We then,\nintroduce a non-linear diffusion model that smoothly transitions latent\nrepresentations corresponding to different $\\beta$ values. This model denoises\ntowards less disentangled and more informative representations, ultimately\nleading to (almost) lossless representations, enabling sharp reconstructions.\nFurthermore, our model supports sample generation without input images,\nfunctioning as a standalone generative model. We evaluate our framework in\nterms of both disentanglement and generation quality. Additionally, we observe\nsmooth transitions in the latent spaces with respect to changes in $\\beta$,\nfacilitating consistent manipulation of generated outputs.",
        "url": "http://arxiv.org/abs/2507.06613v1",
        "published_date": "2025-07-09T07:29:41+00:00",
        "updated_date": "2025-07-09T07:29:41+00:00",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Anshuk Uppal",
            "Yuhta Takida",
            "Chieh-Hsin Lai",
            "Yuki Mitsufuji"
        ],
        "tldr": "This paper introduces a multi-beta VAE framework that learns disentangled latent representations with varying degrees of disentanglement by using different beta values and a diffusion model to transition between these representations, aiming to improve both disentanglement and generation quality.",
        "tldr_zh": "该论文提出了一个多beta VAE框架，通过使用不同的beta值并利用扩散模型在不同表示之间转换，学习具有不同程度解耦的潜在表示，旨在提高解耦性和生成质量。",
        "relevance_score": 8,
        "novelty_claim_score": 7,
        "clarity_score": 8,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]