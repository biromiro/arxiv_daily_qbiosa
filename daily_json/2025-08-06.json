[
    {
        "title": "Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation",
        "summary": "We introduce Skywork UniPic, a 1.5 billion-parameter autoregressive model\nthat unifies image understanding, text-to-image generation, and image editing\nwithin a single architecture-eliminating the need for task-specific adapters or\ninter-module connectors-and demonstrate that compact multimodal systems can\nachieve state-of-the-art performance on commodity hardware. Skywork UniPic\nachieves a GenEval score of 0.86, surpassing most existing unified models; sets\na new DPG-Bench complex-generation record of 85.5; attains 5.83 on\nGEditBench-EN and 3.49 on ImgEdit-Bench for image editing; and generates 1024 x\n1024 images with under 15 GB of GPU memory (e.g., RTX 4090). (1) a decoupled\nencoding strategy that leverages a masked autoregressive encoder for synthesis\nand a SigLIP2 encoder for understanding, all feeding a shared autoregressive\ndecoder; (2) a progressive, resolution-aware training schedule scaling from 256\nx 256 to 1024 x 1024 while dynamically unfreezing parameters to balance\ncapacity and stability; and (3) meticulously curated, 100 million-scale\ndatasets augmented with task-specific reward models to refine generation and\nediting objectives. By demonstrating that high-fidelity multimodal integration\nneed not incur prohibitive resource demands, Skywork UniPic establishes a\npractical paradigm for deployable, high-fidelity multimodal AI. Code and\nweights are publicly available at\nhttps://huggingface.co/Skywork/Skywork-UniPic-1.5B.",
        "url": "http://arxiv.org/abs/2508.03320v1",
        "published_date": "2025-08-05T10:59:01+00:00",
        "updated_date": "2025-08-05T10:59:01+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Peiyu Wang",
            "Yi Peng",
            "Yimeng Gan",
            "Liang Hu",
            "Tianyidan Xie",
            "Xiaokun Wang",
            "Yichen Wei",
            "Chuanxin Tang",
            "Bo Zhu",
            "Changshi Li",
            "Hongyang Wei",
            "Eric Li",
            "Xuchen Song",
            "Yang Liu",
            "Yahui Zhou"
        ],
        "tldr": "Skywork UniPic is a 1.5B parameter autoregressive model unifying image understanding, text-to-image generation, and image editing, achieving state-of-the-art performance with efficient resource usage. It uses a decoupled encoding strategy, progressive training schedule, and curated datasets.",
        "tldr_zh": "Skywork UniPic是一个15亿参数的自回归模型，统一了图像理解、text-to-image生成和图像编辑，以高效的资源使用实现了最先进的性能。 它采用了解耦编码策略、渐进式训练计划和精选数据集。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Diffusion Models with Adaptive Negative Sampling Without External Resources",
        "summary": "Diffusion models (DMs) have demonstrated an unparalleled ability to create\ndiverse and high-fidelity images from text prompts. However, they are also\nwell-known to vary substantially regarding both prompt adherence and quality.\nNegative prompting was introduced to improve prompt compliance by specifying\nwhat an image must not contain. Previous works have shown the existence of an\nideal negative prompt that can maximize the odds of the positive prompt. In\nthis work, we explore relations between negative prompting and classifier-free\nguidance (CFG) to develop a sampling procedure, {\\it Adaptive Negative Sampling\nWithout External Resources} (ANSWER), that accounts for both positive and\nnegative conditions from a single prompt. This leverages the internal\nunderstanding of negation by the diffusion model to increase the odds of\ngenerating images faithful to the prompt. ANSWER is a training-free technique,\napplicable to any model that supports CFG, and allows for negative grounding of\nimage concepts without an explicit negative prompts, which are lossy and\nincomplete. Experiments show that adding ANSWER to existing DMs outperforms the\nbaselines on multiple benchmarks and is preferred by humans 2x more over the\nother methods.",
        "url": "http://arxiv.org/abs/2508.02973v1",
        "published_date": "2025-08-05T00:45:54+00:00",
        "updated_date": "2025-08-05T00:45:54+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Alakh Desai",
            "Nuno Vasconcelos"
        ],
        "tldr": "The paper introduces a training-free negative sampling method, ANSWER, for diffusion models that improves prompt adherence and image quality by leveraging the model's internal understanding of negation, outperforming baselines in benchmarks and human preference.",
        "tldr_zh": "本文介绍了一种无需训练的负采样方法ANSWER，用于扩散模型，通过利用模型对否定的内部理解来提高prompt的遵循度和图像质量，在基准测试和人类偏好方面优于基线方法。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]